[
  {
    "document": "## Calibrating Long-form Generations from Large Language Models\n\n### Yukun Huang[1], Yixin Liu[2], Raghuveer Thirukovalluru[1], Arman Cohan[2], Bhuwan Dhingra[1]\n\n\n1Duke University, 2Yale University\n### {yukun.huang, raghuveer.thirukovalluru}@duke.edu, bdhingra@cs.duke.edu {yixin.liu, arman.cohan}@yale.edu\n\n Abstract\n\n\nTo enhance Large Language Models\u2019 (LLMs)\nreliability, calibration is essential\u2014the model\u2019s\nconfidence scores should align with the likelihood of its responses being correct. However,\ntraditional calibration methods typically rely\non a binary true/false assessment of response\ncorrectness, unsuitable for long-form generations where an answer can be partially correct.\nAddressing this gap, we introduce a unified\ncalibration framework, in which both the correctness of the LLMs\u2019 responses and their associated confidence levels are treated as distributions across a range of scores. We develop\nthree metrics for assessing LLM calibration and\npropose confidence elicitation methods based\non self-consistency and self-evaluation. Our experiments demonstrate that larger models don\u2019t\nnecessarily guarantee better calibration, that\nvarious calibration metrics complement each\nother, and that self-consistency methods excel\nin factoid datasets. We also find that calibration\ncan be enhanced through techniques such as\nfine-tuning, scaling the temperature. Finally,\nwe illustrate one application of long-form calibration through selective answering in longform responses, optimizing correctness within\na constrained API budget.\n\n### 1 Introduction\n\n\nConfidence calibration in large language models\n(LLMs) aims to align the model\u2019s internal confidence with a probabilistic perspective of its answers\u2019 correctness (i.e. quality), enhancing reliability and interpretability for aiding human decisionmaking (Kadavath et al., 2022). People intuitively\nunderstand and utilize probabilities (Cosmides and\nTooby, 1996), making this approach crucial for\npractical applications. Conventional calibration\n(Guo et al., 2017) treats answer correctness as binary (true or false) and seeks to align the model\u2019s\nconfidence with the likelihood of model\u2019s answer\n\n\nFigure 1: A comparison between short-form generation\nand long-form generation. The correctness of the shortform answer can either be true (1) or false (0), while the\ncorrectness of the long-form answer is typically a score\nbetween 0 and 1. Both of these scores may vary across\nevaluators due to subjectivity, hence we conceptualize\nthem as a distribution over [0, 1].\n\nbeing correct, typically stated as: \u201cI am x% confi_dent that this answer is completely correct.\u201d How-_\never, the correctness of long-form generation is\nnot always either true or false but can be partially\ncorrect (Figure 1).\nTherefore, a single confidence score for longform outputs is ambiguous: it can either imply \u201cI\n_am x% confident that the answer is 100% correct\u201d_\nor \u201cI am 100% confident that the answer is x% cor_rect.\u201d The former fails to capture the graded notion_\nof long-form answer correctness, while the latter\nfocuses on self-evaluation of correctness, rather\nthan calibration as it overlooks the confidence at\nspecific correctness levels.\nAddressing this challenge, we propose to conceptualize the model\u2019s confidence as distribution\nacross scores between [0, 1] to capture the nuanced\nunderstanding of the model of each correctness\nlevel of the long-form answer, corresponding to the\nstatement \u201cI am x% confident that this answer is\n_y% correct\u201d. Moreover, we also view the correct-_\n\n\n-----\n\nFigure 2: Overview of our calibration framework. We prompt an LLM to produce an answer to a specific question,\nassess the answer\u2019s correctness distribution using an evaluator (task-specific metric/GPT-4 metric/human metric),\nand determine the model\u2019s confidence distribution through self-evaluation or self-consistency approaches. Finally,\nwe calculate the calibration score by comparing the correctness and confidence distributions against our predefined\nmetrics.\n\n\nness of an LLM\u2019s response as a distribution across\nscores between [0, 1] to capture graded and subjective assessments of long-form generations quality.\nThis subjectivity arises from the multifaceted nature of evaluating long-form outputs, where factors\nlike factuality, coherence, clarity, and comprehensiveness each play a role, potentially introducing\nvariability in judgment (Bakker et al., 2022). We\ncan then measure both the classical notion of calibration error, averaged across different correctness\nlevels, as well as new notions of alignment between the correctness and confidence distributions\nand their utility in selective prediction (\u00a7 3.4). Figure 2 shows an overview of our framework, which\nconsists of three modular components: estimating\nthe target correctness distributions, eliciting confidence distributions from LLMs, and measuring\ncalibration between these distributions.\n\nOur unified framework offers three key advantages. 1. Generalizability: Our framework applies\nto both long-form and short-form generation tasks\nby representing correctness and confidence as distributions, regardless of whether the correctness of\ntask is binary, continuous, subjective, or objective.\n2. Flexibility: The framework is evaluation-metric\nagnostic, allowing the integration of any metric\nor confidence elicitation method, and can adapt\nas evaluation methods evolve. 3. Interpretability: It provides a nuanced view of uncertainty, enabling decision-makers to assess confidence across\nmultiple correctness levels, fostering greater transparency and trust in the model\u2019s outputs.\n\nWe leverage our framework to measure calibration for several LLMs on multiple datasets\nacross three long-form QA\u2014ASQA (Stelmakh\n\n\net al., 2022), ELI5 (Fan et al., 2019), QAMPARI\n(Amouyal et al., 2022)\u2014and one summarization\ntask, CNNDM (Nallapati et al., 2016). Our results show that our methods excel over baselines\nby leveraging the model\u2019s nuanced confidence distribution, stronger LLMs like GPT-3.5 don\u2019t necessarily guarantee better calibration, that various\ncalibration metrics complement each other, and\nLLMs exhibit better calibration on factoid datasets\nthan more open-ended datasets. Furthermore, our\nanalysis highlights that fine-tuning and temperature scaling could enhance calibration. Finally, we\nillustrate a practical application of long-form calibration: employing a cascading strategy (Chen\net al., 2023a) for selective answering to optimize\nthe cost-effectiveness of long-form text generation. In this approach, an open-source model initially handles queries and, based on its confidence\nlevels\u2014assessed using our system\u2014a more advanced API model is engaged as needed. This\nmethod ensures cost efficiency while maintaining\nhigh-performance levels.\nIn summary, our contributions are:\n\n  - A universal calibration framework for text generation tasks, enhancing LLM evaluation for\ncritical applications.\n\n  - Innovative methods for confidence elicitation\nand calibration measurement, applied to a variety of LLMs.\n\n  - Evidence that calibration can be improved by\nmodel fine-tuning and temperature scaling.\n\n  - A cost-effective model usage strategy, illustrating the practicality of long-form calibration in optimizing LLM deployment.\n\n\n-----\n\n### 2 Related Work\n\n**Measuring Calibration Calibration (Guo et al.,**\n2017, Minderer et al., 2021)has been widely\nstudied in language models, whose probabilities\nderived from logits are generally found to not be\ncalibrated (Jiang et al., 2020, Kadavath et al., 2022,\nChen et al., 2023d). Standard metrics to measure\nthe calibration include Expected Calibration\nError (ECE) for confidence-accuracy disparity\n(Naeini et al., 2015), Brier Score for mean squared\nprediction-outcome differences, and AUROC\nfor assessing confidence-based correct answer\nidentification (Boyd et al., 2013, Kuhn et al.,\n2023). Selective Accuracy@Coverage measures\naccuracy within the model\u2019s most confident\npredictions (Liang et al., 2023, Cole et al., 2023).\nHowever, these metrics, rooted in a binary notion\nof correctness, fall short for long-form tasks\nwhere correctness spans a range, suggesting a\ndistribution-based approach is more apt.\n\n**Improving** **Calibration** Traditional calibration methods focus on post-processing logits (Guo\net al., 2017), but with LLMs generating unbounded\ntext, logits could fall short. Thus, extracting better\nconfidence scores (i.e., confidence elicitation)\nhas become crucial for improving calibration.\nThese include: verbalization, which directly asks\nthe model to output its confidence (Lin et al.,\n2022), consistency, which uses the uniformity of\nmultiple responses to gauge confidence (Kadavath\net al., 2022, Kuhn et al., 2023, Cole et al., 2023,\nChen et al., 2023c, Tian et al., 2023a, Lin et al.,\n2023), and the hybrid of both (Xiong et al., 2023,\nTian et al., 2023b, Chen and Mueller, 2023).\nHowever, these methods often presume binary\nanswer correctness, offering a singular confidence\nscore that fails to capture the nuanced correctness\nrequired for long-form tasks. Recent work (Zhang\net al., 2024) on long-form generation addresses\ncontinuous correctness scores but focuses on\naligning an uncertainty score with correctness,\nrather than on improving calibration.\n\n### 3 Long-form Generations Calibration\n\nThis section formalizes the long-form generation\ncalibration problem (\u00a7 3.1), and introduces three\ncore components in our calibration framework (Figure 2): the correctness distributions of the answers\n(\u00a7 3.2), the confidence distributions of the LLM on\nits answers (\u00a7 3.3), and the calibration metrics to\n\n\nmeasure how well these two align (\u00a7 3.4).\n\n**3.1** **Formulation**\n\nGiven a dataset, the model\u2019s answer for each\n_D_\nquestion Qi in the dataset is answer Ai (where i indexes the questions in the dataset). To measure how\ncalibrated the model is, we need three steps. First,\nwe apply an evaluator to get the target correctness\ndistribution PTi where Ti is the random variable\nthat denotes the correctness score in answer Ai.\n\n_PTi(x) = Pr(Ai is s correct)_ (1)\n\nfor s, where is the space of correctness\n_\u2208S_ _S_\nlevels (e.g., normalized from ordinal scores ranging from 0 to 5). It should be noted that s could\ntheoretically be a continuous value in the range\n\n[0%, 100%]. However, since humans tend to make\nmore accurate judgments using discrete ratings due\nto \u201crounding bias\u201d (Honda et al., 2022), we approximate continuous correctness with ordinal scores in\npractice. Second, We use a confidence elicitation\nmethod to derive the confidence distribution PCi\nfrom LLM M, where Ci represents the model\u2019s\nconfidence in its answer Ai. We ensure these confidence scores are normalized to form a valid distribution, matching the domain of the correctness\ndistribution. For s,\n_\u2208S_\n\n_PCi(x) = M\u2019s confidence that A is s correct (2)_\n\nFinally, we design metrics to measure the alignment between PCi and PTi across the dataset.\n\n**3.2** **Correctness Distribution Estimation**\n\nTo establish correctness distributions as alignment\ntargets, we need to adopt long-form evaluation metrics that integrate aspects such as relevance, coherence, factuality, and helpfulness. Traditional\nmetrics like BLEU and ROUGE fail to capture semantic meaning (Liu et al., 2023a), while factualitybased metrics like FactScore (Min et al., 2023)\nmay neglect question relevance. GPT-4 metrics\nhave gained popularity (Li et al., 2024) due to their\nadaptability and comparative accuracy (Jain et al.,\n2023, Liu et al., 2023a). These metrics allow for\nthe integration of various user-prioritized aspects\nby adjusting evaluation rubrics, providing a balanced approach to both referenced and divergent\nanswers. However, they also have limitations like\na bias toward longer outputs (Zheng et al., 2023).\nOur framework is evaluator-agnostic, allowing\nus to use any correctness distribution metric. To\n\n\n-----\n\nidentify a practical and actionable metric that best\nguides human decision-making, we conduct human evaluations to determine alignment with human judgment. According to the results in Appendix C, we determined that the GPT-4 metric,\nwith a higher correlation to human judgments compared to the task-specific metric, is more effective\nfor three datasets (e.g., 76.2 v.s 47.8 in ASQA),\nwhile the task-specific metric is preferred for another dataset. Our framework\u2019s modular design\nallows replacements of evaluation metrics based on\nuser needs or new developments.\n\n**3.3** **Confidence Distribution Elicitation**\n\nThere are two common strategies to develop confidence in model responses: explicitly asking the\nmodel to verbalize its confidence or implicitly estimating it through self-consistency. However, the\nsingle confidence score provided by prior studies\nis ambiguous and non-interpretable in long-form\ncalibration. Therefore, we develop two methods\ntailored for long-form calibration accordingly.\n**Continuous Self Evaluation (CSE) We prompt**\nthe model to repeatedly perform self-evaluations,\nwhere the resulting scores (typically ordinal scores\nfrom 0 to 5) are normalized to a [0,1] range and\ninterpreted as a confidence distribution. The selfevaluation template closely mirrors the template\nfor correctness evaluation but omits the reference\nanswer (see Appendix F.3 for details). Formally,\ngiven an LLM, N self-evaluations:\n_M_\n\n\nAssessing similarity in long-form answers is more\ncomplex than with short responses (Kadavath et al.,\n2022). To address this, we propose four methods\nfor evaluating similarity in long-form content: 1.\n**Naive, assessing overall response similarity with**\nan LLM; 2. Split, analyzing sentence-level similarity; 3. Claim, evaluating claim matching; 4.\n**Named Entity Recognition (NER), focusing on**\nnamed entity overlap. These approaches range\nfrom broad to detailed analysis, chosen based on\ntask requirements and the desired analysis depth.\nSee Appendix B for more details.\n\n**3.4** **Calibration Metrics**\n\nWe introduce three key metrics to assess model\ncalibration from various angles. Expected correct_ness error with multi-class (ECE-M) measures the_\nalignment between the model\u2019s stated confidence\nin reaching a particular level of correctness and\nthe actual likelihood that the model performs at\nthat specified level, across the spectrum from 0 to\n1. Correlation evaluates the alignment between\nexpected confidence and correctness across the\n_dataset, indicating the model\u2019s proficiency in_\nranking answers. Selective F1 measures the utility\nof confidence scores in identifying the good\nanswers and abstaining from the rest.\n\n**ECE-M The classical notion of calibration**\nrelies on an (answer-correctness) pair of random\nvariables (A, Y ) 0, 1, where is the\n_\u2208A \u00d7 {_ _}_ _A_\nanswer space. An LLM with its confidence\n_M_\nelicitation method h : [0, 1] is said to be\n_M_ _A \u2192_\nwell-calibrated if Pr(Y = 1 _h_ (A) = q) = q\n_|_ _M_\nfor q [0, 1]. To measure if this holds, tradi_\u2208_\ntional ECE(h) (Gupta and Ramdas, 2021) is:\nEA [|Pr(Y = 1|hM(A)) \u2212 _hM(A)|]_\nIn long-form calibration where the answer correctness is a continuum Y [0, 1], the probabilistic\n_\u2208_\nconfidence predictor hM should predict confidence\nabout each level of correctness and therefore denoted as h : [0, 1] [0, 1]. The notion of\n_M_ _A \u00d7_ _\u2192_\nlong-form calibration is Pr(Y = s _h_ (A, s) =\n_|_ _M_\n_qs) = qs for every s \u2208_ [0, 1] and qs \u2208 [0, 1] We\ndefine ECE-M as the aggregation of ECE scores for\nall correctness levels. In practice, we use discrete\nlevels s (e.g., ratings from 0-5) for the cor_\u2208S_\nrectness scores. Hence, we calculate an ECE(s, h)\nconditioned on each s,\n\nEX [|Pr(Y = s|hM(A, s)) \u2212 _hM(A, s)|]_ (5)\n\nThen the final ECE-M score is weighted by the\n\n\n_PCi(s) = N[1]_\n\n\n_N_\n\ufffd\n\n1(M(Ai)j = s) (3)\n_j=1_\n\n\nfor score s, where is the space of correctness\n_\u2208S_ _S_\nlevels. Such a sampling method provides a more\nauthentic reflection of the model\u2019s internal distribution than logits (Cole et al., 2023). By asking\nthe model to assess an answer multiple times, we\ncapture a range of scores that better represent the\nmodel\u2019s confidence, which enhances the reliability\nof the confidence estimation.\n**Pairwise Self Consistency (PSC) Another key**\nindicator of model confidence is the consistency\namong multiple responses a model provides for a\ngiven question. Given a primary answer Ai, other\n_N answers A[1]i_ _[...A]i[N]_ [sampled from LLM][ M][, a met-]\nric for measuring the similarity between two answers Sim( _,_ ), and a score s :\n\n_\u00b7_ _\u00b7_ _N_ _\u2208S_\n\n\ufffd\n\n_PCi(s) = [1]_ 1(Sim(Ai, A[j]i [) =][ s][)] (4)\n\n_N_\n\n_j=1_\n\n\n-----\n\nfrequency of each class:\n\n\ufffd\nECE-M(h) := Pr(Y = s)ECE(s, h) (6)\n\n_s\u2208S_\n\n**Correlation While ECE-M focuses on mea-**\nsuring calibration at each correctness level\nindependently, it doesn\u2019t account for the distance\nbetween these levels. To address this, we also measure the correlation between the expected values\nof the confidence and correctness distributions\nfor a more comprehensive assessment. For each\nanswer Ai within the dataset, we can calculate\nthe expected correctness score of the model\n_E|Ci| =_ [\ufffd]s _[P][C]i[(][s][)][ \u00d7][ s][ and the expected correct-]_\nness score of the target E|Ti| = [\ufffd]s _[P][T]i[(][s][)][ \u00d7][ s][.]_\nIn the whole dataset, we can get a list of expected\ncorrectness scores EC from model confidence\nand a list of target expected correctness scores\n**ET. Then we can measure the correlation between**\nthem.\n\n_\u03c1(D) = Corr(EC, ET)_ (7)\n\nwhere Corr( ) represents the correlation function.\n\n_\u00b7_\nThis correlation provides a clear indicator of how\nwell our model\u2019s confidence aligns with its actual\ncorrectness across the entire dataset.\n\n**Selective F1 In selective answering (e.g., Kamath**\net al., 2020), models only respond when confident\nabout their accuracy to improve reliability. Traditional metrics for selective answering include\naccuracy@coverage and coverage@accuracy (Tian\net al., 2023b), which measures a model\u2019s precision\nand recall in selecting completely correct answers.\nSimilarly, in long-form calibration, it is crucial to\nassess the model\u2019s selection of answers that are at\nleast \"s% correct\" using both precision and recall.\nTherefore, we propose the selective F1 metric\n(F 1\u03c4s) to quantify the model\u2019s aptitude in filtering out answers that meet or exceed a predefined\ncorrectness threshold \u03c4s. Our approach utilizes a\ndual-threshold system, consisting of a confidence\nthreshold (\u03c4c) and the correctness threshold (\u03c4s),\nallowing the model to answer questions only if\nits confidence in the answer\u2019s expected correctness score exceeding \u03c4s surpasses \u03c4c. Formally,\nlet A = {A1, A2, ..., An} denote the total set of\nmodel\u2019s answers in the dataset and A[\u2217] = {Ai \u2208\n_A |_ [\ufffd]s\u2265\u03c4s _[P][C]i[(][s][)][ \u2265]_ _[\u03c4][c][}][ denote the set of selected]_\nanswers. Let the indicator function I\u03c4s(Ai) indicate if the expected correctness score E[Ti] of Ai\nexceeds \u03c4s:\n\n\n_I\u03c4s(Ai) =_\n\n\n\ufffd\n1 if E[Ti] \u2265 _\u03c4s_\n(8)\n0 Otherwise\n\n\nThe selective precision P\u03c4s on the dataset D is the\nproportion of selected answers that surpass the correctness threshold \u03c4s relative to the total number of\nselected answers:\n\n\n_P\u03c4s(D) =_\n\n\n\ufffd\n_Ai\u2208A[\u2217]_ _[I][\u03c4]s[(][A][i][)]_\n\n(9)\n_|A[\u2217]|_\n\n\nThe selective recall R\u03c4s compares the number of\nselected answers meeting this criterion against the\ntotal number of correct answers in the dataset that\nexceed the threshold \u03c4s:\n\n\n_R\u03c4s(D) =_\n\n\n\ufffd\n_Ai\u2208A[\u2217]_ _[I][\u03c4]s[(][A][i][)]_\n(10)\n\ufffd\n_Ai\u2208A_ _[I][\u03c4]s[(][A][i][)]_\n\n\nThe selective F1 combines recall and precision:\n\n_F_ 1\u03c4s(D) = 2 _[P][\u03c4][s][(][D][)][R][\u03c4][s][(][D][)]_ (11)\n\n_P\u03c4s(D) + R\u03c4s(D)_\n\nIn our experiments, we select \u03c4s as the nearest\ncorrectness level greater than the best LM\u2019s average\ncorrectness score. For \u03c4c, we choose the value\nthat yields the highest selective F1 score on the\ndevelopment split.\n\n### 4 Experiments and Results\n\n**4.1** **Setup**\n\n**Models and Data We measure different sized**\nLLMs\u2019 calibration, including Llama-2-13b-chat,\nLlama-2-70b-chat (Touvron et al., 2023), Vicuna13b (Zheng et al., 2023), Llama-3-8b-Instruct, GPT3.5-turbo, across three long-form QA tasks: ASQA\n(Stelmakh et al., 2022), ELI5 (Fan et al., 2019),\nQAMPARI (Amouyal et al., 2022), and one summarization task: CNNDM (Nallapati et al., 2016).\nDetails of datasets can be found in Appendix A.\n**Correctness Evaluation We apply GPT-4 to evalu-**\nate target correctness distributions for ASQA, ELI5,\nand CNNDM. In QAMPARI where the answer is\na list of entities, we evaluate using the F1-5 metric, calculating the F1 score by the exact match\nwith the gold answer and defining 100% recall for\npredictions with at least 5 correct answers.\n\n**4.2** **Confidence Elicitation Methods**\n\nIn addition to our methods CSE and PSC (see Appendix D.3 for similarity measurement choosing),\nwe established baselines for self-evaluation, selfconsistency, and logits-based approaches. This is\n\n\n-----\n\n|Method|ASQA ECE-M Corr F1 0.8|QAMPARI ECE-M Corr F1 0.4|ELI5 ECE-M Corr F1 0.8|CNNDM ECE-M Corr F1 0.8|\n|---|---|---|---|---|\n\n|SL\u2217|28.2\u2191 0.7\u2191 0.0 \u2191|27.4\u2191 10.9\u2191 8.0\u2191|29.6\u2191 -11.9\u2191 0.0\u2191|77.2\u2191 -7.5\u2191 0.0\u2191|\n|---|---|---|---|---|\n\n|BSE\u2217 CSE|32.8\u2191 14.2\u2191 57.6 \u2191 29.0\u2193 16.3\u2191 58.5 \u2191|25.2\u2191 16.8\u2191 33.2\u2191 42.8\u2191 21.9\u2191 33.4\u2191|30.3\u2191 11.7\u2191 46.7\u2191 31.2\u2191 26.9\u2191 48.2\u2191|78.5\u2191 11.2\u2191 90.6\u2191 15.2\u2193 19.2\u2191 92.0\u2191|\n|---|---|---|---|---|\n\n|ASC\u2217 PSC F 1 PSC|35.9\u2191 27.1\u2191 5.2 \u2191 28.8\u2191 27.1\u2191 33.5 \u2191 18.3\u2193 46.8\u2191 61.6 \u2191|46.0\u2191 38.6\u2191 38.5\u2191 38.4\u2191 38.6\u2191 42.7\u2191 26.2\u2193 39.1\u2191 44.0\u2191|38.4\u2191 16.7\u2191 7.9\u2191 27.1\u2191 16.7\u2191 20.7\u2191 24.9\u2193 24.9\u2191 46.2\u2191|63.2\u2191 8.8 \u2191 44.2\u2191 57.1\u2191 8.8\u2191 79.5\u2191 64.5\u2191 15.5\u2191 90.0\u2191|\n|---|---|---|---|---|\n\n\nTable 1: Calibration Performance Comparison Among Different Confidence Elicitation Methods Across Four Tasks\n(in %): \u201cECE-M\u201d for expected correctness error with multi-class, \u201cCorr\u201d for Correlation, \u201cF 1\u03c4s\u201d for Selective F1\nScore at threshold \u03c4s. Results represent averages from five models. Methods with * served as baselines. For \u201cCorr\u201d,\n\u201cF 1\u03c4s \u201d, and \u201cScore\u201d, \u2191 means better than corresponding baseline while \u2193 is worse. For \u201cECE-M\u201d, \u2193 is better while\n\n_\u2191_ is worse. The best score among all confidence elicitation methods is bolded. Key insights: 1) Self-Consistency\n(PSC) outperforms Self-Evaluation on factoid datasets; 2) Our methods PSC and CSE surpass baselines; 3) Different\nmetrics offer complementary insights\n\n\nbecause prior studies lack directly applicable baselines, primarily due to the non-interpretable nature\nof single confidence scores.\n**Sentence Likelihood (SL): Based on prior stud-**\nies using logits to gauge model confidence, we\nadopt sentence likelihood as a baseline measure,\nwhich typically results in a confidence distribution\nfocused at the lowest score in long-form answers.\n**Binary Self-Evaluation (BSE): following previous**\nwork (Kadavath et al., 2022) that asks model to selfevaluate if its answer is true several times, using\nthe frequency of true as model\u2019s confidence score\ntowards the answer being true. Then we adapt such\na single score as a distribution focus solely on the\nvalues 0 and 1.\n**Average Self-Consistency (ASC): Following prior**\nwork (Xiong et al., 2023) using the average consistency between these candidate responses and the\noriginal answer then serves as a single measure\nof confidence score, we adopt the simple f1-token\nscore to measure the consistency to adapt it to longform generations. Then we treat the single score as\na point mass distribution.\n**Pairwise Self-Consistency F1 (PSC-F1): Still us-**\ning F1 to measure the consistency like ASC, but\nwe directly treat the pairwise consistency scores as\na distribution without aggregating, thereby keeping model intrinsic understanding about different\ncorrectness levels.\n\n**4.3** **Main Results**\n\nIn Table 1, we evaluate the calibration performances of various confidence elicitation methods\nby averaging the scores across all models. Table 1\nshows that our methods, CSE and PSC, generally\noutperform their respective baseline categories\n\n\nand also surpass the logits-based method SL. Key\nfindings from the results include:\n\n**Self-Consistency Outperforms Self-Evaluation**\n**on Factoid Datasets Self-consistency methods**\ntypically outperform self-evaluation on factoid\ndatasets like ASQA and QAMPARI. However,\ntheir effectiveness diminishes in more subjective\ntasks such as ELI5 or CNNDM. We hypothesize\nthat this is because self-consistency is more\nreadily quantifiable in factoid datasets, where the\nagreement between answers can be assessed based\non factual consistency, thus providing clearer\ncriteria. Conversely, in open-ended datasets, the\nconsistency between answers is more ambiguous,\nmaking it more difficult to measure.\n\n**Nuanced** **Self-Evaluation** **Enhances** **Cali-**\n**bration CSE generally outperforms BSE by**\nproviding detailed confidence estimates at each correctness level. However, the overall improvement\nremains constrained by the intrinsic limitations of\nLMs in self-evaluating their correctness, which\nsometimes hampers accurate estimations.\n\n**Pair-wise** **Similarities** **Distribution** **and**\n**Task-tailored Similarity Measurement Help**\n**Calibration Both ASC and PSC-F1 measure**\nsimilarity with token-level F1. However, PSC-F1\ntreats these scores as a distribution rather than\naveraging them, leading to better ECE-M and\nselective F1. PSC further enhances calibration by\nadopting a task-specific, detailed measurement of\nsimilarity, outperforming FSC in all four tasks.\n\n\n-----\n\n|Model|ASQA ECE-M Corr F1 Score 0.8|QAMPARI ECE-M Corr F1 Score 0.4|\n|---|---|---|\n\n|Llama2-13b Llama2-70b Vicuna-13b Llama-3-8b GPT-3.5-turbo|15.9 48.0 47.5 51.3 14.7 44.3 61.9 59.4 20.1 58.2 56.8 50.8 14.3 53.2 65.1 54.9 26.7 30.5 76.7 72.6|30.5 46.0 42.3 13.3 29.3 17.1 37.0 14.6 14.4 49.5 42.6 11.4 33.0 38.3 42.0 14.1 23.7 44.4 56.2 24.0|\n|---|---|---|\n\n|Model|ELI5 ECE-M Corr F1 Score 0.8|CNNDM ECE-M Corr F1 Score 0.8|\n|---|---|---|\n\n|Llama2-13b Llama2-70b Vicuna-13b Llama-3-8b GPT-3.5-turbo|36.0 21.8 40.1 53.8 32.8 18.8 54.4 61.7 19.4 31.3 34.9 53.0 34.9 36.7 48.4 57.1 32.7 26.2 63.4 63.0|12.6 19.5 92.0 77.0 13.8 6.4 93.6 77.6 32.7 3.9 64.2 78.2 9.3 49.0 86.9 77.8 7.8 17.0 94.7 78.2|\n|---|---|---|\n\n\nTable 2: Comparison of Calibration Performance Across Models for Four Tasks (in %): We identify the optimal\nconfidence elicitation method for each task and compare the performance of various models using this method.\n\u201cScore\u201d means the model\u2019s average correctness score on that task. A key observation is that more powerful LMs do\nnot necessarily exhibit better calibration, although they tend to perform better in selective answering.\n\n\n**Calibration metrics complement each other A**\nsimplistic approach like SL, which allocates all\nthe probability mass to the point of score 0, can\nmisleadingly show decent ECE-M (28.2%) in\nspecific cases like ASQA. However, its negative\ncorrelation (0.7%) and zero F10.8 underscore an\nineffective confidence distribution. Similarly, BSE\nin CNNDM may achieve a high F10.8 (90.6%)\nby overestimating answer correctness, but this\ndoes not truly reflect response quality (correlation:\n11.2%) or provide well-calibrated probabilities\nacross correctness levels, resulting in a bad ECE-M\n(ECE-M: 78.5%). Hence, a comprehensive\nevaluation using multiple metrics is essential for a\nbalanced assessment of model calibration.\n\n**Larger models are not necessarily better**\n**calibrated. In Table 2, we focus on the calibration**\nperformance of individual models when paired\nwith the best-performing confidence elicitation\nmethod for each task. Table 2 shows that despite\npoor performance on ASQA and QAMPARI,\nVicuna-13b has the highest correlation across\nthese datasets. It might be because reinforcement\nlearning for other models causes miscalibration\nby encouraging overfitting to rewarded behaviors\n(Kadavath et al., 2022). Scaling the temperature\ncould enhance the calibration of LLMs fine-tuned\nusing RL (see \u00a7 4.4). Additionally, Llama-2-13b\ndemonstrates a higher correlation than its larger\n\n\ncounterpart, Llama-2-70b. However, GPT-3.5turbo, the strongest model, consistently scores the\nhighest in selective F1 across all datasets. This\nperformance can be attributed to the model\u2019s\nability to generate a larger volume of high-quality\nanswers, increasing the probability of selecting\nsuperior responses even if it is not particularly\nwell-calibrated. Consequently, the Selective F1\nmetric blends performance and calibration, and\ntends to favor more capable models due to their\nhigher output of quality answers.\n\n**4.4** **Improving Calibration**\n\nWe delve into different strategies to enhance\ncalibration: fine-tuning, scaling the temperature,\nadding source documents (Appendix E.2), and\nhybrid confidence elicitation (Appendix E.3).\n\n**Fine-tuning Our study explores three fine-**\ntuning strategies to improve model calibration\non the ASQA dataset: fine-tuning the model for\nself-evaluation (using questions and model answers\nto produce scores and explanations), fine-tuning\nthe model for generation (generating answers\nfrom questions), and a hybrid of both. GPT-4\nsynthesizes self-evaluation data by assessing\ndifferent models\u2019 answers to questions from the\nASQA training set, while the generation data\n\n\n-----\n\noriginates from the ASQA training set itself.\nWe apply LoRA (Hu et al., 2021) fine-tuning to\nthe Llama2-13b model. See Appendix E.1 for\nexperiment details. As Table 3 reveals, solely\ntraining on self-evaluation (\u2018Evaluation\u2019) did\nnot yield consistent improvements in calibration,\npossibly due to the complexity of this task and\nthe limitation of LORA. Nonetheless, fine-tuning\nthe model improves the self-consistency method,\nespecially when the generation data is included\nduring training (\u2018Eval + Gen\u2019 and \u2018Generation\u2019).\nThe model becomes more confident in terms of\nself-consistency after fine-tuning.\n\n**Data** **Corr** **ECE-M** **F10.8** **Score**\n\n**Self-Evaluation (CSE)**\nNone 18.1 \u2191 30.3 \u2191 50.8 \u2191 51.3 \u2191\n\nEvaluation 13.6 \u2193 32.4 \u2191 52.3 \u2191 49.2 \u2193\n\nGeneration 20.0 \u2191 26.2 \u2193 53.4 \u2191 52.1 \u2191\n\nEval + Gen 23.9 \u2191 20.2 \u2193 46.6 \u2193 50.1 \u2193\n\n**Self-Consistency (PSC)**\nNone 48.0 \u2191 15.9 \u2191 47.5 \u2191 51.3 \u2191\n\nEvaluation 46.9 \u2193 13.6 \u2193 56.1 \u2191 49.2 \u2193\n\nGeneration 58.9 \u2191 14.5 \u2193 59.5 \u2191 52.1 \u2191\n\nEval + Gen 54.5 \u2191 12.2 \u2193 50.7 \u2191 50.1 \u2193\n\n\n60\n\n40\n\n20\n0.2 0.4 0.6 0.8 1\n\n\n50\n\n30\n\n10\n0.2 0.4 0.6 0.8 1\n\n\n_t_\n\n\n_t_\n\n\n70\n50\n30\n10\n\n0.2 0.4 0.6 0.8 1\n\n_t_\n\n\n15\n14\n13\n12\n0.2 0.4 0.6 0.8 1\n\n_t_\n\n\nFigure 3: Calibration varies with temperature scaling.\n\nhow many queries reach GPT-4, balancing answer\nquality with API budget constraints. We benchmark using the open-source LM for a zero API\nbudget and the commercial LM for full-budget scenarios. Our experiments utilize the ASQA and\n\n\nTable 3: Comparison among raw and fine-tuned Llama2-13b on ASQA. \u201cNone\u201d for the untrained model, \u201cEvaluation\u201d for the model fine-tuned with the self-evaluation\ndataset, \u201cGeneration\u201d for the model fine-tuned with the\nASQA generation data, and \u201cEval+Gen\u201d for the model\nfine-tuned with the hybrid dataset combined by selfevaluation dataset and generation data.\n\n**Temperature We adjust the generation tempera-**\nture for Llama2-13b from 0.2 to 1 to examine its\nimpact on calibration. The result in Figure 3 reveals consistent improvements in all calibration\nmetrics. Notably, the model\u2019s performance initially\nimproves and then deteriorates. This observation\nimplies that modulating the generation temperature\ncan enhance the calibration of the model.\n\n\n**4.5** **Application**\n\nWe showcase an application of long-form calibration in Figure 4: a cost-effective cascading strategy\nusing language models of varying capabilities to\nefficiently handle queries within an API budget\nconstraint. Initially, an open-source model (Llama2-13b in our experiment) address questions where\nit believes the answer has a probability higher than\n_\u03c4c that the answer\u2019s correctness score is above \u03c4s._\nComplex queries, flagged by lower model confidence, are escalated to a more advanced API LM\n(GPT-4). Adjusting \u03c4c between 0 and 1 controls\n\n\nFigure 4: The illustration of LLM Cascade.\n\nQAMPARI datasets to evaluate four distinct confidence elicitation strategies: PSC, ASC, CSE, and\nBSE. Additionally, we incorporate a baseline strategy where, under a constrained number of API requests, a random selection of queries is processed\nby Llama-2-13b, with the remaining handled by\nGPT-4. For each API budget scenario, questions\nare randomly assigned to Llama-2-13b using 10\ndifferent random seeds, and we calculate the mean\nand standard deviation of the results. We focus on\nthe success rate, which we define as the percentage of answers that meet or exceed a user-specified\nscore threshold. This metric is reported both for the\noverall dataset and for the subset of queries selected\nand handled by Llama-2-13b, illustrating both the\ngeneral effectiveness of our cascading model and\nthe selective answering capabilities of the individual model. As shown in Figure 5, PSC generally\noutperforms the other methods, with CSE and BSE\nyielding comparable results that follow. ASC, in\ncontrast, performs the poorest, comparable to the\nrandom selection strategy. These results highlight\nthe pivotal role of advanced calibration techniques,\nconfidence elicitation methods in our case, in boosting the practical utility and cost-efficiency of LLMs\nwhen API usage is limited.\n\n\n-----\n\n0.9\n\n0.8\n\n0.7\n\n0.6\n\n0.5\n\n0.4\n\n|Col1|Col2|Col3|Col4|Col5|\n|---|---|---|---|---|\n||||||\n||||||\n||||||\n|||||PSC CSE BSE|\n|||||ASC Random|\n\n|Col1|Col2|Col3|Col4|Col5|Col6|\n|---|---|---|---|---|---|\n|||||||\n|||||||\n|||||||\n|||||PSC||\n|||||CSE BSE||\n|||||ASC Random||\n\n\n0 0.2 0.4 0.6 0.8 1.0\n\nbudget\n\n\n0 0.1 0.3 0.5 0.7 0.9\n\nbudget\n\n\n0.8\n\n0.7\n\n0.6\n\n0.5\n\n0.4\n\n0.3\n\n\nhave significant real-world implications. Lastly,\nour self-consistency method is computationally\nintensive, posing a challenge for practical applications. There is a need for more efficient approaches\nin real-world settings.\n\n**Replicability:**\nCodes: [https://github.com/kkkevinkkkkk/](https://github.com/kkkevinkkkkk/calibration)\n[calibration](https://github.com/kkkevinkkkkk/calibration)\n\n\n(a) ASQA Overall\n\n\n(b) ASQA Selected\n\n\n0.6\n\n0.5\n\n0.5\n\n0.4\n\n0.4\n\n0.3\n\n0.2\n\n|Col1|Col2|Col3|Col4|Col5|\n|---|---|---|---|---|\n||||||\n||||||\n|||||PSC|\n|||||CSE BSE|\n|||||ASC Random|\n\n|Col1|Col2|Col3|Col4|Col5|\n|---|---|---|---|---|\n||||||\n|||||PSC|\n|||||CSE BSE|\n|||||ASC Random|\n\n\n0 0.2 0.4 0.6 0.8 1.0\n\nbudget\n\n\n0.5\n\n0.4\n\n\n0 0.1 0.3 0.5 0.7 0.9\n\nbudget\n\n\n0.3\n\n0.2\n\n\n(c) QAMPARI Overall\n\n\n(d) QAMPARI Selected\n\n\nFigure 5: Variation in Success Rate by API Budget\nAllocation on the ASQA and QAMPARI Datasets for\nAll Queries and Those Selected by Llama-2.\n\n### 5 Conclusion\n\n\nOur study presents a novel calibration system for\nevaluating LLMs in long-form generation. Our results challenge the assumption that larger LLMs are\nalways calibrated better and show calibration variability across datasets. Additionally, we propose\nmethods to improve LLM calibration and show\nan application that optimizes performance under\nAPI budget constraints. The system we present is\ncrucial for further improving the liability of LLMs.\n\n### 6 Limitation\n\n\nOur study faces three primary limitations. First,\nwe rely on GPT-4 to estimate the target correctness\ndistribution. But as tasks become more subjective,\nconsensus on humans\u2019 evaluations may decrease.\nThis wider target correctness distribution becomes\nchallenging for both GPT-4 and human annotators\nto accurately capture. This limitation is inherent\nto natural language generation (NLG) evaluation\nand lies beyond the purview of our project. Our\nframework operates under the premise that a target\ncorrectness distribution exists and concentrates on\ncalibration which aligns the model\u2019s confidence\nwith this assumed target. Second, our experiments\nfocus on long-form QA and do not extend to\nspecialized domains such as law, medicine, or\neducation, where the calibration of LLMs could\n\n\n### References\n\nSamuel Joseph Amouyal, Tomer Wolfson, Ohad Rubin,\nOri Yoran, Jonathan Herzig, and Jonathan Berant.\n[2022. Qampari: An open-domain question answer-](https://api.semanticscholar.org/CorpusID:249062559)\n[ing benchmark for questions with many answers from](https://api.semanticscholar.org/CorpusID:249062559)\n[multiple paragraphs.](https://api.semanticscholar.org/CorpusID:249062559)\n\nMichiel A. Bakker, Martin Chadwick, Hannah Sheahan,\nMichael Henry Tessler, Lucy Campbell-Gillingham,\nJan Balaguer, Nathan McAleese, Amelia Glaese,\nJohn Aslanides, Matthew M. Botvinick, and Christo[pher Summerfield. 2022. Fine-tuning language mod-](https://api.semanticscholar.org/CorpusID:254043997)\n[els to find agreement among humans with diverse](https://api.semanticscholar.org/CorpusID:254043997)\n[preferences. ArXiv, abs/2211.15006.](https://api.semanticscholar.org/CorpusID:254043997)\n\nKendrick Boyd, Kevin H. Eng, and David Page. 2013.\n\n[Area under the precision-recall curve: Point estimates](https://api.semanticscholar.org/CorpusID:37409855)\n[and confidence intervals. In ECML/PKDD.](https://api.semanticscholar.org/CorpusID:37409855)\n\n[Jiuhai Chen and Jonas Mueller. 2023. Quantifying un-](https://api.semanticscholar.org/CorpusID:263611057)\n[certainty in answers from any language model and](https://api.semanticscholar.org/CorpusID:263611057)\n[enhancing their trustworthiness.](https://api.semanticscholar.org/CorpusID:263611057)\n\nLingjiao Chen, Matei A. Zaharia, and James Y. Zou.\n[2023a. Frugalgpt: How to use large language mod-](https://api.semanticscholar.org/CorpusID:258564349)\n[els while reducing cost and improving performance.](https://api.semanticscholar.org/CorpusID:258564349)\n_ArXiv, abs/2305.05176._\n\nXinyun Chen, Renat Aksitov, Uri Alon, Jie Ren, Kefan Xiao, Pengcheng Yin, Sushant Prakash, Charles\n[Sutton, Xuezhi Wang, and Denny Zhou. 2023b. Uni-](https://api.semanticscholar.org/CorpusID:265498407)\n[versal self-consistency for large language model gen-](https://api.semanticscholar.org/CorpusID:265498407)\n[eration. ArXiv, abs/2311.17311.](https://api.semanticscholar.org/CorpusID:265498407)\n\nYanda Chen, Chen Zhao, Zhou Yu, Kathleen McKe[own, and He He. 2023c. On the relation between](https://doi.org/10.18653/v1/2023.findings-emnlp.12)\n[sensitivity and accuracy in in-context learning. In](https://doi.org/10.18653/v1/2023.findings-emnlp.12)\n_Findings of the Association for Computational Lin-_\n_guistics: EMNLP 2023, pages 155\u2013167, Singapore._\nAssociation for Computational Linguistics.\n\nYangyi Chen, Lifan Yuan, Ganqu Cui, Zhiyuan Liu,\n[and Heng Ji. 2023d. A close look into the calibra-](https://doi.org/10.18653/v1/2023.acl-long.75)\n[tion of pre-trained language models. In Proceedings](https://doi.org/10.18653/v1/2023.acl-long.75)\n_of the 61st Annual Meeting of the Association for_\n_Computational Linguistics (Volume 1: Long Papers),_\npages 1343\u20131367, Toronto, Canada. Association for\nComputational Linguistics.\n\nJeremy Cole, Michael Zhang, Daniel Gillick, Julian\nEisenschlos, Bhuwan Dhingra, and Jacob Eisenstein.\n[2023. Selectively answering ambiguous questions.](https://doi.org/10.18653/v1/2023.emnlp-main.35)\n\n\n-----\n\nIn Proceedings of the 2023 Conference on Empiri_cal Methods in Natural Language Processing, pages_\n530\u2013543, Singapore. Association for Computational\nLinguistics.\n\n[Leda Cosmides and John Tooby. 1996. Are humans](https://api.semanticscholar.org/CorpusID:18631755)\n[good intuitive statisticians after all? rethinking some](https://api.semanticscholar.org/CorpusID:18631755)\n[conclusions from the literature on judgment under](https://api.semanticscholar.org/CorpusID:18631755)\n[uncertainty. Cognition, 58:1\u201373.](https://api.semanticscholar.org/CorpusID:18631755)\n\nAngela Fan, Yacine Jernite, Ethan Perez, David Grang[ier, Jason Weston, and Michael Auli. 2019. ELI5:](https://doi.org/10.18653/v1/P19-1346)\n[Long form question answering. In Proceedings of](https://doi.org/10.18653/v1/P19-1346)\n_the 57th Annual Meeting of the Association for Com-_\n_putational Linguistics, pages 3558\u20133567, Florence,_\nItaly. Association for Computational Linguistics.\n\nTianyu Gao, Howard Yen, Jiatong Yu, and Danqi Chen.\n[2023. Enabling large language models to generate](https://doi.org/10.18653/v1/2023.emnlp-main.398)\n[text with citations. In Proceedings of the 2023 Con-](https://doi.org/10.18653/v1/2023.emnlp-main.398)\n_ference on Empirical Methods in Natural Language_\n_Processing, pages 6465\u20136488, Singapore. Associa-_\ntion for Computational Linguistics.\n\nTanya Goyal, Junyi Jessy Li, and Greg Durrett. 2022.\n\n[News summarization and evaluation in the era of](https://api.semanticscholar.org/CorpusID:252532176)\n[gpt-3. ArXiv, abs/2209.12356.](https://api.semanticscholar.org/CorpusID:252532176)\n\nChuan Guo, Geoff Pleiss, Yu Sun, and Kilian Q. Wein[berger. 2017. On calibration of modern neural net-](https://api.semanticscholar.org/CorpusID:28671436)\n[works.](https://api.semanticscholar.org/CorpusID:28671436) In International Conference on Machine\n_Learning._\n\n[Chirag Gupta and Aaditya Ramdas. 2021. Top-label](https://api.semanticscholar.org/CorpusID:240070283)\n[calibration and multiclass-to-binary reductions. In](https://api.semanticscholar.org/CorpusID:240070283)\n_International Conference on Learning Representa-_\n_tions._\n\nPengcheng He, Xiaodong Liu, Jianfeng Gao, and\nWeizhu Chen. 2020. Deberta: Decoding[enhanced bert with disentangled attention. ArXiv,](https://api.semanticscholar.org/CorpusID:219531210)\nabs/2006.03654.\n\nHidehito Honda, Rina Kagawa, and Masaru Shirasuna.\n[2022. On the round number bias and wisdom of](https://api.semanticscholar.org/CorpusID:248858577)\n[crowds in different response formats for numerical](https://api.semanticscholar.org/CorpusID:248858577)\n[estimation. Scientific Reports, 12.](https://api.semanticscholar.org/CorpusID:248858577)\n\nOr Honovich, Roee Aharoni, Jonathan Herzig, Hagai\nTaitelbaum, Doron Kukliansy, Vered Cohen, Thomas\nScialom, Idan Szpektor, Avinatan Hassidim, and\n[Yossi Matias. 2022. TRUE: Re-evaluating factual](https://doi.org/10.18653/v1/2022.naacl-main.287)\n[consistency evaluation. In Proceedings of the 2022](https://doi.org/10.18653/v1/2022.naacl-main.287)\n_Conference of the North American Chapter of the_\n_Association for Computational Linguistics: Human_\n_Language Technologies, pages 3905\u20133920, Seattle,_\nUnited States. Association for Computational Linguistics.\n\nJ. Edward Hu, Yelong Shen, Phillip Wallis, Zeyuan\nAllen-Zhu, Yuanzhi Li, Shean Wang, and Weizhu\n[Chen. 2021. Lora: Low-rank adaptation of large](https://api.semanticscholar.org/CorpusID:235458009)\n[language models. ArXiv, abs/2106.09685.](https://api.semanticscholar.org/CorpusID:235458009)\n\n\nSameer Jain, Vaishakh Keshava, Swarnashree\nMysore Sathyendra, Patrick Fernandes, Pengfei\nLiu, Graham Neubig, and Chunting Zhou. 2023.\n[Multi-dimensional evaluation of text summarization](https://doi.org/10.18653/v1/2023.findings-acl.537)\n[with in-context learning. In Findings of the Asso-](https://doi.org/10.18653/v1/2023.findings-acl.537)\n_ciation for Computational Linguistics: ACL 2023,_\npages 8487\u20138495, Toronto, Canada. Association for\nComputational Linguistics.\n\nZhengbao Jiang, Frank F. Xu, Jun Araki, and Graham\n[Neubig. 2020. How can we know what language](https://doi.org/10.1162/tacl_a_00324)\n[models know? Transactions of the Association for](https://doi.org/10.1162/tacl_a_00324)\n_Computational Linguistics, 8:423\u2013438._\n\nSaurav Kadavath, Tom Conerly, Amanda Askell, T. J.\nHenighan, Dawn Drain, Ethan Perez, Nicholas\nSchiefer, Zachary Dodds, Nova DasSarma, Eli TranJohnson, Scott Johnston, Sheer El-Showk, Andy\nJones, Nelson Elhage, Tristan Hume, Anna Chen,\nYuntao Bai, Sam Bowman, Stanislav Fort, Deep\nGanguli, Danny Hernandez, Josh Jacobson, John\nKernion, Shauna Kravec, Liane Lovitt, Kamal\nNdousse, Catherine Olsson, Sam Ringer, Dario\nAmodei, Tom B. Brown, Jack Clark, Nicholas Joseph,\nBenjamin Mann, Sam McCandlish, Christopher Olah,\n[and Jared Kaplan. 2022. Language models (mostly)](https://api.semanticscholar.org/CorpusID:250451161)\n[know what they know. ArXiv, abs/2207.05221.](https://api.semanticscholar.org/CorpusID:250451161)\n\n[Amita Kamath, Robin Jia, and Percy Liang. 2020. Se-](https://doi.org/10.18653/v1/2020.acl-main.503)\n[lective question answering under domain shift. In](https://doi.org/10.18653/v1/2020.acl-main.503)\n_Proceedings of the 58th Annual Meeting of the Asso-_\n_ciation for Computational Linguistics, pages 5684\u2013_\n5696, Online. Association for Computational Linguistics.\n\nJoonghoon Kim, Saeran Park, Kiyoon Jeong, Sangmin\nLee, Seung Hun Han, Jiyoon Lee, and Pilsung Kang.\n[2023. Which is better? exploring prompting strategy](https://api.semanticscholar.org/CorpusID:265043839)\n[for llm-based metrics. ArXiv, abs/2311.03754.](https://api.semanticscholar.org/CorpusID:265043839)\n\nLorenz Kuhn, Yarin Gal, and Sebastian Farquhar. 2023.\n\n[Semantic uncertainty: Linguistic invariances for un-](https://api.semanticscholar.org/CorpusID:257039062)\n[certainty estimation in natural language generation.](https://api.semanticscholar.org/CorpusID:257039062)\n_ArXiv, abs/2302.09664._\n\nZhen Li, Xiaohan Xu, Tao Shen, Can Xu, Jia-Chen\n[Gu, and Chongyang Tao. 2024. Leveraging large](https://api.semanticscholar.org/CorpusID:266999586)\n[language models for nlg evaluation: A survey. ArXiv,](https://api.semanticscholar.org/CorpusID:266999586)\nabs/2401.07103.\n\nPercy Liang, Rishi Bommasani, Tony Lee, Dimitris\nTsipras, Dilara Soylu, Michihiro Yasunaga, Yian\nZhang, Deepak Narayanan, Yuhuai Wu, Ananya Kumar, Benjamin Newman, Binhang Yuan, Bobby Yan,\nCe Zhang, Christian Cosgrove, Christopher D. Manning, Christopher R\u2019e, Diana Acosta-Navas, Drew A.\nHudson, E. Zelikman, Esin Durmus, Faisal Ladhak,\nFrieda Rong, Hongyu Ren, Huaxiu Yao, Jue Wang,\nKeshav Santhanam, Laurel J. Orr, Lucia Zheng,\nMert Yuksekgonul, Mirac Suzgun, Nathan S. Kim,\nNeel Guha, Niladri S. Chatterji, O. Khattab, Peter\nHenderson, Qian Huang, Ryan Chi, Sang Michael\nXie, Shibani Santurkar, Surya Ganguli, Tatsunori\nHashimoto, Thomas F. Icard, Tianyi Zhang, Vishrav\nChaudhary, William Wang, Xuechen Li, Yifan Mai,\n\n\n-----\n\n[Yuhui Zhang, and Yuta Koreeda. 2023. Holistic eval-](https://api.semanticscholar.org/CorpusID:253553585)\n[uation of language models. Annals of the New York](https://api.semanticscholar.org/CorpusID:253553585)\n_Academy of Sciences, 1525:140 \u2013 146._\n\nStephanie C. Lin, Jacob Hilton, and Owain Evans.\n[2022. Teaching models to express their uncertainty](https://api.semanticscholar.org/CorpusID:249191391)\n[in words. Trans. Mach. Learn. Res., 2022.](https://api.semanticscholar.org/CorpusID:249191391)\n\nZhen Lin, Shubhendu Trivedi, and Jimeng Sun. 2023.\n\n[Generating with confidence: Uncertainty quantifi-](https://api.semanticscholar.org/CorpusID:258967487)\n[cation for black-box large language models. Trans.](https://api.semanticscholar.org/CorpusID:258967487)\n_Mach. Learn. Res., 2024._\n\nYang Liu, Dan Iter, Yichong Xu, Shuohang Wang,\n[Ruochen Xu, and Chenguang Zhu. 2023a. G-eval:](https://doi.org/10.18653/v1/2023.emnlp-main.153)\n[NLG evaluation using gpt-4 with better human align-](https://doi.org/10.18653/v1/2023.emnlp-main.153)\n[ment. In Proceedings of the 2023 Conference on](https://doi.org/10.18653/v1/2023.emnlp-main.153)\n_Empirical Methods in Natural Language Processing,_\npages 2511\u20132522, Singapore. Association for Computational Linguistics.\n\nYinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis,\nLuke Zettlemoyer, and Veselin Stoyanov. 2019.\n[Roberta: A robustly optimized bert pretraining ap-](https://api.semanticscholar.org/CorpusID:198953378)\n[proach. ArXiv, abs/1907.11692.](https://api.semanticscholar.org/CorpusID:198953378)\n\nYixin Liu, Alex Fabbri, Pengfei Liu, Yilun Zhao, Linyong Nan, Ruilin Han, Simeng Han, Shafiq Joty,\nChien-Sheng Wu, Caiming Xiong, and Dragomir\n[Radev. 2023b. Revisiting the gold standard: Ground-](https://doi.org/10.18653/v1/2023.acl-long.228)\n[ing summarization evaluation with robust human](https://doi.org/10.18653/v1/2023.acl-long.228)\n[evaluation. In Proceedings of the 61st Annual Meet-](https://doi.org/10.18653/v1/2023.acl-long.228)\n_ing of the Association for Computational Linguistics_\n_(Volume 1: Long Papers), pages 4140\u20134170, Toronto,_\nCanada. Association for Computational Linguistics.\n\nSewon Min, Kalpesh Krishna, Xinxi Lyu, Mike Lewis,\nWen-tau Yih, Pang Koh, Mohit Iyyer, Luke Zettle[moyer, and Hannaneh Hajishirzi. 2023. FActScore:](https://doi.org/10.18653/v1/2023.emnlp-main.741)\n[Fine-grained atomic evaluation of factual precision](https://doi.org/10.18653/v1/2023.emnlp-main.741)\n[in long form text generation. In Proceedings of the](https://doi.org/10.18653/v1/2023.emnlp-main.741)\n_2023 Conference on Empirical Methods in Natural_\n_Language Processing, pages 12076\u201312100, Singa-_\npore. Association for Computational Linguistics.\n\nMatthias Minderer, Josip Djolonga, Rob Romijnders,\nFrances Ann Hubis, Xiaohua Zhai, Neil Houlsby,\nDustin Tran, and Mario Lucic. 2021. [Revisiting](https://api.semanticscholar.org/CorpusID:235435823)\n[the calibration of modern neural networks. ArXiv,](https://api.semanticscholar.org/CorpusID:235435823)\nabs/2106.07998.\n\nMahdi Pakdaman Naeini, Gregory F. Cooper, and Milos\n[Hauskrecht. 2015. Obtaining well calibrated proba-](https://api.semanticscholar.org/CorpusID:6292807)\n[bilities using bayesian binning. Proceedings of the](https://api.semanticscholar.org/CorpusID:6292807)\n_... AAAI Conference on Artificial Intelligence. AAAI_\n_Conference on Artificial Intelligence, 2015:2901\u2013_\n2907.\n\nRamesh Nallapati, Bowen Zhou, Cicero dos Santos,\n[\u00c7a\u02d8glar Gu[\u00b4]l\u00e7ehre, and Bing Xiang. 2016. Abstrac-](https://doi.org/10.18653/v1/K16-1028)\n[tive text summarization using sequence-to-sequence](https://doi.org/10.18653/v1/K16-1028)\n[RNNs and beyond.](https://doi.org/10.18653/v1/K16-1028) In Proceedings of the 20th\n_SIGNLL Conference on Computational Natural Lan-_\n_guage Learning, pages 280\u2013290, Berlin, Germany._\nAssociation for Computational Linguistics.\n\n\nIvan Stelmakh, Yi Luan, Bhuwan Dhingra, and Ming[Wei Chang. 2022. ASQA: Factoid questions meet](https://doi.org/10.18653/v1/2022.emnlp-main.566)\n[long-form answers. In Proceedings of the 2022 Con-](https://doi.org/10.18653/v1/2022.emnlp-main.566)\n_ference on Empirical Methods in Natural Language_\n_Processing, pages 8273\u20138288, Abu Dhabi, United_\nArab Emirates. Association for Computational Linguistics.\n\nKatherine Tian, Eric Mitchell, Huaxiu Yao, Christo[pher D. Manning, and Chelsea Finn. 2023a. Fine-](https://api.semanticscholar.org/CorpusID:265158181)\n[tuning language models for factuality.](https://api.semanticscholar.org/CorpusID:265158181) _ArXiv,_\nabs/2311.08401.\n\nKatherine Tian, Eric Mitchell, Allan Zhou, Archit\nSharma, Rafael Rafailov, Huaxiu Yao, Chelsea Finn,\n[and Christopher Manning. 2023b. Just ask for cali-](https://doi.org/10.18653/v1/2023.emnlp-main.330)\n[bration: Strategies for eliciting calibrated confidence](https://doi.org/10.18653/v1/2023.emnlp-main.330)\n[scores from language models fine-tuned with human](https://doi.org/10.18653/v1/2023.emnlp-main.330)\n[feedback. In Proceedings of the 2023 Conference](https://doi.org/10.18653/v1/2023.emnlp-main.330)\n_on Empirical Methods in Natural Language Process-_\n_ing, pages 5433\u20135442, Singapore. Association for_\nComputational Linguistics.\n\nHugo Touvron, Louis Martin, Kevin R. Stone, Peter\nAlbert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava,\nShruti Bhosale, Daniel M. Bikel, Lukas Blecher, Cristian Cant\u00f3n Ferrer, Moya Chen, Guillem Cucurull,\nDavid Esiobu, Jude Fernandes, Jeremy Fu, Wenyin\nFu, Brian Fuller, Cynthia Gao, Vedanuj Goswami,\nNaman Goyal, Anthony S. Hartshorn, Saghar Hosseini, Rui Hou, Hakan Inan, Marcin Kardas, Viktor\nKerkez, Madian Khabsa, Isabel M. Kloumann, A. V.\nKorenev, Punit Singh Koura, Marie-Anne Lachaux,\nThibaut Lavril, Jenya Lee, Diana Liskovich, Yinghai\nLu, Yuning Mao, Xavier Martinet, Todor Mihaylov,\nPushkar Mishra, Igor Molybog, Yixin Nie, Andrew\nPoulton, Jeremy Reizenstein, Rashi Rungta, Kalyan\nSaladi, Alan Schelten, Ruan Silva, Eric Michael\nSmith, R. Subramanian, Xia Tan, Binh Tang, Ross\nTaylor, Adina Williams, Jian Xiang Kuan, Puxin\nXu, Zhengxu Yan, Iliyan Zarov, Yuchen Zhang, Angela Fan, Melanie Kambadur, Sharan Narang, Aurelien Rodriguez, Robert Stojnic, Sergey Edunov, and\n[Thomas Scialom. 2023. Llama 2: Open foundation](https://api.semanticscholar.org/CorpusID:259950998)\n[and fine-tuned chat models. ArXiv, abs/2307.09288.](https://api.semanticscholar.org/CorpusID:259950998)\n\nMiao Xiong, Zhiyuan Hu, Xinyang Lu, Yifei Li, Jie Fu,\n[Junxian He, and Bryan Hooi. 2023. Can llms express](https://api.semanticscholar.org/CorpusID:259224389)\n[their uncertainty? an empirical evaluation of confi-](https://api.semanticscholar.org/CorpusID:259224389)\n[dence elicitation in llms. ArXiv, abs/2306.13063.](https://api.semanticscholar.org/CorpusID:259224389)\n\nCaiqi Zhang, Fangyu Liu, Marco Basaldella, and Nigel\n[Collier. 2024. Luq: Long-text uncertainty quantifica-](https://api.semanticscholar.org/CorpusID:268793903)\n[tion for llms. ArXiv, abs/2403.20279.](https://api.semanticscholar.org/CorpusID:268793903)\n\nTianyi Zhang, Faisal Ladhak, Esin Durmus, Percy Liang,\nKathleen McKeown, and Tatsunori Hashimoto. 2023.\n[Benchmarking large language models for news sum-](https://api.semanticscholar.org/CorpusID:256416014)\n[marization. Transactions of the Association for Com-](https://api.semanticscholar.org/CorpusID:256416014)\n_putational Linguistics, 12:39\u201357._\n\nLianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan\nZhuang, Zhanghao Wu, Yonghao Zhuang, Zi Lin,\nZhuohan Li, Dacheng Li, Eric P. Xing, Haotong\n\n\n-----\n\n[Zhang, Joseph Gonzalez, and Ion Stoica. 2023. Judg-](https://api.semanticscholar.org/CorpusID:259129398)\n[ing llm-as-a-judge with mt-bench and chatbot arena.](https://api.semanticscholar.org/CorpusID:259129398)\n_ArXiv, abs/2306.05685._\n\n### A Dataset\n\n**ASQA (Answer Summaries for Questions which**\nare Ambiguous) (Stelmakh et al., 2022) is a\nspecialized long-form factoid dataset, designed\nto address ambiguous factoid questions that\nyield different correct answers based on their\ninterpretations. This dataset challenges models\nto synthesize factual information from multiple\nsources, creating coherent long-form summaries\nthat effectively resolve the inherent ambiguities in\nthese questions.\n\n**ELI5 (Fan et al., 2019) is a comprehensive**\nopen-ended long-form dataset, encompassing over\n270,000 threads from the Reddit forum \u201cExplain\nLike I\u2019m Five.\u201d This unique platform features\ncommunity-generated responses to a wide array of\nquestions, all tailored to be easily understandable\nby a five-year-old audience. The majority of\nqueries in ELI5 are centered around \u2019how,\u2019\n\u2019why,\u2019 and \u2019what\u2019 questions, which necessitate\ncomprehensive, detailed responses supported by\nevidence from multiple passages.\n\n**QAMPARI (Amouyal et al., 2022) is a fac-**\ntoid dataset where answers are presented as lists of\nentities dispersed across multiple paragraphs. Its\nconstruction involves an automated process that\nutilizes Wikipedia knowledge graphs and tables.\nQuestions are manually paraphrased, and answers\nare thoroughly verified for accuracy. Notably,\neach question in QAMPARI is associated with an\naverage of 13 answers, demonstrating its breadth.\n\n**CNNDM (Nallapati et al., 2016) is a large-**\nscale news summarization dataset containing\nnews articles from CNN[1] and DailyMail[2]. The\noriginal CNNDM dataset consists of both source\nnews articles and reference summaries. However, recent work (Liu et al., 2023b; Zhang\net al., 2023) has found that the provided reference summaries are not of very good quality\nand zero-shot LLMs summaries are preferred\nby human annotators over the reference summaries.\n\nIn the **ACLE** (Automatic LLMs\u2019 Citation\n\n[1https://www.cnn.com/](https://www.cnn.com/)\n[2https://www.dailymail.co.uk/](https://www.dailymail.co.uk/)\n\n\nEvaluation) (Gao et al., 2023), a pioneering benchmark for assessing LLMs\u2019 citation capabilities, a\nsubset of 1,000 examples is randomly selected\nfrom the development sets of ASQA, ELI5, and\nQAMPARI to form a test set for each task. For our\nspecific analysis, we choose to utilize the first 500\nexamples from each of these datasets in ACLE as\nour test set, providing a focused and representative\nsample for each task. For CNNDM, we utilize 100\nexamples as our test set.\n\n### B Self-consistency\n\nWe propose four different self-consistency based\nmethods tailored for long-form generation, each\nwith a different strategy to measure the similarity\nbetween two long-form answer.\n\n**Naive The most basic approach utilizes an**\nadditional LLM (GPT-3.5-turbo in our experiments, which can be replaced by other models\ntrained for this task) to determine if two responses\nare akin, assigning a corresponding similarity\nscore. This method diverges from the relevant\ntechnique in contemporary research (Chen et al.,\n2023b), which primarily focuses on identifying\nthe most consistent answer. Instead, our approach\naims to secure specific consistency ratings that\nreflect the model\u2019s assurance in its primary answer,\noffering a general overview of the answers\u2019\nsimilarity. The template for similarity measuring\ncan be found in Appendix F.4.\n\n**Sentence Split For a more detailed similar-**\nity analysis between the two answers, we split the\nfirst answer into individual sentences. Another\nLLM (GPT-3.5-turbo or a similar NLI model) is\nthen used to evaluate whether similar statements\nare present in the second answer. This method\u2019s\nlimitation is that not all sentences carry equal\ninformational weight. Some may be filler or less\ninformative, potentially skewing the similarity\nassessment. The template can be found in\nAppendix F.4.\n\n**Claim To further refine the approach,** we\nfocus on sentences that make factual claims. This\ninvolves two steps: first, using a claim detector\nto identify factual claims within a sentence and\nthen using an NLI model to determine if similar\nfactual claims exist in the second answer. This\nmethod operates under the assumption that factual\n\n\n-----\n\nclaims are the most critical components of an\nanswer, representing its core information. We\nleverage a DeBERTa-V2 (He et al., 2020) trained\nby ClaimBuster as our fact detector and GPT-3.5\nas the NLI models.\n\n**Named** **Entity** **Recognition** Advancing the\ngranularity further, we compare named entities\nbetween two responses. We identify and compare\nentities present in both answers by utilizing a\nnamed entity recognition model. The degree of\noverlap in these entities serves as an indicator of\nanswer similarity. This approach focuses more on\nconcrete, identifiable elements within the answers.\nWe use a Roberta-large (Liu et al., 2019) trained\nwith SpanMarker framework [3], which can be\nreplaced by other NER models.\n\n### C Evaluation Metric\n\n**C.1** **GPT-4 metric**\n\nWe ask GPT-4 to range an answer from 0 (worst)\nto 5 (best), which is then normalized to [0, 1]. See\nAppendix F.1 for details of the template. To mitigate scoring variability from criteria ambiguity and\nLLM uncertainty, we have evaluators repeatedly\nscore each answer, forming a score distribution that\nbetter reflects its correctness. Specifically, given\nan LLM evaluator, N evaluations from it, and a\n_E_\nscore x [0, 1], the correctness distribution is:\n_\u2208_\n\n\nexact substrings of the generated content, following\nestablished methodologies. For ELI5, we utilize\nthe most precise automatic metric to date, claim re_call, employing the TRUE (Honovich et al., 2022)_\nnatural language inference model to ascertain if the\ngenerated output encompasses the sub-claims of\nthe reference answer.\nWe present the task criteria to humans and ask\nthem to provide a score for each answer based\non the criteria. Participants are provided with a\nreference answer\u2014not as an exclusive ground truth\nbut as a guide\u2014and are permitted to use search\nengines for additional context. We enlisted three\nannotators to evaluate 75 samples each for ASQA\nand ELI5, and calculate the average of them as a\nhuman score. Our analysis compares these human\nscores with those generated by task-specific metrics\nand GPT-4. The results, as detailed in our Table 4,\nunderscore GPT-4\u2019s closer alignment with human\njudgments in both ASQA and ELI5. As shown in\nFigure 12, as the task becomes more open-ended\nlike Eli5, the human agreements become lower than\nthe factoid dataset ASQA. This further evidence\nthe assumption that the correctness of a long-form\nanswer should be a distribution.\n\n**ASQA** **ELI5**\n**Metric** **EM** **GPT-4** **Claim** **GPT-4**\n\nCorr \u2191 47.8 76.2 42.9 71.5\nMAE \u2193 43.0 12.9 52.0 9.1\n\nTable 4: Comparison of Human, Task-Specific metric,\nand GPT-4 Correctness Distributions in ASQA and ELI5\nTasks. Results are with %. \u2018Corr\u2019 denotes Pearson\ncorrelation (the higher the better), \u2018MAE\u2019 denotes mean\nabsolute error (the lower the better). \u2018EM\u2019 denotes EMrecall, and \u2018Claim\u2019 denotes Claim-recall.\n\n### D Main Experiment\n\nWe assess the calibration of variously sized models\n(Llama-2-13b, Llama-2-70b, Vicuna-13b, GPT-3.5turbo) across three long-form QA datasets (ASQA,\nELI5, QAMPARI) and one summarization dataset\n(CNNDM). The process involves several steps: 1.\nGeneration: Asking the model to generate answers\nfor questions in the dataset 2. Correctness Assessment: We utilize GPT-4 to evaluate the correctness of the models\u2019 answers, except for QAMPARI, where we directly apply the F1-5 metric. 3.\nConfidence Distribution Derivation: After generating answers, models employ self-evaluation or\nself-consistency methods to derive their confidence\n\n|Metric|ASQA EM GPT-4|ELI5 Claim GPT-4|\n|---|---|---|\n\n|Corr \u2191 MAE \u2193|47.8 76.2 43.0 12.9|42.9 71.5 52.0 9.1|\n|---|---|---|\n\n\n_PTi(x) = N[1]_\n\n\n_N_\n\ufffd\n\n1(E(Ai)j = x) (12)\n_j=1_\n\n\n**C.2** **Human Evaluation**\n\nWe utilize GPT-4 to assess answers across different tasks, including ASQA, ELI5, and CNNDM,\nusing GPT-4 scores as a proxy for the target distribution. To demonstrate the better alignment of\nGPT-4 scores with human preferences over taskspecific metrics, we focus our human evaluation\nefforts on the long-form tasks of ASQA and ELI5.\nThis approach is supported by prior research indicating GPT-4\u2019s congruence with human judgments on summarization tasks (Liu et al., 2023a),\nthereby obviating the need for manual evaluation of\nCNNDM. Following Gao et al. (2023), in ASQA,\nwe adopt the EM-recall automatic metric, which\ngauges the recall of correct short answers by verifying if the dataset\u2019s provided short answers are\n\n[3https://github.com/tomaarsen/SpanMarkerNER](https://github.com/tomaarsen/SpanMarkerNER)\n\n\n-----\n\n1.00\n\n0.95\n\n\n1.0\n\n0.9\n\n\n0.90\n\n0.85\n\n\n0.8\n\n0.7\n\n\n0.80\n\n0.75\n\n\n0.6\n\n0.5\n\n\n0.14\n\n0.12\n\n0.10\n\n0.08\n\n0.06\n\n0.04\n\n0.02\n\n0.00\n\n0.12\n\n|1.00|0.90|0.72|\n|---|---|---|\n|0.90|1.00|0.72|\n|0.72|0.72|1.00|\n\n|1.00|0.75|0.56|\n|---|---|---|\n|0.75|1.00|0.49|\n|0.56|0.49|1.00|\n\n|0.00|0.08|0.12|\n|---|---|---|\n|0.08|0.00|0.15|\n|0.12|0.15|0.00|\n\n\nAnnotator 1 Annotator 2 Annotator 3\n\n\nAnnotator 1 Annotator 2 Annotator 3\n\n\nFigure 6: Correlation for ASQA\n\n1.0\n\n\nFigure 7: Cohen Kappa for ASQA\n\n1.0\n\n\nAnnotator 1 Annotator 2 Annotator 3\n\nFigure 8: MAE for ASQA\n\n\n0.9\n\n0.8\n\n\n0.8\n\n0.6\n\n\n0.10\n\n0.08\n\n\n0.7\n\n\n0.06\n\n0.04\n\n\n0.6\n\n0.53 0.42 1.00 0.5\n\n\n0.4\n\n0.2\n\n\n0.0\n\n\n0.02\n\n0.00\n\n|1.00|0.72|0.53|\n|---|---|---|\n|0.72|1.00|0.42|\n|0.53|0.42|1.00|\n\n|1.00|0.41|0.27|\n|---|---|---|\n|0.41|1.00|-0.02|\n|0.27|-0.02|1.00|\n\n|0.00|0.09|0.12|\n|---|---|---|\n|0.09|0.00|0.14|\n|0.12|0.14|0.00|\n\n\nAnnotator 1 Annotator 2 Annotator 3\n\nFigure 9: Correlation for ELI5\n\n\nAnnotator 1 Annotator 2 Annotator 3\n\nFigure 10: Cohen Kappa for ELI5\n\n\nAnnotator 1 Annotator 2 Annotator 3\n\nFigure 11: MAE for ELI5\n\n\nFigure 12: Pairwise annotator agreements for ASQA and ELI5 respectively\n\n\ndistribution. 4. Calibration Measurement: .\n\n**D.1** **Generation**\n\n\nIn the answer generation phase, we employ a 3-shot\nin-context learning approach for each long-form\nQA dataset, providing three exemplars to guide\nthe models. For the CNNDM dataset, we adopt a\n0-shot strategy, aligning with prior studies (Goyal\net al., 2022). The generation of answers utilizes\na top-K sampling method, setting the generation\ntemperature for all models at 0.6 and the top-K\nparameter at 10.\n\n**D.2** **Correctness Evaluation**\n\n\nas answers, we determine that F1 scores provide a\nmore suitable measure of correctness than GPT-4\nevaluations. To this end, we adopt the F1-5 metric\n(Gao et al., 2023), computing the F1 score based\non direct matches with the correct answer list and\nassigning a recall of 100% for responses containing\nat least five accurate answers (recall-5).\n\n**D.3** **Confidence Elicitation**\n\n\nFor ASQA, ELI5, CNNDM, we ask the GPT-4 to\nevaluate the correctness of examples. For ASQA\nand ELI5, We ask GPT-4 to evaluate the answer\nthree times, producing a distribution capturing criteria ambiguity and model\u2019s inherent subjectivity.\nHowever, for CNNDM, we only ask GPT-4 to evaluate once to save computation given that most\nanswers correctness concentrates around 0.8 with\nsmall variance. The GPT-4 evaluation template can\nbe found in Appendix F.1 and criteria for different\ntasks can be found in Appendix F.2. For QAMPARI, which involves generating a list of entities\n\n\nAfter getting the answer from the model, we\nleverage the self-evaluation or self-consistency\nmethod to derive confidence distribution from the\nmodel.\n\n**Self-Evaluation** We prompt the model to\nself-evaluate an answer 10 times, creating a\nconfidence distribution based on its self-evaluation\nscores. Each self-evaluation includes task instructions, grading criteria, and evaluation examples\n(three for all long-form QA datasets and one for\nCNNDM due to length constraints). Additionally,\nit contains specific instructions for self-evaluation,\nincorporating both the question and the answer\nunder evaluation. The detailed self-evaluation\ntemplate and criteria are available in Appendix F.3\nand Appendix F.2 respectively.\n\n\n-----\n\n**Self-consistency** In the self-consistency approach, we generate an answer to the same\nquestion 10 times, designating the first response as\nthe primary answer. We then calculate similarity\nscores between the primary answer and the\nremaining responses. These scores collectively\ncreate the model\u2019s confidence distribution for the\nprimary answer. For various datasets, tailored\nstrategies are employed to compare similarities\nbetween two answers.\nFor ASQA, we employ a self-consistency-claim\napproach. To assess the similarity between the two\nanswers, we first identify factual claims in the first\nanswer using a ClaimBuster-trained DeBERTa V2\n(He et al., 2020) claim detector. We then verify\nthe presence of these claims in the second answer\nthrough NLI. The similarity score is the average\npresence of factual claims across answers.\nIn QAMPARI, self-consistency-NER is used to\ndetermine confidence distribution. As the answers\nare entity lists, we extract entities by separating\ncommas. The similarity score is calculated based\non the proportion of overlapping entities between\ntwo answers, relative to the total entities in the first\nanswer.\nFor ELI5, where answers provide easily understandable explanations, we focus on the overall\ncontent. Here, we apply a self-consistency-naive\nmethod, assign a similarity score to each answer\npair with simple prompting.\nIn CNNDM, where answers are summaries highlighting key points of an article, we gauge the similarity between two answers by evaluating the overlap of key points. To achieve this, we implement\nthe self-consistency-split method. We dissect the\nfirst answer into individual sentences and then use\nNLI to determine if each sentence is present in\nthe second answer. The similarity score is derived\nby averaging the presence of these segmented sentences in the comparative answer.\n\n### E Improving Calibration\n\n**E.1** **Fine-tuning**\n\nIn our study, we focus on improving model\ncalibration on the ASQA dataset. We explore\nthree different strategies: fine-tune the model to\ndo self-evaluation (Input: question and model\u2019s\nanswer; Output: answer\u2019s score and explanation),\nfine-tune the model to do generation (Input:\nquestion; Output: answer), and a hybrid of both.\n\n\n**Data We generate a self-evaluation training**\ndataset with GPT-4, which evaluates different\nmodels responses to questions drawn from ASQA\ntraining set. This dataset comprises inputs of\nquestions and corresponding model answers, with\noutputs including a score and an explanation\nfor each answer. We create the self-evaluation\ndata in two steps. The initial phase involves the\ncreation of a diverse answer pool. This is achieved\nby employing a suite of models with varying\ncomputational capacities, including Llama-2-7b,\nLlama-2-13b, Llama2-70b, Vicuna-13b, and\nChatGPT. Each model generates responses to a\nspectrum of questions drawn from the training\nset of ASQA task, ensuring the resultant answer\npool encompasses a broad quality spectrum, from\nlow to high. Subsequently, we employ GPT-4\nto critically assess these answers, assigning a\nscore and providing a corresponding explanation\nfor its evaluation. This process yields a rich\ndataset, each instance of which encompasses a\nquestion, a model-generated answer, an evaluative\nscore, and a justification for that scoring. This\napproach results in a comprehensive dataset\nwith 2,000 self-evaluation examples (1,800 for\ntraining and 200 for validation), each including\na question, model-generated answer, score, and\njustification. For generation data, we use 80%\nof training ASQA\u2019s dataset (4,353 examples) for\ntraining and the remaining 20% for validation. The\nhybrid dataset combines the self-evaluation and\ngeneration training sets, using the self-evaluation\nvalidation set for assessment.\n\n**Training** **and** **Results** Regarding training,\nwe fine-tune Llama2-13b-chat model using LORA\non this dataset. We maintain consistent parameters\nacross all scenarios: a learning rate of 5e-6, five\nepochs, 100 warm-up steps, and a total batch size\nof 4 (achieved through 4 gradient accumulation\nsteps across four GPUs, with a batch size of 1 per\ndevice). As Table 3 reveals, solely training on selfevaluation (\u2018Evaluation\u2019) did not yield consistent\nimprovements in calibration, possibly due to the\ncomplexity of this task, as well as the limitation\nof LORA fine-tuning. Nonetheless, fine-tuning\nthe model improves the self-consistency method,\nespecially when the generation data is included\nduring training (\u2018Eval + Gen\u2019 and \u2018Generation\u2019).\nThe model becomes more confident in terms of\nself-consistency after fine-tuning.\n\n\n-----\n\n**E.2** **Source Documents**\n\nWe investigate the effect of additional context on\nLLM calibration, focusing on self-consistency confidence with Llama-2-13b-chat and GPT-3.5-turbo\nmodels on the ASQA dataset. We test the model\u2019s\nperformance when supplemented with two different types of source documents: random documents\nrelated to the question and \u2018oracle\u2019 documents directly relevant to the answers, as included in the\ndataset release (Stelmakh et al., 2022). Findings in\nTable 5 reveal that Oracle documents can enhance\nmodel performance and calibration across two out\nof three metrics for both models, while random documents are less effective. These results underscore\nthe importance of relevant contextual information\nin model calibration.\n\n\nCalibration Scores vs. Weight Variation\n\n60\n55\n50\n45\n40\n0 0.2 0.4 0.6 0.8 1\n\n\n70\n50\n30\n10\n\n\n0 0.2 0.4 0.6 0.8 1\n\n_\u03b1_\n\n\n**Model** **Doc** **Corr** **ECE-M** **F10.8** **Score**\n\nN 48.0\u2212 15.9\u2191 3.6\u2212 51.3\u2212\nLlama213b R 39.0 \u2193 14.8\u2193 30.6 \u2191 59.6 \u2191\n\nO 49.5 \u2191 17.5\u2191 20.1 \u2191 65.8 \u2191\n\nN 30.5\u2212 26.7\u2191 58.4\u2212 72.6\u2193\nGPT-3.5turbo R 36.6 \u2191 26.4\u2193 68.2 \u2191 64.8 \u2193\n\nO 27.0 \u2193 24.9\u2193 72.8 \u2191 75.8 \u2191\n\nTable 5: How source documents affect the calibration\nscore. In the document column, \u201cN\u201d means no documents in the input prompt, \u201cR\u201d means randomly selected\ndocuments relevant to the topic, and \u201cO\u201d means the oracle documents relevant to the answer. denotes that\n_\u2191_\nthe calibration score goes up when adding documents,\nwhile means going down. For ECE-M it\u2019s opposite.\n_\u2193_\n\n\nFigure 13: Hybrid confidence elicitation\n\n### F Prompts\n\n\n**E.3** **Hybrid Confidence Elicitation**\n\nWe explore whether combining self-evaluation and\nself-consistency can yield a more accurate confidence distribution on ASQA dataset. By blending confidence distributions from self-evaluation\n(Ci[eval]) and self-consistency (Ci[consist]) into a hybrid distribution Ci[hybrid] = _\u03b1Ci[eval]_ + (1 \u2212\n_\u03b1)Ci[consist], we adjust their relative contributions_\nusing \u03b1. As shown in Figure 13, we observe that\nthe correlation between confidence and correctness\ninitially increases but then declines as \u03b1 varies from\n0 to 1. However, this trend doesn\u2019t extend to other\nmetrics like F1, indicating that while hybrid calibration elicitation may enhance calibration in terms\nof correlation, it may not have the same impact on\nother dimensions.\n\n\nThis section introduces the prompts used for our\nexperiments.\n\n**F.1** **Correctness Evaluation Template**\n\n\nSimilar to contemporary work (Kim et al., 2023),\nour evaluation template for GPT-4 evaluation to\nget the target correctness distribution of an answer\nincludes four components: a clear task description,\nexpertly crafted evaluation criteria for objectivity,\ndemonstrations with a variety of answer qualities\n(best, worst, intermediate) each with a score and\nrationale, and specific evaluation instructions for\nthe LLM, encompassing the question-answer pair\nto be evaluated and a reference answer.\n\n\n-----\n\nEvaluation Template\n\n{task instruction}\n\nYou will be given a question, a reference answer, and a student\u2019s answer. Please evaluate the\nstudent\u2019s answer based on both your knowledge and\nthe reference answer, and provide a score from 0-5 to\nthe student\u2019s answer. Keep in mind that the reference\nanswer is not the sole correct response. Assess for\nboth factual accuracy and relevance to the question.\nThe following are the scoring criterion:\n\n{criterion}\n\nHere are some examples.\n\n{examples}\n\nNow it\u2019s your turn.\n\nQuestion: {question}\n\nReference answer: {reference answer}\n\nStudent\u2019s answer: {answer}\n\nNow please provide your score about this answer in the format of \u201cScore: <Your score>/5\u201d and\ngive your explanation.\n\n\nASQA Criterion\n\n5 - Completely Correct and Highly Relevant: The\nanswer fully addresses the question, resolves the ambiguity, and provides a well-rounded resolution. All\nfacts presented in the answer are accurate and relevant.\n4 - Mostly Correct and Relevant: The answer is very\nrelevant and addresses the ambiguity well, but might\nhave a minor oversight or inaccuracy. All the facts\npresented are accurate and relevant, or with only minor errors.\n3 - Partially Correct and Relevant: The answer is generally on topic and attempts to address the ambiguity,\nbut there might be inaccuracies or omissions. The\nmajority of the facts are correct, with a few errors.\n2 - Flawed but Somewhat Relevant: The answer\nsomewhat addresses the topic but does not fully explore the question\u2019s ambiguity or does not provide a\ncomplete resolution. The facts presented are a mix\nof correct and incorrect information, with about half\nbeing accurate.\n1 - Mostly Incorrect or Mostly Irrelevant: The answer\nslightly touches upon the topic but misses the main\npoint. The majority of the facts presented are incorrect, with only a small portion being accurate.\n0 - Completely Incorrect or Completely Irrelevant:\nThe student\u2019s answer is completely off-topic, not related to the question at all, or contains only incorrect\ninformation.\n\n\n**ELI5 Criterion**\n\n\n**F.2** **Criteria**\n\nBelow are the criteria for various tasks, with a\nspecial note that the CNNDM summarization task\nutilizes a distinct evaluation template.\n\n**ASQA Criterion**\n\n\nELI5 Criterion\n\n5 - Perfectly Addressed, Accurate and Clarity: The\nanswer flawlessly addresses the question with exceptional accuracy and clarity. It simplifies complex\nconcepts effectively and does so in a way that is captivating and memorable.\n4 - Accurate and clear: The answer is accurate, relevant to the question, and presented in a way that is\nengaging and understandable. It simplifies complex\nconcepts effectively but may miss a small opportunity\nfor further clarification or engagement.\n3 - Moderately Accurate and Understandable: The\nanswer is mostly accurate and somewhat understandable. It addresses the question reasonably well but\nmay lack detail or contain some inaccuracies. It may\nuse complex terms or concepts that are not broken\ndown into simpler ideas.\n2 - Relevant but Lacks Clarity or Accuracy: The answer is related to the question but lacks clarity or\ncontains partial inaccuracies. It attempts to simplify\nthe idea but does not do so effectively, leaving room\nfor confusion or misunderstanding.\n1 - Significantly Flawed: The answer addresses the\nquestion to a minimal extent but contains significant\ninaccuracies or misleading information. It might\nshow a basic attempt to simplify the concept but fail\nin accuracy or relevance.\n0 - Completely Inaccurate or Irrelevant: The answer\nis entirely off-topic, irrelevant, or factually incorrect.\nIt fails to address the question and does not simplify\ncomplex ideas.\n\n\n-----\n\nQAMPARI Criterion\n\n- Estimated Accuracy Assessment (0-3 Points)\n\n- 3 Points: All answers provided seem correct based\non available knowledge.\n\n- 2 Points: Majority of the answers seem correct.\n\n- 1 Point: Some answers are correct, but there are\nnotable inaccuracies.\n\n- 0 Points: No answers seem correct or very high\ndegree of inaccuracy.\n\n- Estimated Completeness Assessment (0-2\nPoints)\n\n- 2 Points: The response seems comprehensive,\ncovering a broad range of known or expected correct\nanswers.\n\n- 1 Point: The response covers some correct answers\nbut misses significant known or expected answers.\n\n- 0 Points: The response is highly incomplete,\nmissing most of the known or expected correct\nanswers.\n\n- Total Score (0-5 Scale)\n\n- Add the points from Estimated Accuracy and\nEstimated Completeness.\n\n\n**F.3** **Self-Evaluation Template**\n\n\nSelf Evaluation Template\n\n{task instruction}\n\nYou will be given a question and a student\u2019s\nanswer. Please evaluate the student\u2019s answer, and\nprovide a score from 0-5 to the student\u2019s answer\nbased on the following scoring criterion:\n\n{criterion}\n\nHere are some examples.\n\n{examples}\n\nNow it\u2019s your turn.\n\nQuestion: {question}\n\nAnswer: {answer}\n\nNow please provide your score about this answer in the format of \u201cScore: <Your score>/5\u201d and\ngive your explanation. Assess for both factual\naccuracy and relevance to the question.\n\n\nSummarization Evaluation Template\n\nYou will be given one summary written for a news\narticle.\n\nYour task is to rate the overall quality of the\nsummary with a score from 0 to 5, where 0 is the\nlowest and 5 is the highest.\n\nPlease make sure you read and understand\nthese instructions carefully. Please keep this document open while reviewing, and refer to it as needed.\n\nEvaluation Steps:\n1. Read the news article carefully and identify the\nmain topic and key points.\n2. Read the summary and compare it to the news\narticle. Check if the summary covers the main topic\nand key points of the news article, and if it presents\nthem in a clear and logical order.\n3. Assign a score for the summary quality on a scale\nof 0 to 5, where 0 is the lowest and 5 is the highest.\n\nTask Input:\n\nArticle: {article}\n\nSummary: {summary}\n\nNow please provide your score of the summary in the format of \u201cScore: <Your score>/5\u201d and\ngive your explanation.\n\n\n**F.4** **Self-Consistency Template**\nIn self-consistency approaches, assessing the similarity between two answers requires the use of an additional LLM\nin naive and split/claim methods. For the self-consistencynaive method, this involves an LLM directly providing similarity scores for the pair of answers. Meanwhile, for the\nself-consistency-split/claim method, another LLM is tasked\nwith detecting the presence of sentences from answer 1 in\nanswer 2. The templates for both the naive method and the\nsplit/claim method are outlined below.\n\nSimilarity Comparison Naive Template\n\nYou will be presented with a question followed by\ntwo answers. Evaluate how similar these answers are,\nconsidering their amount of information provided,\nfactual content, effectiveness in addressing the question, format and organization. Conclude by providing\nan integer similarity score between 0 and 5.\nQuestion: {question}\nAnswer 1: {answer1}\nAnswer 2: {answer2}\nNow please give your similarity score in the format\nof \u201cSimilarity score: <Your score>/5\u201d and give your\nexplanation. Make your answer short and concise.\n\nSimilarity Comparison Split Template\n\nYou will receive a sentence and a response; please\nascertain if a similar statement is present in the response.\nSentence: {sentence}\nResponse: {response}\nVerify if the response contains a statement resembling\nthe target sentence. Answer yes or no.\n\n### G Qualitative Analysis\n\nWe showcase successful and failed calibration examples on\nQampari and ASQA with self-consistency method.\n\n\n-----\n\n**type** **content**\n\n\n**QAMPARI Successful Example 1**\n\n\n_Question_ Who directed a film that had P. Balachandran as a screenwriter?\n_Answer_ Kamal, P. Balachandran, T. K. Rajeev Kumar, V. K. Prakash, Rajeev Ravi.\n_Model Answer_ Adu, Ammayum Muyalum, Bhoothakkannadi, Chattambi, Kakkakku Pinnaka...\n\n_Other Answer 1_ Agraharathile Kazhuthai, Kaliyugam, Kodungallur, Kodiyettam ...\n_Other Answer 2_ Kodiyettam, Kuttyedam, Oru CBI Diary Kurippu...\n_Other Answer 3_ Aravindan, K.G. George, John Abraham, Shyam Benegal ...\n_..._ ...\n_Self-consistency scores_ [0, 0, 0, ...] (%)\n\n_Correctness_ Score: 0% Distribution: {0 : 1.0}\n_Confidence score_ Score: 0% Distribution: {0 : 1.0}\n\n\n**QAMPARI Successful Example 2**\n\n\n_Question_ Which cities or municipalities are located in the province of Basilan?\n_Answer_ Akbar, Al-Barka, Hadji Muhtamad, Isabela City, Lamitan, Lantawan, Maluso, Sumisip, TabuanLasa, Tipo-Tipo, Tuburan, Ungkaya Pukan.\n_Model Answer_ Al-Barka, Basilan, Isabela, Lamitan, Tipo-Tipo, Maluso, Sumisip.\n\n_Other Answer 1_ Basilan, Isabela, Lamitan, Lantawan, Tipo-Tipo, Sumisip.\n_Other Answer 2_ Basilan, Tipo-Tipo, Isabela City, Maluso, Sumisip, Tuburan.\n_Other Answer 3_ Basilan, Isabela, Tipo-Tipo, Lamitan, Sumisip, Al-Barka, Maluso, Tuburan.\n_..._ ...\n_Self-consistency scores_ [71.4, 57.1, 85.7, ...](%)\n\n_Correctness_ Score: 83.3% Distribution: {0.8 : 1.0}\n_Confidence_ Score: 76.2% Distribution: {0.6 : 0.11, 0.8 : 0.78, 1.0 : 0.11}\n\n\n**QAMPARI Failed Example 1 (Under Confident)**\n\n\n_Question_ What city or municipality located in the Philipines are in the Tarlac province?\n_Answer_ Anao, Bamban, Camiling, Capas, Concepcion, Gerona, La Paz, Mayantoc, Moncada, Paniqui,\nPura, Ramos, San Clemente, San Jose, San Manuel, Santa Ignacia, Tarlac City, Victoria.\n_Model Answer_ Capas, Concepcion, Gerona, La Paz, Mayantoc, Paniqui, San Jose, Santa Ignacia, Tarlac City,\nVictoria.\n\n_Other Answer 1_ Capas, Concepcion, Camiling, Tarlac City, Paniqui, San Jose, Santa Lucia, Victoria.\n_Other Answer 2_ Capas, Tarlac, Concepcion, Tarlac, Gerona, Tarlac, La Paz, Tarlac, Paniqui, Tarlac, San Jose,\nTarlac, Tarlac City.\n_Other Answer 3_ Capas, Concepcion, Camiling, Tarlac City, San Jose.\n_..._ ...\n_Self-consistency scores_ [60, 60, 30, ...](%)\n\n_Correctness_ Score: 100% Distribution: {1 : 1.0}\n_Confidence_ Score: 51.1% Distribution: {0.4 : 0.56, 0.6 : 0.33, 0.8 : 0.11}\n\n\n**QAMPARI Failed Example 1 (Over Confident)**\n\n\n_Question_ What are some notables mailing list softwares ?\n_Answer_ Dada Mail, Discourse, GNU Mailman, GroupServer, LISTSERV, Majordomo, Organic Groups\nMailing List, Sympa.\n_Model Answer_ Mailchimp, Constant Contact, Campaign Monitor, AWeber, GetResponse, MailPoet, Sendinblue,\nMailerLite, Klaviyo, ConvertKit.\n\n_Other Answer 1_ Mailchimp, AWeber, GetResponse, Campaign Monitor, Constant Contact, Klaviyo, ConvertKit,\nMailPoet, Mailster, Sendinblue, MailerLite.\n_Other Answer 2_ Mailchimp, Constant Contact, AWeber, Campaign Monitor, GetResponse, Klaviyo, MailPoet,\nMailster, Sendinblue, MailerLite, ConvertKit, ActiveCampaign, and Constant Contact.\n_Other Answer 3_ Mailchimp, AWeber, GetResponse, Campaign Monitor, MailerLite, Constant Contact, Klaviyo,\nConvertKit, Sendinblue, and Emma.\n_..._ ...\n_Self-consistency scores_ [100, 100, 90, ...](%)\n\n_Correctness_ Score: 0% Distribution: {0 : 1.0}\n_Confidence score_ Score: 97.8% Distribution: {0.8 : 0.22, 1.0 : 0.78}\n\nTable 6: Examples for QAMPARI\n\n\n-----\n\n**type** **content**\n\n\n**ASQA Successful Example 1**\n\n\n_Question_ What are the three types of enzymes in digestion?\n_Answer_ Digestive enzymes are a group of enzymes that break down polymeric... Lipases split fatty\nacids... Proteases and peptidases split proteins ... Amylases split carbohydrates ... Nucleases\nsplit nucleic acids into nucleotides...\n_Model Answer_ There are three main types of enzymes involved in digestion: proteases, which break down\nproteins; amylases, which break down carbohydrates; and lipases, which break down fats.\nProteases are produced by the stomach and pancreas, while amylases are ... These enzymes work\nin concert ...\n\n_Other Answer 1_ Digestive enzymes are proteins that help ... There are three main types of digestive enzymes:\nproteases, which break down proteins into amino acids; amylases, which break down carbohydrates into simple sugars; and lipases, which break down fats into glycerol and fatty acids. These\nenzymes are produced by different organs and ...\n_Other Answer 2_ There are three main types of enzymes involved in digestion: proteases, which break down\nproteins; amylases, which break down carbohydrates; and lipases, which break down fats. These\nenzymes are produced by the salivary glands, stomach, and pancreas, and work in various parts\nof the digestive system...\n_..._ ...\n_Self-consistency scores_ [100, 100, 0, ...] (%)\n\n_Correctness_ Score: 100% Distribution: {1.0 : 1.0}\n_Confidence score_ Score: 95.6% Distribution: {0.8 : 0.22, 1.0 : 0.78}\n\n\n**ASQA Successful Example 2**\n\n\n_Question_ When did ben rectors new album come out?\n_Answer_ Benjamin Evans Rector is an American singer... He has released seven studio albums, including\nMagic on June 22, 2018, which peaked at No. 1 .. Brand New which released on August 28,\n2015... Older albums such as Something Like This, released on September 13, 2011 and The\nWalking in Between, came out August 20, 2013.\n_Model Answer_ Ben Rector\u2019s new album, \"Magic\", was released on March 25, 2022.\n\n_Other Answer 1_ Ben Rector\u2019s new album, \"Brand New\", was released on March 10th, 2022.\n_Other Answer 2_ Ben Rector, an American singer-songwriter, released his new album \"Magic\" on October 20...\n_..._ ...\n_Self-consistency scores_ [0, 0, ...](%)\n\n_Correctness_ Score: 0% Distribution: {0 : 1.0}\n_Confidence_ Score: 0% Distribution: {0 : 1.0}\n\n\n**ASQA Failed Example 1 (Under Confident)**\n\n\n_Question_ Who plays charlie on it\u2019s always sunny?\n_Answer_ Charlie Day plays the fictional character Charlie Kelly... Day is an American actor, screenwriter...\n_Model Answer_ Charlie Day plays Charlie on It\u2019s Always Sunny in Philadelphia. He is also known for his role as\nDale Arbus ... Day is a member of the improvisational comedy ...\n\n_Other Answer 1_ Dennis is played by Glenn Howerton.\n_Other Answer 2_ Charlie on It\u2019s Always Sunny in Philadelphia is played by Charlie Day.\n_..._ ...\n_Self-consistency scores_ [0, 33.3, ...](%)\n\n_Correctness_ Score: 80% Distribution: {0.8 : 1.0}\n_Confidence_ Score: 31.1% Distribution: {0 : 0.22, 0.4 : 0.78}\n\n\n**ASQA Failed Example 2 (Over Confident)**\n\n\n_Question_ Who sings wake me up when it\u2019s all over?\n_Answer_ \u201cWake Me Up\u201d is a song by Swedish DJ and record producer Avicii. Aloe Blacc, which is the\nstage name for Egbert Nathaniel Dawkins III provides vocals for the song while Mike Einziger\nprovides acoustic guitar. \u201cWake Me When It\u2019s Over\u201d is a song written and recorded by Willie...\n_Model Answer_ \u201cWake Me Up When September Ends\u201d is a song written by Billy\n\n_Other Answer 1_ \u201cWake Me Up When September Ends\u201d is a song by American rock band Green Day, written by\nlead vocalist Billie Joe Armstrong...\n_Other Answer 2_ \u201cWake Me Up When September Ends\u201d is a song by Green Day, written by the band\u2019s lead\nvocalist and guitarist Billie Joe Armstrong...\n_..._ ...\n_Self-consistency scores_ [100, 100, ...](%)\n\n_Correctness_ Score: 0% Distribution: {0 : 1.0}\n_Confidence score_ Score: 77.8% Distribution: {0 : 0.22, 1.0 : 0.78}\n\nTable 7: Examples for ASQA\n\n\n-----\n\n",
    "query": "I am interested in articles related to Roberta models",
    "references": [
      {
        "arxiv_id": "2207.05221",
        "title": "Language models (mostly) know what they know",
        "relevance_score": 1
      },
      {
        "arxiv_id": "2209.12356",
        "title": "News summarization and evaluation in the era of GPT-3",
        "relevance_score": 1
      },
      {
        "arxiv_id": "2106.07998",
        "title": "Revisiting the calibration of modern neural networks",
        "relevance_score": 1
      },
      {
        "arxiv_id": "2311.08401",
        "title": "Fine-tuning language models for factuality",
        "relevance_score": 1
      },
      {
        "arxiv_id": "2006.03654",
        "title": "DeBERTa: Decoding-enhanced BERT with disentangled attention",
        "relevance_score": 4
      },
      {
        "arxiv_id": "2311.03754",
        "title": "Which is better? Exploring prompting strategy for LLM-based metrics",
        "relevance_score": 2
      },
      {
        "arxiv_id": "2302.09664",
        "title": "Semantic uncertainty: Linguistic invariances for uncertainty estimation in natural language generation",
        "relevance_score": 1
      },
      {
        "arxiv_id": "2401.07103",
        "title": "Leveraging large language models for NLG evaluation: A survey",
        "relevance_score": 2
      },
      {
        "arxiv_id": "2211.15006",
        "title": "Fine-tuning language models to find agreement among humans with diverse preferences",
        "relevance_score": 1
      },
      {
        "arxiv_id": "2305.05176",
        "title": "FrugalGPT: How to use large language models while reducing cost and improving performance",
        "relevance_score": 2,
        "relevance_score_explanation": "This paper discusses a cost-effective strategy for using LLMs, which is indirectly relevant to Roberta models as it touches upon the efficiency and resource management aspects of large language models.  However, it does not specifically focus on Roberta models."
      },
      {
        "arxiv_id": "2311.17311",
        "title": "Universal self-consistency for large language model generation",
        "relevance_score": 2,
        "relevance_score_explanation": "This paper discusses universal self-consistency for large language model generation, which is relevant to Roberta models as it explores methods for improving the reliability and consistency of model outputs. However, it does not specifically focus on Roberta models."
      },
      {
        "arxiv_id": "2106.09685",
        "title": "LoRA: Low-rank adaptation of large language models",
        "relevance_score": 1,
        "relevance_score_explanation": "This paper introduces LoRA, a low-rank adaptation technique for large language models. While relevant to the broader context of LLMs, it doesn\u2019t directly pertain to Roberta models or their specific properties."
      },
      {
        "arxiv_id": "2307.09288",
        "title": "Llama 2: Open foundation and fine-tuned chat models",
        "relevance_score": 1,
        "relevance_score_explanation": "This paper introduces Llama 2, a different family of large language models. While relevant to the broader context of LLMs, it doesn\u2019t directly pertain to Roberta models or their specific properties."
      },
      {
        "arxiv_id": "2306.13063",
        "title": "Can LLMs express their uncertainty? An empirical evaluation of confidence elicitation in LLMs",
        "relevance_score": 2,
        "relevance_score_explanation": "This paper explores confidence elicitation in LLMs, which is relevant to Roberta models as it investigates methods for assessing the certainty of model outputs. However, it does not specifically focus on Roberta models."
      },
      {
        "arxiv_id": "2403.20279",
        "title": "LUQ: Long-text uncertainty quantification for LLMs",
        "relevance_score": 2,
        "relevance_score_explanation": "This paper addresses long-text uncertainty quantification for LLMs, which is relevant to Roberta models as it explores methods for assessing the uncertainty associated with longer text generations. However, it does not specifically focus on Roberta models."
      },
      {
        "arxiv_id": "2306.05685",
        "title": "Judging LLMs-as-a-judge with MT-Bench and Chatbot Arena",
        "relevance_score": 1,
        "relevance_score_explanation": "This paper discusses evaluating LLMs using MT-Bench and Chatbot Arena. While relevant to the broader context of LLMs, it doesn\u2019t directly pertain to Roberta models or their specific properties."
      },
      {
        "arxiv_id": "1907.11692",
        "title": "RoBERTa: A robustly optimized BERT pretraining approach",
        "relevance_score": 5,
        "relevance_score_explanation": "This paper introduces RoBERTa, a robustly optimized BERT pretraining approach.  This is directly relevant to the query."
      }
    ]
  },
  {
    "document": "## Calibrating Long-form Generations from Large Language Models\n\n### Yukun Huang[1], Yixin Liu[2], Raghuveer Thirukovalluru[1], Arman Cohan[2], Bhuwan Dhingra[1]\n\n\n1Duke University, 2Yale University\n### {yukun.huang, raghuveer.thirukovalluru}@duke.edu, bdhingra@cs.duke.edu {yixin.liu, arman.cohan}@yale.edu\n\n Abstract\n\n\nTo enhance Large Language Models\u2019 (LLMs)\nreliability, calibration is essential\u2014the model\u2019s\nconfidence scores should align with the likelihood of its responses being correct. However,\ntraditional calibration methods typically rely\non a binary true/false assessment of response\ncorrectness, unsuitable for long-form generations where an answer can be partially correct.\nAddressing this gap, we introduce a unified\ncalibration framework, in which both the correctness of the LLMs\u2019 responses and their associated confidence levels are treated as distributions across a range of scores. We develop\nthree metrics for assessing LLM calibration and\npropose confidence elicitation methods based\non self-consistency and self-evaluation. Our experiments demonstrate that larger models don\u2019t\nnecessarily guarantee better calibration, that\nvarious calibration metrics complement each\nother, and that self-consistency methods excel\nin factoid datasets. We also find that calibration\ncan be enhanced through techniques such as\nfine-tuning, scaling the temperature. Finally,\nwe illustrate one application of long-form calibration through selective answering in longform responses, optimizing correctness within\na constrained API budget.\n\n### 1 Introduction\n\n\nConfidence calibration in large language models\n(LLMs) aims to align the model\u2019s internal confidence with a probabilistic perspective of its answers\u2019 correctness (i.e. quality), enhancing reliability and interpretability for aiding human decisionmaking (Kadavath et al., 2022). People intuitively\nunderstand and utilize probabilities (Cosmides and\nTooby, 1996), making this approach crucial for\npractical applications. Conventional calibration\n(Guo et al., 2017) treats answer correctness as binary (true or false) and seeks to align the model\u2019s\nconfidence with the likelihood of model\u2019s answer\n\n\nFigure 1: A comparison between short-form generation\nand long-form generation. The correctness of the shortform answer can either be true (1) or false (0), while the\ncorrectness of the long-form answer is typically a score\nbetween 0 and 1. Both of these scores may vary across\nevaluators due to subjectivity, hence we conceptualize\nthem as a distribution over [0, 1].\n\nbeing correct, typically stated as: \u201cI am x% confi_dent that this answer is completely correct.\u201d How-_\never, the correctness of long-form generation is\nnot always either true or false but can be partially\ncorrect (Figure 1).\nTherefore, a single confidence score for longform outputs is ambiguous: it can either imply \u201cI\n_am x% confident that the answer is 100% correct\u201d_\nor \u201cI am 100% confident that the answer is x% cor_rect.\u201d The former fails to capture the graded notion_\nof long-form answer correctness, while the latter\nfocuses on self-evaluation of correctness, rather\nthan calibration as it overlooks the confidence at\nspecific correctness levels.\nAddressing this challenge, we propose to conceptualize the model\u2019s confidence as distribution\nacross scores between [0, 1] to capture the nuanced\nunderstanding of the model of each correctness\nlevel of the long-form answer, corresponding to the\nstatement \u201cI am x% confident that this answer is\n_y% correct\u201d. Moreover, we also view the correct-_\n\n\n-----\n\nFigure 2: Overview of our calibration framework. We prompt an LLM to produce an answer to a specific question,\nassess the answer\u2019s correctness distribution using an evaluator (task-specific metric/GPT-4 metric/human metric),\nand determine the model\u2019s confidence distribution through self-evaluation or self-consistency approaches. Finally,\nwe calculate the calibration score by comparing the correctness and confidence distributions against our predefined\nmetrics.\n\n\nness of an LLM\u2019s response as a distribution across\nscores between [0, 1] to capture graded and subjective assessments of long-form generations quality.\nThis subjectivity arises from the multifaceted nature of evaluating long-form outputs, where factors\nlike factuality, coherence, clarity, and comprehensiveness each play a role, potentially introducing\nvariability in judgment (Bakker et al., 2022). We\ncan then measure both the classical notion of calibration error, averaged across different correctness\nlevels, as well as new notions of alignment between the correctness and confidence distributions\nand their utility in selective prediction (\u00a7 3.4). Figure 2 shows an overview of our framework, which\nconsists of three modular components: estimating\nthe target correctness distributions, eliciting confidence distributions from LLMs, and measuring\ncalibration between these distributions.\n\nOur unified framework offers three key advantages. 1. Generalizability: Our framework applies\nto both long-form and short-form generation tasks\nby representing correctness and confidence as distributions, regardless of whether the correctness of\ntask is binary, continuous, subjective, or objective.\n2. Flexibility: The framework is evaluation-metric\nagnostic, allowing the integration of any metric\nor confidence elicitation method, and can adapt\nas evaluation methods evolve. 3. Interpretability: It provides a nuanced view of uncertainty, enabling decision-makers to assess confidence across\nmultiple correctness levels, fostering greater transparency and trust in the model\u2019s outputs.\n\nWe leverage our framework to measure calibration for several LLMs on multiple datasets\nacross three long-form QA\u2014ASQA (Stelmakh\n\n\net al., 2022), ELI5 (Fan et al., 2019), QAMPARI\n(Amouyal et al., 2022)\u2014and one summarization\ntask, CNNDM (Nallapati et al., 2016). Our results show that our methods excel over baselines\nby leveraging the model\u2019s nuanced confidence distribution, stronger LLMs like GPT-3.5 don\u2019t necessarily guarantee better calibration, that various\ncalibration metrics complement each other, and\nLLMs exhibit better calibration on factoid datasets\nthan more open-ended datasets. Furthermore, our\nanalysis highlights that fine-tuning and temperature scaling could enhance calibration. Finally, we\nillustrate a practical application of long-form calibration: employing a cascading strategy (Chen\net al., 2023a) for selective answering to optimize\nthe cost-effectiveness of long-form text generation. In this approach, an open-source model initially handles queries and, based on its confidence\nlevels\u2014assessed using our system\u2014a more advanced API model is engaged as needed. This\nmethod ensures cost efficiency while maintaining\nhigh-performance levels.\nIn summary, our contributions are:\n\n  - A universal calibration framework for text generation tasks, enhancing LLM evaluation for\ncritical applications.\n\n  - Innovative methods for confidence elicitation\nand calibration measurement, applied to a variety of LLMs.\n\n  - Evidence that calibration can be improved by\nmodel fine-tuning and temperature scaling.\n\n  - A cost-effective model usage strategy, illustrating the practicality of long-form calibration in optimizing LLM deployment.\n\n\n-----\n\n### 2 Related Work\n\n**Measuring Calibration Calibration (Guo et al.,**\n2017, Minderer et al., 2021)has been widely\nstudied in language models, whose probabilities\nderived from logits are generally found to not be\ncalibrated (Jiang et al., 2020, Kadavath et al., 2022,\nChen et al., 2023d). Standard metrics to measure\nthe calibration include Expected Calibration\nError (ECE) for confidence-accuracy disparity\n(Naeini et al., 2015), Brier Score for mean squared\nprediction-outcome differences, and AUROC\nfor assessing confidence-based correct answer\nidentification (Boyd et al., 2013, Kuhn et al.,\n2023). Selective Accuracy@Coverage measures\naccuracy within the model\u2019s most confident\npredictions (Liang et al., 2023, Cole et al., 2023).\nHowever, these metrics, rooted in a binary notion\nof correctness, fall short for long-form tasks\nwhere correctness spans a range, suggesting a\ndistribution-based approach is more apt.\n\n**Improving** **Calibration** Traditional calibration methods focus on post-processing logits (Guo\net al., 2017), but with LLMs generating unbounded\ntext, logits could fall short. Thus, extracting better\nconfidence scores (i.e., confidence elicitation)\nhas become crucial for improving calibration.\nThese include: verbalization, which directly asks\nthe model to output its confidence (Lin et al.,\n2022), consistency, which uses the uniformity of\nmultiple responses to gauge confidence (Kadavath\net al., 2022, Kuhn et al., 2023, Cole et al., 2023,\nChen et al., 2023c, Tian et al., 2023a, Lin et al.,\n2023), and the hybrid of both (Xiong et al., 2023,\nTian et al., 2023b, Chen and Mueller, 2023).\nHowever, these methods often presume binary\nanswer correctness, offering a singular confidence\nscore that fails to capture the nuanced correctness\nrequired for long-form tasks. Recent work (Zhang\net al., 2024) on long-form generation addresses\ncontinuous correctness scores but focuses on\naligning an uncertainty score with correctness,\nrather than on improving calibration.\n\n### 3 Long-form Generations Calibration\n\nThis section formalizes the long-form generation\ncalibration problem (\u00a7 3.1), and introduces three\ncore components in our calibration framework (Figure 2): the correctness distributions of the answers\n(\u00a7 3.2), the confidence distributions of the LLM on\nits answers (\u00a7 3.3), and the calibration metrics to\n\n\nmeasure how well these two align (\u00a7 3.4).\n\n**3.1** **Formulation**\n\nGiven a dataset, the model\u2019s answer for each\n_D_\nquestion Qi in the dataset is answer Ai (where i indexes the questions in the dataset). To measure how\ncalibrated the model is, we need three steps. First,\nwe apply an evaluator to get the target correctness\ndistribution PTi where Ti is the random variable\nthat denotes the correctness score in answer Ai.\n\n_PTi(x) = Pr(Ai is s correct)_ (1)\n\nfor s, where is the space of correctness\n_\u2208S_ _S_\nlevels (e.g., normalized from ordinal scores ranging from 0 to 5). It should be noted that s could\ntheoretically be a continuous value in the range\n\n[0%, 100%]. However, since humans tend to make\nmore accurate judgments using discrete ratings due\nto \u201crounding bias\u201d (Honda et al., 2022), we approximate continuous correctness with ordinal scores in\npractice. Second, We use a confidence elicitation\nmethod to derive the confidence distribution PCi\nfrom LLM M, where Ci represents the model\u2019s\nconfidence in its answer Ai. We ensure these confidence scores are normalized to form a valid distribution, matching the domain of the correctness\ndistribution. For s,\n_\u2208S_\n\n_PCi(x) = M\u2019s confidence that A is s correct (2)_\n\nFinally, we design metrics to measure the alignment between PCi and PTi across the dataset.\n\n**3.2** **Correctness Distribution Estimation**\n\nTo establish correctness distributions as alignment\ntargets, we need to adopt long-form evaluation metrics that integrate aspects such as relevance, coherence, factuality, and helpfulness. Traditional\nmetrics like BLEU and ROUGE fail to capture semantic meaning (Liu et al., 2023a), while factualitybased metrics like FactScore (Min et al., 2023)\nmay neglect question relevance. GPT-4 metrics\nhave gained popularity (Li et al., 2024) due to their\nadaptability and comparative accuracy (Jain et al.,\n2023, Liu et al., 2023a). These metrics allow for\nthe integration of various user-prioritized aspects\nby adjusting evaluation rubrics, providing a balanced approach to both referenced and divergent\nanswers. However, they also have limitations like\na bias toward longer outputs (Zheng et al., 2023).\nOur framework is evaluator-agnostic, allowing\nus to use any correctness distribution metric. To\n\n\n-----\n\nidentify a practical and actionable metric that best\nguides human decision-making, we conduct human evaluations to determine alignment with human judgment. According to the results in Appendix C, we determined that the GPT-4 metric,\nwith a higher correlation to human judgments compared to the task-specific metric, is more effective\nfor three datasets (e.g., 76.2 v.s 47.8 in ASQA),\nwhile the task-specific metric is preferred for another dataset. Our framework\u2019s modular design\nallows replacements of evaluation metrics based on\nuser needs or new developments.\n\n**3.3** **Confidence Distribution Elicitation**\n\nThere are two common strategies to develop confidence in model responses: explicitly asking the\nmodel to verbalize its confidence or implicitly estimating it through self-consistency. However, the\nsingle confidence score provided by prior studies\nis ambiguous and non-interpretable in long-form\ncalibration. Therefore, we develop two methods\ntailored for long-form calibration accordingly.\n**Continuous Self Evaluation (CSE) We prompt**\nthe model to repeatedly perform self-evaluations,\nwhere the resulting scores (typically ordinal scores\nfrom 0 to 5) are normalized to a [0,1] range and\ninterpreted as a confidence distribution. The selfevaluation template closely mirrors the template\nfor correctness evaluation but omits the reference\nanswer (see Appendix F.3 for details). Formally,\ngiven an LLM, N self-evaluations:\n_M_\n\n\nAssessing similarity in long-form answers is more\ncomplex than with short responses (Kadavath et al.,\n2022). To address this, we propose four methods\nfor evaluating similarity in long-form content: 1.\n**Naive, assessing overall response similarity with**\nan LLM; 2. Split, analyzing sentence-level similarity; 3. Claim, evaluating claim matching; 4.\n**Named Entity Recognition (NER), focusing on**\nnamed entity overlap. These approaches range\nfrom broad to detailed analysis, chosen based on\ntask requirements and the desired analysis depth.\nSee Appendix B for more details.\n\n**3.4** **Calibration Metrics**\n\nWe introduce three key metrics to assess model\ncalibration from various angles. Expected correct_ness error with multi-class (ECE-M) measures the_\nalignment between the model\u2019s stated confidence\nin reaching a particular level of correctness and\nthe actual likelihood that the model performs at\nthat specified level, across the spectrum from 0 to\n1. Correlation evaluates the alignment between\nexpected confidence and correctness across the\n_dataset, indicating the model\u2019s proficiency in_\nranking answers. Selective F1 measures the utility\nof confidence scores in identifying the good\nanswers and abstaining from the rest.\n\n**ECE-M The classical notion of calibration**\nrelies on an (answer-correctness) pair of random\nvariables (A, Y ) 0, 1, where is the\n_\u2208A \u00d7 {_ _}_ _A_\nanswer space. An LLM with its confidence\n_M_\nelicitation method h : [0, 1] is said to be\n_M_ _A \u2192_\nwell-calibrated if Pr(Y = 1 _h_ (A) = q) = q\n_|_ _M_\nfor q [0, 1]. To measure if this holds, tradi_\u2208_\ntional ECE(h) (Gupta and Ramdas, 2021) is:\nEA [|Pr(Y = 1|hM(A)) \u2212 _hM(A)|]_\nIn long-form calibration where the answer correctness is a continuum Y [0, 1], the probabilistic\n_\u2208_\nconfidence predictor hM should predict confidence\nabout each level of correctness and therefore denoted as h : [0, 1] [0, 1]. The notion of\n_M_ _A \u00d7_ _\u2192_\nlong-form calibration is Pr(Y = s _h_ (A, s) =\n_|_ _M_\n_qs) = qs for every s \u2208_ [0, 1] and qs \u2208 [0, 1] We\ndefine ECE-M as the aggregation of ECE scores for\nall correctness levels. In practice, we use discrete\nlevels s (e.g., ratings from 0-5) for the cor_\u2208S_\nrectness scores. Hence, we calculate an ECE(s, h)\nconditioned on each s,\n\nEX [|Pr(Y = s|hM(A, s)) \u2212 _hM(A, s)|]_ (5)\n\nThen the final ECE-M score is weighted by the\n\n\n_PCi(s) = N[1]_\n\n\n_N_\n\ufffd\n\n1(M(Ai)j = s) (3)\n_j=1_\n\n\nfor score s, where is the space of correctness\n_\u2208S_ _S_\nlevels. Such a sampling method provides a more\nauthentic reflection of the model\u2019s internal distribution than logits (Cole et al., 2023). By asking\nthe model to assess an answer multiple times, we\ncapture a range of scores that better represent the\nmodel\u2019s confidence, which enhances the reliability\nof the confidence estimation.\n**Pairwise Self Consistency (PSC) Another key**\nindicator of model confidence is the consistency\namong multiple responses a model provides for a\ngiven question. Given a primary answer Ai, other\n_N answers A[1]i_ _[...A]i[N]_ [sampled from LLM][ M][, a met-]\nric for measuring the similarity between two answers Sim( _,_ ), and a score s :\n\n_\u00b7_ _\u00b7_ _N_ _\u2208S_\n\n\ufffd\n\n_PCi(s) = [1]_ 1(Sim(Ai, A[j]i [) =][ s][)] (4)\n\n_N_\n\n_j=1_\n\n\n-----\n\nfrequency of each class:\n\n\ufffd\nECE-M(h) := Pr(Y = s)ECE(s, h) (6)\n\n_s\u2208S_\n\n**Correlation While ECE-M focuses on mea-**\nsuring calibration at each correctness level\nindependently, it doesn\u2019t account for the distance\nbetween these levels. To address this, we also measure the correlation between the expected values\nof the confidence and correctness distributions\nfor a more comprehensive assessment. For each\nanswer Ai within the dataset, we can calculate\nthe expected correctness score of the model\n_E|Ci| =_ [\ufffd]s _[P][C]i[(][s][)][ \u00d7][ s][ and the expected correct-]_\nness score of the target E|Ti| = [\ufffd]s _[P][T]i[(][s][)][ \u00d7][ s][.]_\nIn the whole dataset, we can get a list of expected\ncorrectness scores EC from model confidence\nand a list of target expected correctness scores\n**ET. Then we can measure the correlation between**\nthem.\n\n_\u03c1(D) = Corr(EC, ET)_ (7)\n\nwhere Corr( ) represents the correlation function.\n\n_\u00b7_\nThis correlation provides a clear indicator of how\nwell our model\u2019s confidence aligns with its actual\ncorrectness across the entire dataset.\n\n**Selective F1 In selective answering (e.g., Kamath**\net al., 2020), models only respond when confident\nabout their accuracy to improve reliability. Traditional metrics for selective answering include\naccuracy@coverage and coverage@accuracy (Tian\net al., 2023b), which measures a model\u2019s precision\nand recall in selecting completely correct answers.\nSimilarly, in long-form calibration, it is crucial to\nassess the model\u2019s selection of answers that are at\nleast \"s% correct\" using both precision and recall.\nTherefore, we propose the selective F1 metric\n(F 1\u03c4s) to quantify the model\u2019s aptitude in filtering out answers that meet or exceed a predefined\ncorrectness threshold \u03c4s. Our approach utilizes a\ndual-threshold system, consisting of a confidence\nthreshold (\u03c4c) and the correctness threshold (\u03c4s),\nallowing the model to answer questions only if\nits confidence in the answer\u2019s expected correctness score exceeding \u03c4s surpasses \u03c4c. Formally,\nlet A = {A1, A2, ..., An} denote the total set of\nmodel\u2019s answers in the dataset and A[\u2217] = {Ai \u2208\n_A |_ [\ufffd]s\u2265\u03c4s _[P][C]i[(][s][)][ \u2265]_ _[\u03c4][c][}][ denote the set of selected]_\nanswers. Let the indicator function I\u03c4s(Ai) indicate if the expected correctness score E[Ti] of Ai\nexceeds \u03c4s:\n\n\n_I\u03c4s(Ai) =_\n\n\n\ufffd\n1 if E[Ti] \u2265 _\u03c4s_\n(8)\n0 Otherwise\n\n\nThe selective precision P\u03c4s on the dataset D is the\nproportion of selected answers that surpass the correctness threshold \u03c4s relative to the total number of\nselected answers:\n\n\n_P\u03c4s(D) =_\n\n\n\ufffd\n_Ai\u2208A[\u2217]_ _[I][\u03c4]s[(][A][i][)]_\n\n(9)\n_|A[\u2217]|_\n\n\nThe selective recall R\u03c4s compares the number of\nselected answers meeting this criterion against the\ntotal number of correct answers in the dataset that\nexceed the threshold \u03c4s:\n\n\n_R\u03c4s(D) =_\n\n\n\ufffd\n_Ai\u2208A[\u2217]_ _[I][\u03c4]s[(][A][i][)]_\n(10)\n\ufffd\n_Ai\u2208A_ _[I][\u03c4]s[(][A][i][)]_\n\n\nThe selective F1 combines recall and precision:\n\n_F_ 1\u03c4s(D) = 2 _[P][\u03c4][s][(][D][)][R][\u03c4][s][(][D][)]_ (11)\n\n_P\u03c4s(D) + R\u03c4s(D)_\n\nIn our experiments, we select \u03c4s as the nearest\ncorrectness level greater than the best LM\u2019s average\ncorrectness score. For \u03c4c, we choose the value\nthat yields the highest selective F1 score on the\ndevelopment split.\n\n### 4 Experiments and Results\n\n**4.1** **Setup**\n\n**Models and Data We measure different sized**\nLLMs\u2019 calibration, including Llama-2-13b-chat,\nLlama-2-70b-chat (Touvron et al., 2023), Vicuna13b (Zheng et al., 2023), Llama-3-8b-Instruct, GPT3.5-turbo, across three long-form QA tasks: ASQA\n(Stelmakh et al., 2022), ELI5 (Fan et al., 2019),\nQAMPARI (Amouyal et al., 2022), and one summarization task: CNNDM (Nallapati et al., 2016).\nDetails of datasets can be found in Appendix A.\n**Correctness Evaluation We apply GPT-4 to evalu-**\nate target correctness distributions for ASQA, ELI5,\nand CNNDM. In QAMPARI where the answer is\na list of entities, we evaluate using the F1-5 metric, calculating the F1 score by the exact match\nwith the gold answer and defining 100% recall for\npredictions with at least 5 correct answers.\n\n**4.2** **Confidence Elicitation Methods**\n\nIn addition to our methods CSE and PSC (see Appendix D.3 for similarity measurement choosing),\nwe established baselines for self-evaluation, selfconsistency, and logits-based approaches. This is\n\n\n-----\n\n|Method|ASQA ECE-M Corr F1 0.8|QAMPARI ECE-M Corr F1 0.4|ELI5 ECE-M Corr F1 0.8|CNNDM ECE-M Corr F1 0.8|\n|---|---|---|---|---|\n\n|SL\u2217|28.2\u2191 0.7\u2191 0.0 \u2191|27.4\u2191 10.9\u2191 8.0\u2191|29.6\u2191 -11.9\u2191 0.0\u2191|77.2\u2191 -7.5\u2191 0.0\u2191|\n|---|---|---|---|---|\n\n|BSE\u2217 CSE|32.8\u2191 14.2\u2191 57.6 \u2191 29.0\u2193 16.3\u2191 58.5 \u2191|25.2\u2191 16.8\u2191 33.2\u2191 42.8\u2191 21.9\u2191 33.4\u2191|30.3\u2191 11.7\u2191 46.7\u2191 31.2\u2191 26.9\u2191 48.2\u2191|78.5\u2191 11.2\u2191 90.6\u2191 15.2\u2193 19.2\u2191 92.0\u2191|\n|---|---|---|---|---|\n\n|ASC\u2217 PSC F 1 PSC|35.9\u2191 27.1\u2191 5.2 \u2191 28.8\u2191 27.1\u2191 33.5 \u2191 18.3\u2193 46.8\u2191 61.6 \u2191|46.0\u2191 38.6\u2191 38.5\u2191 38.4\u2191 38.6\u2191 42.7\u2191 26.2\u2193 39.1\u2191 44.0\u2191|38.4\u2191 16.7\u2191 7.9\u2191 27.1\u2191 16.7\u2191 20.7\u2191 24.9\u2193 24.9\u2191 46.2\u2191|63.2\u2191 8.8 \u2191 44.2\u2191 57.1\u2191 8.8\u2191 79.5\u2191 64.5\u2191 15.5\u2191 90.0\u2191|\n|---|---|---|---|---|\n\n\nTable 1: Calibration Performance Comparison Among Different Confidence Elicitation Methods Across Four Tasks\n(in %): \u201cECE-M\u201d for expected correctness error with multi-class, \u201cCorr\u201d for Correlation, \u201cF 1\u03c4s\u201d for Selective F1\nScore at threshold \u03c4s. Results represent averages from five models. Methods with * served as baselines. For \u201cCorr\u201d,\n\u201cF 1\u03c4s \u201d, and \u201cScore\u201d, \u2191 means better than corresponding baseline while \u2193 is worse. For \u201cECE-M\u201d, \u2193 is better while\n\n_\u2191_ is worse. The best score among all confidence elicitation methods is bolded. Key insights: 1) Self-Consistency\n(PSC) outperforms Self-Evaluation on factoid datasets; 2) Our methods PSC and CSE surpass baselines; 3) Different\nmetrics offer complementary insights\n\n\nbecause prior studies lack directly applicable baselines, primarily due to the non-interpretable nature\nof single confidence scores.\n**Sentence Likelihood (SL): Based on prior stud-**\nies using logits to gauge model confidence, we\nadopt sentence likelihood as a baseline measure,\nwhich typically results in a confidence distribution\nfocused at the lowest score in long-form answers.\n**Binary Self-Evaluation (BSE): following previous**\nwork (Kadavath et al., 2022) that asks model to selfevaluate if its answer is true several times, using\nthe frequency of true as model\u2019s confidence score\ntowards the answer being true. Then we adapt such\na single score as a distribution focus solely on the\nvalues 0 and 1.\n**Average Self-Consistency (ASC): Following prior**\nwork (Xiong et al., 2023) using the average consistency between these candidate responses and the\noriginal answer then serves as a single measure\nof confidence score, we adopt the simple f1-token\nscore to measure the consistency to adapt it to longform generations. Then we treat the single score as\na point mass distribution.\n**Pairwise Self-Consistency F1 (PSC-F1): Still us-**\ning F1 to measure the consistency like ASC, but\nwe directly treat the pairwise consistency scores as\na distribution without aggregating, thereby keeping model intrinsic understanding about different\ncorrectness levels.\n\n**4.3** **Main Results**\n\nIn Table 1, we evaluate the calibration performances of various confidence elicitation methods\nby averaging the scores across all models. Table 1\nshows that our methods, CSE and PSC, generally\noutperform their respective baseline categories\n\n\nand also surpass the logits-based method SL. Key\nfindings from the results include:\n\n**Self-Consistency Outperforms Self-Evaluation**\n**on Factoid Datasets Self-consistency methods**\ntypically outperform self-evaluation on factoid\ndatasets like ASQA and QAMPARI. However,\ntheir effectiveness diminishes in more subjective\ntasks such as ELI5 or CNNDM. We hypothesize\nthat this is because self-consistency is more\nreadily quantifiable in factoid datasets, where the\nagreement between answers can be assessed based\non factual consistency, thus providing clearer\ncriteria. Conversely, in open-ended datasets, the\nconsistency between answers is more ambiguous,\nmaking it more difficult to measure.\n\n**Nuanced** **Self-Evaluation** **Enhances** **Cali-**\n**bration CSE generally outperforms BSE by**\nproviding detailed confidence estimates at each correctness level. However, the overall improvement\nremains constrained by the intrinsic limitations of\nLMs in self-evaluating their correctness, which\nsometimes hampers accurate estimations.\n\n**Pair-wise** **Similarities** **Distribution** **and**\n**Task-tailored Similarity Measurement Help**\n**Calibration Both ASC and PSC-F1 measure**\nsimilarity with token-level F1. However, PSC-F1\ntreats these scores as a distribution rather than\naveraging them, leading to better ECE-M and\nselective F1. PSC further enhances calibration by\nadopting a task-specific, detailed measurement of\nsimilarity, outperforming FSC in all four tasks.\n\n\n-----\n\n|Model|ASQA ECE-M Corr F1 Score 0.8|QAMPARI ECE-M Corr F1 Score 0.4|\n|---|---|---|\n\n|Llama2-13b Llama2-70b Vicuna-13b Llama-3-8b GPT-3.5-turbo|15.9 48.0 47.5 51.3 14.7 44.3 61.9 59.4 20.1 58.2 56.8 50.8 14.3 53.2 65.1 54.9 26.7 30.5 76.7 72.6|30.5 46.0 42.3 13.3 29.3 17.1 37.0 14.6 14.4 49.5 42.6 11.4 33.0 38.3 42.0 14.1 23.7 44.4 56.2 24.0|\n|---|---|---|\n\n|Model|ELI5 ECE-M Corr F1 Score 0.8|CNNDM ECE-M Corr F1 Score 0.8|\n|---|---|---|\n\n|Llama2-13b Llama2-70b Vicuna-13b Llama-3-8b GPT-3.5-turbo|36.0 21.8 40.1 53.8 32.8 18.8 54.4 61.7 19.4 31.3 34.9 53.0 34.9 36.7 48.4 57.1 32.7 26.2 63.4 63.0|12.6 19.5 92.0 77.0 13.8 6.4 93.6 77.6 32.7 3.9 64.2 78.2 9.3 49.0 86.9 77.8 7.8 17.0 94.7 78.2|\n|---|---|---|\n\n\nTable 2: Comparison of Calibration Performance Across Models for Four Tasks (in %): We identify the optimal\nconfidence elicitation method for each task and compare the performance of various models using this method.\n\u201cScore\u201d means the model\u2019s average correctness score on that task. A key observation is that more powerful LMs do\nnot necessarily exhibit better calibration, although they tend to perform better in selective answering.\n\n\n**Calibration metrics complement each other A**\nsimplistic approach like SL, which allocates all\nthe probability mass to the point of score 0, can\nmisleadingly show decent ECE-M (28.2%) in\nspecific cases like ASQA. However, its negative\ncorrelation (0.7%) and zero F10.8 underscore an\nineffective confidence distribution. Similarly, BSE\nin CNNDM may achieve a high F10.8 (90.6%)\nby overestimating answer correctness, but this\ndoes not truly reflect response quality (correlation:\n11.2%) or provide well-calibrated probabilities\nacross correctness levels, resulting in a bad ECE-M\n(ECE-M: 78.5%). Hence, a comprehensive\nevaluation using multiple metrics is essential for a\nbalanced assessment of model calibration.\n\n**Larger models are not necessarily better**\n**calibrated. In Table 2, we focus on the calibration**\nperformance of individual models when paired\nwith the best-performing confidence elicitation\nmethod for each task. Table 2 shows that despite\npoor performance on ASQA and QAMPARI,\nVicuna-13b has the highest correlation across\nthese datasets. It might be because reinforcement\nlearning for other models causes miscalibration\nby encouraging overfitting to rewarded behaviors\n(Kadavath et al., 2022). Scaling the temperature\ncould enhance the calibration of LLMs fine-tuned\nusing RL (see \u00a7 4.4). Additionally, Llama-2-13b\ndemonstrates a higher correlation than its larger\n\n\ncounterpart, Llama-2-70b. However, GPT-3.5turbo, the strongest model, consistently scores the\nhighest in selective F1 across all datasets. This\nperformance can be attributed to the model\u2019s\nability to generate a larger volume of high-quality\nanswers, increasing the probability of selecting\nsuperior responses even if it is not particularly\nwell-calibrated. Consequently, the Selective F1\nmetric blends performance and calibration, and\ntends to favor more capable models due to their\nhigher output of quality answers.\n\n**4.4** **Improving Calibration**\n\nWe delve into different strategies to enhance\ncalibration: fine-tuning, scaling the temperature,\nadding source documents (Appendix E.2), and\nhybrid confidence elicitation (Appendix E.3).\n\n**Fine-tuning Our study explores three fine-**\ntuning strategies to improve model calibration\non the ASQA dataset: fine-tuning the model for\nself-evaluation (using questions and model answers\nto produce scores and explanations), fine-tuning\nthe model for generation (generating answers\nfrom questions), and a hybrid of both. GPT-4\nsynthesizes self-evaluation data by assessing\ndifferent models\u2019 answers to questions from the\nASQA training set, while the generation data\n\n\n-----\n\noriginates from the ASQA training set itself.\nWe apply LoRA (Hu et al., 2021) fine-tuning to\nthe Llama2-13b model. See Appendix E.1 for\nexperiment details. As Table 3 reveals, solely\ntraining on self-evaluation (\u2018Evaluation\u2019) did\nnot yield consistent improvements in calibration,\npossibly due to the complexity of this task and\nthe limitation of LORA. Nonetheless, fine-tuning\nthe model improves the self-consistency method,\nespecially when the generation data is included\nduring training (\u2018Eval + Gen\u2019 and \u2018Generation\u2019).\nThe model becomes more confident in terms of\nself-consistency after fine-tuning.\n\n**Data** **Corr** **ECE-M** **F10.8** **Score**\n\n**Self-Evaluation (CSE)**\nNone 18.1 \u2191 30.3 \u2191 50.8 \u2191 51.3 \u2191\n\nEvaluation 13.6 \u2193 32.4 \u2191 52.3 \u2191 49.2 \u2193\n\nGeneration 20.0 \u2191 26.2 \u2193 53.4 \u2191 52.1 \u2191\n\nEval + Gen 23.9 \u2191 20.2 \u2193 46.6 \u2193 50.1 \u2193\n\n**Self-Consistency (PSC)**\nNone 48.0 \u2191 15.9 \u2191 47.5 \u2191 51.3 \u2191\n\nEvaluation 46.9 \u2193 13.6 \u2193 56.1 \u2191 49.2 \u2193\n\nGeneration 58.9 \u2191 14.5 \u2193 59.5 \u2191 52.1 \u2191\n\nEval + Gen 54.5 \u2191 12.2 \u2193 50.7 \u2191 50.1 \u2193\n\n\n60\n\n40\n\n20\n0.2 0.4 0.6 0.8 1\n\n\n50\n\n30\n\n10\n0.2 0.4 0.6 0.8 1\n\n\n_t_\n\n\n_t_\n\n\n70\n50\n30\n10\n\n0.2 0.4 0.6 0.8 1\n\n_t_\n\n\n15\n14\n13\n12\n0.2 0.4 0.6 0.8 1\n\n_t_\n\n\nFigure 3: Calibration varies with temperature scaling.\n\nhow many queries reach GPT-4, balancing answer\nquality with API budget constraints. We benchmark using the open-source LM for a zero API\nbudget and the commercial LM for full-budget scenarios. Our experiments utilize the ASQA and\n\n\nTable 3: Comparison among raw and fine-tuned Llama2-13b on ASQA. \u201cNone\u201d for the untrained model, \u201cEvaluation\u201d for the model fine-tuned with the self-evaluation\ndataset, \u201cGeneration\u201d for the model fine-tuned with the\nASQA generation data, and \u201cEval+Gen\u201d for the model\nfine-tuned with the hybrid dataset combined by selfevaluation dataset and generation data.\n\n**Temperature We adjust the generation tempera-**\nture for Llama2-13b from 0.2 to 1 to examine its\nimpact on calibration. The result in Figure 3 reveals consistent improvements in all calibration\nmetrics. Notably, the model\u2019s performance initially\nimproves and then deteriorates. This observation\nimplies that modulating the generation temperature\ncan enhance the calibration of the model.\n\n\n**4.5** **Application**\n\nWe showcase an application of long-form calibration in Figure 4: a cost-effective cascading strategy\nusing language models of varying capabilities to\nefficiently handle queries within an API budget\nconstraint. Initially, an open-source model (Llama2-13b in our experiment) address questions where\nit believes the answer has a probability higher than\n_\u03c4c that the answer\u2019s correctness score is above \u03c4s._\nComplex queries, flagged by lower model confidence, are escalated to a more advanced API LM\n(GPT-4). Adjusting \u03c4c between 0 and 1 controls\n\n\nFigure 4: The illustration of LLM Cascade.\n\nQAMPARI datasets to evaluate four distinct confidence elicitation strategies: PSC, ASC, CSE, and\nBSE. Additionally, we incorporate a baseline strategy where, under a constrained number of API requests, a random selection of queries is processed\nby Llama-2-13b, with the remaining handled by\nGPT-4. For each API budget scenario, questions\nare randomly assigned to Llama-2-13b using 10\ndifferent random seeds, and we calculate the mean\nand standard deviation of the results. We focus on\nthe success rate, which we define as the percentage of answers that meet or exceed a user-specified\nscore threshold. This metric is reported both for the\noverall dataset and for the subset of queries selected\nand handled by Llama-2-13b, illustrating both the\ngeneral effectiveness of our cascading model and\nthe selective answering capabilities of the individual model. As shown in Figure 5, PSC generally\noutperforms the other methods, with CSE and BSE\nyielding comparable results that follow. ASC, in\ncontrast, performs the poorest, comparable to the\nrandom selection strategy. These results highlight\nthe pivotal role of advanced calibration techniques,\nconfidence elicitation methods in our case, in boosting the practical utility and cost-efficiency of LLMs\nwhen API usage is limited.\n\n\n-----\n\n0.9\n\n0.8\n\n0.7\n\n0.6\n\n0.5\n\n0.4\n\n|Col1|Col2|Col3|Col4|Col5|\n|---|---|---|---|---|\n||||||\n||||||\n||||||\n|||||PSC CSE BSE|\n|||||ASC Random|\n\n|Col1|Col2|Col3|Col4|Col5|Col6|\n|---|---|---|---|---|---|\n|||||||\n|||||||\n|||||||\n|||||PSC||\n|||||CSE BSE||\n|||||ASC Random||\n\n\n0 0.2 0.4 0.6 0.8 1.0\n\nbudget\n\n\n0 0.1 0.3 0.5 0.7 0.9\n\nbudget\n\n\n0.8\n\n0.7\n\n0.6\n\n0.5\n\n0.4\n\n0.3\n\n\nhave significant real-world implications. Lastly,\nour self-consistency method is computationally\nintensive, posing a challenge for practical applications. There is a need for more efficient approaches\nin real-world settings.\n\n**Replicability:**\nCodes: [https://github.com/kkkevinkkkkk/](https://github.com/kkkevinkkkkk/calibration)\n[calibration](https://github.com/kkkevinkkkkk/calibration)\n\n\n(a) ASQA Overall\n\n\n(b) ASQA Selected\n\n\n0.6\n\n0.5\n\n0.5\n\n0.4\n\n0.4\n\n0.3\n\n0.2\n\n|Col1|Col2|Col3|Col4|Col5|\n|---|---|---|---|---|\n||||||\n||||||\n|||||PSC|\n|||||CSE BSE|\n|||||ASC Random|\n\n|Col1|Col2|Col3|Col4|Col5|\n|---|---|---|---|---|\n||||||\n|||||PSC|\n|||||CSE BSE|\n|||||ASC Random|\n\n\n0 0.2 0.4 0.6 0.8 1.0\n\nbudget\n\n\n0.5\n\n0.4\n\n\n0 0.1 0.3 0.5 0.7 0.9\n\nbudget\n\n\n0.3\n\n0.2\n\n\n(c) QAMPARI Overall\n\n\n(d) QAMPARI Selected\n\n\nFigure 5: Variation in Success Rate by API Budget\nAllocation on the ASQA and QAMPARI Datasets for\nAll Queries and Those Selected by Llama-2.\n\n### 5 Conclusion\n\n\nOur study presents a novel calibration system for\nevaluating LLMs in long-form generation. Our results challenge the assumption that larger LLMs are\nalways calibrated better and show calibration variability across datasets. Additionally, we propose\nmethods to improve LLM calibration and show\nan application that optimizes performance under\nAPI budget constraints. The system we present is\ncrucial for further improving the liability of LLMs.\n\n### 6 Limitation\n\n\nOur study faces three primary limitations. First,\nwe rely on GPT-4 to estimate the target correctness\ndistribution. But as tasks become more subjective,\nconsensus on humans\u2019 evaluations may decrease.\nThis wider target correctness distribution becomes\nchallenging for both GPT-4 and human annotators\nto accurately capture. This limitation is inherent\nto natural language generation (NLG) evaluation\nand lies beyond the purview of our project. Our\nframework operates under the premise that a target\ncorrectness distribution exists and concentrates on\ncalibration which aligns the model\u2019s confidence\nwith this assumed target. Second, our experiments\nfocus on long-form QA and do not extend to\nspecialized domains such as law, medicine, or\neducation, where the calibration of LLMs could\n\n\n### References\n\nSamuel Joseph Amouyal, Tomer Wolfson, Ohad Rubin,\nOri Yoran, Jonathan Herzig, and Jonathan Berant.\n[2022. Qampari: An open-domain question answer-](https://api.semanticscholar.org/CorpusID:249062559)\n[ing benchmark for questions with many answers from](https://api.semanticscholar.org/CorpusID:249062559)\n[multiple paragraphs.](https://api.semanticscholar.org/CorpusID:249062559)\n\nMichiel A. Bakker, Martin Chadwick, Hannah Sheahan,\nMichael Henry Tessler, Lucy Campbell-Gillingham,\nJan Balaguer, Nathan McAleese, Amelia Glaese,\nJohn Aslanides, Matthew M. Botvinick, and Christo[pher Summerfield. 2022. Fine-tuning language mod-](https://api.semanticscholar.org/CorpusID:254043997)\n[els to find agreement among humans with diverse](https://api.semanticscholar.org/CorpusID:254043997)\n[preferences. ArXiv, abs/2211.15006.](https://api.semanticscholar.org/CorpusID:254043997)\n\nKendrick Boyd, Kevin H. Eng, and David Page. 2013.\n\n[Area under the precision-recall curve: Point estimates](https://api.semanticscholar.org/CorpusID:37409855)\n[and confidence intervals. In ECML/PKDD.](https://api.semanticscholar.org/CorpusID:37409855)\n\n[Jiuhai Chen and Jonas Mueller. 2023. Quantifying un-](https://api.semanticscholar.org/CorpusID:263611057)\n[certainty in answers from any language model and](https://api.semanticscholar.org/CorpusID:263611057)\n[enhancing their trustworthiness.](https://api.semanticscholar.org/CorpusID:263611057)\n\nLingjiao Chen, Matei A. Zaharia, and James Y. Zou.\n[2023a. Frugalgpt: How to use large language mod-](https://api.semanticscholar.org/CorpusID:258564349)\n[els while reducing cost and improving performance.](https://api.semanticscholar.org/CorpusID:258564349)\n_ArXiv, abs/2305.05176._\n\nXinyun Chen, Renat Aksitov, Uri Alon, Jie Ren, Kefan Xiao, Pengcheng Yin, Sushant Prakash, Charles\n[Sutton, Xuezhi Wang, and Denny Zhou. 2023b. Uni-](https://api.semanticscholar.org/CorpusID:265498407)\n[versal self-consistency for large language model gen-](https://api.semanticscholar.org/CorpusID:265498407)\n[eration. ArXiv, abs/2311.17311.](https://api.semanticscholar.org/CorpusID:265498407)\n\nYanda Chen, Chen Zhao, Zhou Yu, Kathleen McKe[own, and He He. 2023c. On the relation between](https://doi.org/10.18653/v1/2023.findings-emnlp.12)\n[sensitivity and accuracy in in-context learning. In](https://doi.org/10.18653/v1/2023.findings-emnlp.12)\n_Findings of the Association for Computational Lin-_\n_guistics: EMNLP 2023, pages 155\u2013167, Singapore._\nAssociation for Computational Linguistics.\n\nYangyi Chen, Lifan Yuan, Ganqu Cui, Zhiyuan Liu,\n[and Heng Ji. 2023d. A close look into the calibra-](https://doi.org/10.18653/v1/2023.acl-long.75)\n[tion of pre-trained language models. In Proceedings](https://doi.org/10.18653/v1/2023.acl-long.75)\n_of the 61st Annual Meeting of the Association for_\n_Computational Linguistics (Volume 1: Long Papers),_\npages 1343\u20131367, Toronto, Canada. Association for\nComputational Linguistics.\n\nJeremy Cole, Michael Zhang, Daniel Gillick, Julian\nEisenschlos, Bhuwan Dhingra, and Jacob Eisenstein.\n[2023. Selectively answering ambiguous questions.](https://doi.org/10.18653/v1/2023.emnlp-main.35)\n\n\n-----\n\nIn Proceedings of the 2023 Conference on Empiri_cal Methods in Natural Language Processing, pages_\n530\u2013543, Singapore. Association for Computational\nLinguistics.\n\n[Leda Cosmides and John Tooby. 1996. Are humans](https://api.semanticscholar.org/CorpusID:18631755)\n[good intuitive statisticians after all? rethinking some](https://api.semanticscholar.org/CorpusID:18631755)\n[conclusions from the literature on judgment under](https://api.semanticscholar.org/CorpusID:18631755)\n[uncertainty. Cognition, 58:1\u201373.](https://api.semanticscholar.org/CorpusID:18631755)\n\nAngela Fan, Yacine Jernite, Ethan Perez, David Grang[ier, Jason Weston, and Michael Auli. 2019. ELI5:](https://doi.org/10.18653/v1/P19-1346)\n[Long form question answering. In Proceedings of](https://doi.org/10.18653/v1/P19-1346)\n_the 57th Annual Meeting of the Association for Com-_\n_putational Linguistics, pages 3558\u20133567, Florence,_\nItaly. Association for Computational Linguistics.\n\nTianyu Gao, Howard Yen, Jiatong Yu, and Danqi Chen.\n[2023. Enabling large language models to generate](https://doi.org/10.18653/v1/2023.emnlp-main.398)\n[text with citations. In Proceedings of the 2023 Con-](https://doi.org/10.18653/v1/2023.emnlp-main.398)\n_ference on Empirical Methods in Natural Language_\n_Processing, pages 6465\u20136488, Singapore. Associa-_\ntion for Computational Linguistics.\n\nTanya Goyal, Junyi Jessy Li, and Greg Durrett. 2022.\n\n[News summarization and evaluation in the era of](https://api.semanticscholar.org/CorpusID:252532176)\n[gpt-3. ArXiv, abs/2209.12356.](https://api.semanticscholar.org/CorpusID:252532176)\n\nChuan Guo, Geoff Pleiss, Yu Sun, and Kilian Q. Wein[berger. 2017. On calibration of modern neural net-](https://api.semanticscholar.org/CorpusID:28671436)\n[works.](https://api.semanticscholar.org/CorpusID:28671436) In International Conference on Machine\n_Learning._\n\n[Chirag Gupta and Aaditya Ramdas. 2021. Top-label](https://api.semanticscholar.org/CorpusID:240070283)\n[calibration and multiclass-to-binary reductions. In](https://api.semanticscholar.org/CorpusID:240070283)\n_International Conference on Learning Representa-_\n_tions._\n\nPengcheng He, Xiaodong Liu, Jianfeng Gao, and\nWeizhu Chen. 2020. Deberta: Decoding[enhanced bert with disentangled attention. ArXiv,](https://api.semanticscholar.org/CorpusID:219531210)\nabs/2006.03654.\n\nHidehito Honda, Rina Kagawa, and Masaru Shirasuna.\n[2022. On the round number bias and wisdom of](https://api.semanticscholar.org/CorpusID:248858577)\n[crowds in different response formats for numerical](https://api.semanticscholar.org/CorpusID:248858577)\n[estimation. Scientific Reports, 12.](https://api.semanticscholar.org/CorpusID:248858577)\n\nOr Honovich, Roee Aharoni, Jonathan Herzig, Hagai\nTaitelbaum, Doron Kukliansy, Vered Cohen, Thomas\nScialom, Idan Szpektor, Avinatan Hassidim, and\n[Yossi Matias. 2022. TRUE: Re-evaluating factual](https://doi.org/10.18653/v1/2022.naacl-main.287)\n[consistency evaluation. In Proceedings of the 2022](https://doi.org/10.18653/v1/2022.naacl-main.287)\n_Conference of the North American Chapter of the_\n_Association for Computational Linguistics: Human_\n_Language Technologies, pages 3905\u20133920, Seattle,_\nUnited States. Association for Computational Linguistics.\n\nJ. Edward Hu, Yelong Shen, Phillip Wallis, Zeyuan\nAllen-Zhu, Yuanzhi Li, Shean Wang, and Weizhu\n[Chen. 2021. Lora: Low-rank adaptation of large](https://api.semanticscholar.org/CorpusID:235458009)\n[language models. ArXiv, abs/2106.09685.](https://api.semanticscholar.org/CorpusID:235458009)\n\n\nSameer Jain, Vaishakh Keshava, Swarnashree\nMysore Sathyendra, Patrick Fernandes, Pengfei\nLiu, Graham Neubig, and Chunting Zhou. 2023.\n[Multi-dimensional evaluation of text summarization](https://doi.org/10.18653/v1/2023.findings-acl.537)\n[with in-context learning. In Findings of the Asso-](https://doi.org/10.18653/v1/2023.findings-acl.537)\n_ciation for Computational Linguistics: ACL 2023,_\npages 8487\u20138495, Toronto, Canada. Association for\nComputational Linguistics.\n\nZhengbao Jiang, Frank F. Xu, Jun Araki, and Graham\n[Neubig. 2020. How can we know what language](https://doi.org/10.1162/tacl_a_00324)\n[models know? Transactions of the Association for](https://doi.org/10.1162/tacl_a_00324)\n_Computational Linguistics, 8:423\u2013438._\n\nSaurav Kadavath, Tom Conerly, Amanda Askell, T. J.\nHenighan, Dawn Drain, Ethan Perez, Nicholas\nSchiefer, Zachary Dodds, Nova DasSarma, Eli TranJohnson, Scott Johnston, Sheer El-Showk, Andy\nJones, Nelson Elhage, Tristan Hume, Anna Chen,\nYuntao Bai, Sam Bowman, Stanislav Fort, Deep\nGanguli, Danny Hernandez, Josh Jacobson, John\nKernion, Shauna Kravec, Liane Lovitt, Kamal\nNdousse, Catherine Olsson, Sam Ringer, Dario\nAmodei, Tom B. Brown, Jack Clark, Nicholas Joseph,\nBenjamin Mann, Sam McCandlish, Christopher Olah,\n[and Jared Kaplan. 2022. Language models (mostly)](https://api.semanticscholar.org/CorpusID:250451161)\n[know what they know. ArXiv, abs/2207.05221.](https://api.semanticscholar.org/CorpusID:250451161)\n\n[Amita Kamath, Robin Jia, and Percy Liang. 2020. Se-](https://doi.org/10.18653/v1/2020.acl-main.503)\n[lective question answering under domain shift. In](https://doi.org/10.18653/v1/2020.acl-main.503)\n_Proceedings of the 58th Annual Meeting of the Asso-_\n_ciation for Computational Linguistics, pages 5684\u2013_\n5696, Online. Association for Computational Linguistics.\n\nJoonghoon Kim, Saeran Park, Kiyoon Jeong, Sangmin\nLee, Seung Hun Han, Jiyoon Lee, and Pilsung Kang.\n[2023. Which is better? exploring prompting strategy](https://api.semanticscholar.org/CorpusID:265043839)\n[for llm-based metrics. ArXiv, abs/2311.03754.](https://api.semanticscholar.org/CorpusID:265043839)\n\nLorenz Kuhn, Yarin Gal, and Sebastian Farquhar. 2023.\n\n[Semantic uncertainty: Linguistic invariances for un-](https://api.semanticscholar.org/CorpusID:257039062)\n[certainty estimation in natural language generation.](https://api.semanticscholar.org/CorpusID:257039062)\n_ArXiv, abs/2302.09664._\n\nZhen Li, Xiaohan Xu, Tao Shen, Can Xu, Jia-Chen\n[Gu, and Chongyang Tao. 2024. Leveraging large](https://api.semanticscholar.org/CorpusID:266999586)\n[language models for nlg evaluation: A survey. ArXiv,](https://api.semanticscholar.org/CorpusID:266999586)\nabs/2401.07103.\n\nPercy Liang, Rishi Bommasani, Tony Lee, Dimitris\nTsipras, Dilara Soylu, Michihiro Yasunaga, Yian\nZhang, Deepak Narayanan, Yuhuai Wu, Ananya Kumar, Benjamin Newman, Binhang Yuan, Bobby Yan,\nCe Zhang, Christian Cosgrove, Christopher D. Manning, Christopher R\u2019e, Diana Acosta-Navas, Drew A.\nHudson, E. Zelikman, Esin Durmus, Faisal Ladhak,\nFrieda Rong, Hongyu Ren, Huaxiu Yao, Jue Wang,\nKeshav Santhanam, Laurel J. Orr, Lucia Zheng,\nMert Yuksekgonul, Mirac Suzgun, Nathan S. Kim,\nNeel Guha, Niladri S. Chatterji, O. Khattab, Peter\nHenderson, Qian Huang, Ryan Chi, Sang Michael\nXie, Shibani Santurkar, Surya Ganguli, Tatsunori\nHashimoto, Thomas F. Icard, Tianyi Zhang, Vishrav\nChaudhary, William Wang, Xuechen Li, Yifan Mai,\n\n\n-----\n\n[Yuhui Zhang, and Yuta Koreeda. 2023. Holistic eval-](https://api.semanticscholar.org/CorpusID:253553585)\n[uation of language models. Annals of the New York](https://api.semanticscholar.org/CorpusID:253553585)\n_Academy of Sciences, 1525:140 \u2013 146._\n\nStephanie C. Lin, Jacob Hilton, and Owain Evans.\n[2022. Teaching models to express their uncertainty](https://api.semanticscholar.org/CorpusID:249191391)\n[in words. Trans. Mach. Learn. Res., 2022.](https://api.semanticscholar.org/CorpusID:249191391)\n\nZhen Lin, Shubhendu Trivedi, and Jimeng Sun. 2023.\n\n[Generating with confidence: Uncertainty quantifi-](https://api.semanticscholar.org/CorpusID:258967487)\n[cation for black-box large language models. Trans.](https://api.semanticscholar.org/CorpusID:258967487)\n_Mach. Learn. Res., 2024._\n\nYang Liu, Dan Iter, Yichong Xu, Shuohang Wang,\n[Ruochen Xu, and Chenguang Zhu. 2023a. G-eval:](https://doi.org/10.18653/v1/2023.emnlp-main.153)\n[NLG evaluation using gpt-4 with better human align-](https://doi.org/10.18653/v1/2023.emnlp-main.153)\n[ment. In Proceedings of the 2023 Conference on](https://doi.org/10.18653/v1/2023.emnlp-main.153)\n_Empirical Methods in Natural Language Processing,_\npages 2511\u20132522, Singapore. Association for Computational Linguistics.\n\nYinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis,\nLuke Zettlemoyer, and Veselin Stoyanov. 2019.\n[Roberta: A robustly optimized bert pretraining ap-](https://api.semanticscholar.org/CorpusID:198953378)\n[proach. ArXiv, abs/1907.11692.](https://api.semanticscholar.org/CorpusID:198953378)\n\nYixin Liu, Alex Fabbri, Pengfei Liu, Yilun Zhao, Linyong Nan, Ruilin Han, Simeng Han, Shafiq Joty,\nChien-Sheng Wu, Caiming Xiong, and Dragomir\n[Radev. 2023b. Revisiting the gold standard: Ground-](https://doi.org/10.18653/v1/2023.acl-long.228)\n[ing summarization evaluation with robust human](https://doi.org/10.18653/v1/2023.acl-long.228)\n[evaluation. In Proceedings of the 61st Annual Meet-](https://doi.org/10.18653/v1/2023.acl-long.228)\n_ing of the Association for Computational Linguistics_\n_(Volume 1: Long Papers), pages 4140\u20134170, Toronto,_\nCanada. Association for Computational Linguistics.\n\nSewon Min, Kalpesh Krishna, Xinxi Lyu, Mike Lewis,\nWen-tau Yih, Pang Koh, Mohit Iyyer, Luke Zettle[moyer, and Hannaneh Hajishirzi. 2023. FActScore:](https://doi.org/10.18653/v1/2023.emnlp-main.741)\n[Fine-grained atomic evaluation of factual precision](https://doi.org/10.18653/v1/2023.emnlp-main.741)\n[in long form text generation. In Proceedings of the](https://doi.org/10.18653/v1/2023.emnlp-main.741)\n_2023 Conference on Empirical Methods in Natural_\n_Language Processing, pages 12076\u201312100, Singa-_\npore. Association for Computational Linguistics.\n\nMatthias Minderer, Josip Djolonga, Rob Romijnders,\nFrances Ann Hubis, Xiaohua Zhai, Neil Houlsby,\nDustin Tran, and Mario Lucic. 2021. [Revisiting](https://api.semanticscholar.org/CorpusID:235435823)\n[the calibration of modern neural networks. ArXiv,](https://api.semanticscholar.org/CorpusID:235435823)\nabs/2106.07998.\n\nMahdi Pakdaman Naeini, Gregory F. Cooper, and Milos\n[Hauskrecht. 2015. Obtaining well calibrated proba-](https://api.semanticscholar.org/CorpusID:6292807)\n[bilities using bayesian binning. Proceedings of the](https://api.semanticscholar.org/CorpusID:6292807)\n_... AAAI Conference on Artificial Intelligence. AAAI_\n_Conference on Artificial Intelligence, 2015:2901\u2013_\n2907.\n\nRamesh Nallapati, Bowen Zhou, Cicero dos Santos,\n[\u00c7a\u02d8glar Gu[\u00b4]l\u00e7ehre, and Bing Xiang. 2016. Abstrac-](https://doi.org/10.18653/v1/K16-1028)\n[tive text summarization using sequence-to-sequence](https://doi.org/10.18653/v1/K16-1028)\n[RNNs and beyond.](https://doi.org/10.18653/v1/K16-1028) In Proceedings of the 20th\n_SIGNLL Conference on Computational Natural Lan-_\n_guage Learning, pages 280\u2013290, Berlin, Germany._\nAssociation for Computational Linguistics.\n\n\nIvan Stelmakh, Yi Luan, Bhuwan Dhingra, and Ming[Wei Chang. 2022. ASQA: Factoid questions meet](https://doi.org/10.18653/v1/2022.emnlp-main.566)\n[long-form answers. In Proceedings of the 2022 Con-](https://doi.org/10.18653/v1/2022.emnlp-main.566)\n_ference on Empirical Methods in Natural Language_\n_Processing, pages 8273\u20138288, Abu Dhabi, United_\nArab Emirates. Association for Computational Linguistics.\n\nKatherine Tian, Eric Mitchell, Huaxiu Yao, Christo[pher D. Manning, and Chelsea Finn. 2023a. Fine-](https://api.semanticscholar.org/CorpusID:265158181)\n[tuning language models for factuality.](https://api.semanticscholar.org/CorpusID:265158181) _ArXiv,_\nabs/2311.08401.\n\nKatherine Tian, Eric Mitchell, Allan Zhou, Archit\nSharma, Rafael Rafailov, Huaxiu Yao, Chelsea Finn,\n[and Christopher Manning. 2023b. Just ask for cali-](https://doi.org/10.18653/v1/2023.emnlp-main.330)\n[bration: Strategies for eliciting calibrated confidence](https://doi.org/10.18653/v1/2023.emnlp-main.330)\n[scores from language models fine-tuned with human](https://doi.org/10.18653/v1/2023.emnlp-main.330)\n[feedback. In Proceedings of the 2023 Conference](https://doi.org/10.18653/v1/2023.emnlp-main.330)\n_on Empirical Methods in Natural Language Process-_\n_ing, pages 5433\u20135442, Singapore. Association for_\nComputational Linguistics.\n\nHugo Touvron, Louis Martin, Kevin R. Stone, Peter\nAlbert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava,\nShruti Bhosale, Daniel M. Bikel, Lukas Blecher, Cristian Cant\u00f3n Ferrer, Moya Chen, Guillem Cucurull,\nDavid Esiobu, Jude Fernandes, Jeremy Fu, Wenyin\nFu, Brian Fuller, Cynthia Gao, Vedanuj Goswami,\nNaman Goyal, Anthony S. Hartshorn, Saghar Hosseini, Rui Hou, Hakan Inan, Marcin Kardas, Viktor\nKerkez, Madian Khabsa, Isabel M. Kloumann, A. V.\nKorenev, Punit Singh Koura, Marie-Anne Lachaux,\nThibaut Lavril, Jenya Lee, Diana Liskovich, Yinghai\nLu, Yuning Mao, Xavier Martinet, Todor Mihaylov,\nPushkar Mishra, Igor Molybog, Yixin Nie, Andrew\nPoulton, Jeremy Reizenstein, Rashi Rungta, Kalyan\nSaladi, Alan Schelten, Ruan Silva, Eric Michael\nSmith, R. Subramanian, Xia Tan, Binh Tang, Ross\nTaylor, Adina Williams, Jian Xiang Kuan, Puxin\nXu, Zhengxu Yan, Iliyan Zarov, Yuchen Zhang, Angela Fan, Melanie Kambadur, Sharan Narang, Aurelien Rodriguez, Robert Stojnic, Sergey Edunov, and\n[Thomas Scialom. 2023. Llama 2: Open foundation](https://api.semanticscholar.org/CorpusID:259950998)\n[and fine-tuned chat models. ArXiv, abs/2307.09288.](https://api.semanticscholar.org/CorpusID:259950998)\n\nMiao Xiong, Zhiyuan Hu, Xinyang Lu, Yifei Li, Jie Fu,\n[Junxian He, and Bryan Hooi. 2023. Can llms express](https://api.semanticscholar.org/CorpusID:259224389)\n[their uncertainty? an empirical evaluation of confi-](https://api.semanticscholar.org/CorpusID:259224389)\n[dence elicitation in llms. ArXiv, abs/2306.13063.](https://api.semanticscholar.org/CorpusID:259224389)\n\nCaiqi Zhang, Fangyu Liu, Marco Basaldella, and Nigel\n[Collier. 2024. Luq: Long-text uncertainty quantifica-](https://api.semanticscholar.org/CorpusID:268793903)\n[tion for llms. ArXiv, abs/2403.20279.](https://api.semanticscholar.org/CorpusID:268793903)\n\nTianyi Zhang, Faisal Ladhak, Esin Durmus, Percy Liang,\nKathleen McKeown, and Tatsunori Hashimoto. 2023.\n[Benchmarking large language models for news sum-](https://api.semanticscholar.org/CorpusID:256416014)\n[marization. Transactions of the Association for Com-](https://api.semanticscholar.org/CorpusID:256416014)\n_putational Linguistics, 12:39\u201357._\n\nLianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan\nZhuang, Zhanghao Wu, Yonghao Zhuang, Zi Lin,\nZhuohan Li, Dacheng Li, Eric P. Xing, Haotong\n\n\n-----\n\n[Zhang, Joseph Gonzalez, and Ion Stoica. 2023. Judg-](https://api.semanticscholar.org/CorpusID:259129398)\n[ing llm-as-a-judge with mt-bench and chatbot arena.](https://api.semanticscholar.org/CorpusID:259129398)\n_ArXiv, abs/2306.05685._\n\n### A Dataset\n\n**ASQA (Answer Summaries for Questions which**\nare Ambiguous) (Stelmakh et al., 2022) is a\nspecialized long-form factoid dataset, designed\nto address ambiguous factoid questions that\nyield different correct answers based on their\ninterpretations. This dataset challenges models\nto synthesize factual information from multiple\nsources, creating coherent long-form summaries\nthat effectively resolve the inherent ambiguities in\nthese questions.\n\n**ELI5 (Fan et al., 2019) is a comprehensive**\nopen-ended long-form dataset, encompassing over\n270,000 threads from the Reddit forum \u201cExplain\nLike I\u2019m Five.\u201d This unique platform features\ncommunity-generated responses to a wide array of\nquestions, all tailored to be easily understandable\nby a five-year-old audience. The majority of\nqueries in ELI5 are centered around \u2019how,\u2019\n\u2019why,\u2019 and \u2019what\u2019 questions, which necessitate\ncomprehensive, detailed responses supported by\nevidence from multiple passages.\n\n**QAMPARI (Amouyal et al., 2022) is a fac-**\ntoid dataset where answers are presented as lists of\nentities dispersed across multiple paragraphs. Its\nconstruction involves an automated process that\nutilizes Wikipedia knowledge graphs and tables.\nQuestions are manually paraphrased, and answers\nare thoroughly verified for accuracy. Notably,\neach question in QAMPARI is associated with an\naverage of 13 answers, demonstrating its breadth.\n\n**CNNDM (Nallapati et al., 2016) is a large-**\nscale news summarization dataset containing\nnews articles from CNN[1] and DailyMail[2]. The\noriginal CNNDM dataset consists of both source\nnews articles and reference summaries. However, recent work (Liu et al., 2023b; Zhang\net al., 2023) has found that the provided reference summaries are not of very good quality\nand zero-shot LLMs summaries are preferred\nby human annotators over the reference summaries.\n\nIn the **ACLE** (Automatic LLMs\u2019 Citation\n\n[1https://www.cnn.com/](https://www.cnn.com/)\n[2https://www.dailymail.co.uk/](https://www.dailymail.co.uk/)\n\n\nEvaluation) (Gao et al., 2023), a pioneering benchmark for assessing LLMs\u2019 citation capabilities, a\nsubset of 1,000 examples is randomly selected\nfrom the development sets of ASQA, ELI5, and\nQAMPARI to form a test set for each task. For our\nspecific analysis, we choose to utilize the first 500\nexamples from each of these datasets in ACLE as\nour test set, providing a focused and representative\nsample for each task. For CNNDM, we utilize 100\nexamples as our test set.\n\n### B Self-consistency\n\nWe propose four different self-consistency based\nmethods tailored for long-form generation, each\nwith a different strategy to measure the similarity\nbetween two long-form answer.\n\n**Naive The most basic approach utilizes an**\nadditional LLM (GPT-3.5-turbo in our experiments, which can be replaced by other models\ntrained for this task) to determine if two responses\nare akin, assigning a corresponding similarity\nscore. This method diverges from the relevant\ntechnique in contemporary research (Chen et al.,\n2023b), which primarily focuses on identifying\nthe most consistent answer. Instead, our approach\naims to secure specific consistency ratings that\nreflect the model\u2019s assurance in its primary answer,\noffering a general overview of the answers\u2019\nsimilarity. The template for similarity measuring\ncan be found in Appendix F.4.\n\n**Sentence Split For a more detailed similar-**\nity analysis between the two answers, we split the\nfirst answer into individual sentences. Another\nLLM (GPT-3.5-turbo or a similar NLI model) is\nthen used to evaluate whether similar statements\nare present in the second answer. This method\u2019s\nlimitation is that not all sentences carry equal\ninformational weight. Some may be filler or less\ninformative, potentially skewing the similarity\nassessment. The template can be found in\nAppendix F.4.\n\n**Claim To further refine the approach,** we\nfocus on sentences that make factual claims. This\ninvolves two steps: first, using a claim detector\nto identify factual claims within a sentence and\nthen using an NLI model to determine if similar\nfactual claims exist in the second answer. This\nmethod operates under the assumption that factual\n\n\n-----\n\nclaims are the most critical components of an\nanswer, representing its core information. We\nleverage a DeBERTa-V2 (He et al., 2020) trained\nby ClaimBuster as our fact detector and GPT-3.5\nas the NLI models.\n\n**Named** **Entity** **Recognition** Advancing the\ngranularity further, we compare named entities\nbetween two responses. We identify and compare\nentities present in both answers by utilizing a\nnamed entity recognition model. The degree of\noverlap in these entities serves as an indicator of\nanswer similarity. This approach focuses more on\nconcrete, identifiable elements within the answers.\nWe use a Roberta-large (Liu et al., 2019) trained\nwith SpanMarker framework [3], which can be\nreplaced by other NER models.\n\n### C Evaluation Metric\n\n**C.1** **GPT-4 metric**\n\nWe ask GPT-4 to range an answer from 0 (worst)\nto 5 (best), which is then normalized to [0, 1]. See\nAppendix F.1 for details of the template. To mitigate scoring variability from criteria ambiguity and\nLLM uncertainty, we have evaluators repeatedly\nscore each answer, forming a score distribution that\nbetter reflects its correctness. Specifically, given\nan LLM evaluator, N evaluations from it, and a\n_E_\nscore x [0, 1], the correctness distribution is:\n_\u2208_\n\n\nexact substrings of the generated content, following\nestablished methodologies. For ELI5, we utilize\nthe most precise automatic metric to date, claim re_call, employing the TRUE (Honovich et al., 2022)_\nnatural language inference model to ascertain if the\ngenerated output encompasses the sub-claims of\nthe reference answer.\nWe present the task criteria to humans and ask\nthem to provide a score for each answer based\non the criteria. Participants are provided with a\nreference answer\u2014not as an exclusive ground truth\nbut as a guide\u2014and are permitted to use search\nengines for additional context. We enlisted three\nannotators to evaluate 75 samples each for ASQA\nand ELI5, and calculate the average of them as a\nhuman score. Our analysis compares these human\nscores with those generated by task-specific metrics\nand GPT-4. The results, as detailed in our Table 4,\nunderscore GPT-4\u2019s closer alignment with human\njudgments in both ASQA and ELI5. As shown in\nFigure 12, as the task becomes more open-ended\nlike Eli5, the human agreements become lower than\nthe factoid dataset ASQA. This further evidence\nthe assumption that the correctness of a long-form\nanswer should be a distribution.\n\n**ASQA** **ELI5**\n**Metric** **EM** **GPT-4** **Claim** **GPT-4**\n\nCorr \u2191 47.8 76.2 42.9 71.5\nMAE \u2193 43.0 12.9 52.0 9.1\n\nTable 4: Comparison of Human, Task-Specific metric,\nand GPT-4 Correctness Distributions in ASQA and ELI5\nTasks. Results are with %. \u2018Corr\u2019 denotes Pearson\ncorrelation (the higher the better), \u2018MAE\u2019 denotes mean\nabsolute error (the lower the better). \u2018EM\u2019 denotes EMrecall, and \u2018Claim\u2019 denotes Claim-recall.\n\n### D Main Experiment\n\nWe assess the calibration of variously sized models\n(Llama-2-13b, Llama-2-70b, Vicuna-13b, GPT-3.5turbo) across three long-form QA datasets (ASQA,\nELI5, QAMPARI) and one summarization dataset\n(CNNDM). The process involves several steps: 1.\nGeneration: Asking the model to generate answers\nfor questions in the dataset 2. Correctness Assessment: We utilize GPT-4 to evaluate the correctness of the models\u2019 answers, except for QAMPARI, where we directly apply the F1-5 metric. 3.\nConfidence Distribution Derivation: After generating answers, models employ self-evaluation or\nself-consistency methods to derive their confidence\n\n|Metric|ASQA EM GPT-4|ELI5 Claim GPT-4|\n|---|---|---|\n\n|Corr \u2191 MAE \u2193|47.8 76.2 43.0 12.9|42.9 71.5 52.0 9.1|\n|---|---|---|\n\n\n_PTi(x) = N[1]_\n\n\n_N_\n\ufffd\n\n1(E(Ai)j = x) (12)\n_j=1_\n\n\n**C.2** **Human Evaluation**\n\nWe utilize GPT-4 to assess answers across different tasks, including ASQA, ELI5, and CNNDM,\nusing GPT-4 scores as a proxy for the target distribution. To demonstrate the better alignment of\nGPT-4 scores with human preferences over taskspecific metrics, we focus our human evaluation\nefforts on the long-form tasks of ASQA and ELI5.\nThis approach is supported by prior research indicating GPT-4\u2019s congruence with human judgments on summarization tasks (Liu et al., 2023a),\nthereby obviating the need for manual evaluation of\nCNNDM. Following Gao et al. (2023), in ASQA,\nwe adopt the EM-recall automatic metric, which\ngauges the recall of correct short answers by verifying if the dataset\u2019s provided short answers are\n\n[3https://github.com/tomaarsen/SpanMarkerNER](https://github.com/tomaarsen/SpanMarkerNER)\n\n\n-----\n\n1.00\n\n0.95\n\n\n1.0\n\n0.9\n\n\n0.90\n\n0.85\n\n\n0.8\n\n0.7\n\n\n0.80\n\n0.75\n\n\n0.6\n\n0.5\n\n\n0.14\n\n0.12\n\n0.10\n\n0.08\n\n0.06\n\n0.04\n\n0.02\n\n0.00\n\n0.12\n\n|1.00|0.90|0.72|\n|---|---|---|\n|0.90|1.00|0.72|\n|0.72|0.72|1.00|\n\n|1.00|0.75|0.56|\n|---|---|---|\n|0.75|1.00|0.49|\n|0.56|0.49|1.00|\n\n|0.00|0.08|0.12|\n|---|---|---|\n|0.08|0.00|0.15|\n|0.12|0.15|0.00|\n\n\nAnnotator 1 Annotator 2 Annotator 3\n\n\nAnnotator 1 Annotator 2 Annotator 3\n\n\nFigure 6: Correlation for ASQA\n\n1.0\n\n\nFigure 7: Cohen Kappa for ASQA\n\n1.0\n\n\nAnnotator 1 Annotator 2 Annotator 3\n\nFigure 8: MAE for ASQA\n\n\n0.9\n\n0.8\n\n\n0.8\n\n0.6\n\n\n0.10\n\n0.08\n\n\n0.7\n\n\n0.06\n\n0.04\n\n\n0.6\n\n0.53 0.42 1.00 0.5\n\n\n0.4\n\n0.2\n\n\n0.0\n\n\n0.02\n\n0.00\n\n|1.00|0.72|0.53|\n|---|---|---|\n|0.72|1.00|0.42|\n|0.53|0.42|1.00|\n\n|1.00|0.41|0.27|\n|---|---|---|\n|0.41|1.00|-0.02|\n|0.27|-0.02|1.00|\n\n|0.00|0.09|0.12|\n|---|---|---|\n|0.09|0.00|0.14|\n|0.12|0.14|0.00|\n\n\nAnnotator 1 Annotator 2 Annotator 3\n\nFigure 9: Correlation for ELI5\n\n\nAnnotator 1 Annotator 2 Annotator 3\n\nFigure 10: Cohen Kappa for ELI5\n\n\nAnnotator 1 Annotator 2 Annotator 3\n\nFigure 11: MAE for ELI5\n\n\nFigure 12: Pairwise annotator agreements for ASQA and ELI5 respectively\n\n\ndistribution. 4. Calibration Measurement: .\n\n**D.1** **Generation**\n\n\nIn the answer generation phase, we employ a 3-shot\nin-context learning approach for each long-form\nQA dataset, providing three exemplars to guide\nthe models. For the CNNDM dataset, we adopt a\n0-shot strategy, aligning with prior studies (Goyal\net al., 2022). The generation of answers utilizes\na top-K sampling method, setting the generation\ntemperature for all models at 0.6 and the top-K\nparameter at 10.\n\n**D.2** **Correctness Evaluation**\n\n\nas answers, we determine that F1 scores provide a\nmore suitable measure of correctness than GPT-4\nevaluations. To this end, we adopt the F1-5 metric\n(Gao et al., 2023), computing the F1 score based\non direct matches with the correct answer list and\nassigning a recall of 100% for responses containing\nat least five accurate answers (recall-5).\n\n**D.3** **Confidence Elicitation**\n\n\nFor ASQA, ELI5, CNNDM, we ask the GPT-4 to\nevaluate the correctness of examples. For ASQA\nand ELI5, We ask GPT-4 to evaluate the answer\nthree times, producing a distribution capturing criteria ambiguity and model\u2019s inherent subjectivity.\nHowever, for CNNDM, we only ask GPT-4 to evaluate once to save computation given that most\nanswers correctness concentrates around 0.8 with\nsmall variance. The GPT-4 evaluation template can\nbe found in Appendix F.1 and criteria for different\ntasks can be found in Appendix F.2. For QAMPARI, which involves generating a list of entities\n\n\nAfter getting the answer from the model, we\nleverage the self-evaluation or self-consistency\nmethod to derive confidence distribution from the\nmodel.\n\n**Self-Evaluation** We prompt the model to\nself-evaluate an answer 10 times, creating a\nconfidence distribution based on its self-evaluation\nscores. Each self-evaluation includes task instructions, grading criteria, and evaluation examples\n(three for all long-form QA datasets and one for\nCNNDM due to length constraints). Additionally,\nit contains specific instructions for self-evaluation,\nincorporating both the question and the answer\nunder evaluation. The detailed self-evaluation\ntemplate and criteria are available in Appendix F.3\nand Appendix F.2 respectively.\n\n\n-----\n\n**Self-consistency** In the self-consistency approach, we generate an answer to the same\nquestion 10 times, designating the first response as\nthe primary answer. We then calculate similarity\nscores between the primary answer and the\nremaining responses. These scores collectively\ncreate the model\u2019s confidence distribution for the\nprimary answer. For various datasets, tailored\nstrategies are employed to compare similarities\nbetween two answers.\nFor ASQA, we employ a self-consistency-claim\napproach. To assess the similarity between the two\nanswers, we first identify factual claims in the first\nanswer using a ClaimBuster-trained DeBERTa V2\n(He et al., 2020) claim detector. We then verify\nthe presence of these claims in the second answer\nthrough NLI. The similarity score is the average\npresence of factual claims across answers.\nIn QAMPARI, self-consistency-NER is used to\ndetermine confidence distribution. As the answers\nare entity lists, we extract entities by separating\ncommas. The similarity score is calculated based\non the proportion of overlapping entities between\ntwo answers, relative to the total entities in the first\nanswer.\nFor ELI5, where answers provide easily understandable explanations, we focus on the overall\ncontent. Here, we apply a self-consistency-naive\nmethod, assign a similarity score to each answer\npair with simple prompting.\nIn CNNDM, where answers are summaries highlighting key points of an article, we gauge the similarity between two answers by evaluating the overlap of key points. To achieve this, we implement\nthe self-consistency-split method. We dissect the\nfirst answer into individual sentences and then use\nNLI to determine if each sentence is present in\nthe second answer. The similarity score is derived\nby averaging the presence of these segmented sentences in the comparative answer.\n\n### E Improving Calibration\n\n**E.1** **Fine-tuning**\n\nIn our study, we focus on improving model\ncalibration on the ASQA dataset. We explore\nthree different strategies: fine-tune the model to\ndo self-evaluation (Input: question and model\u2019s\nanswer; Output: answer\u2019s score and explanation),\nfine-tune the model to do generation (Input:\nquestion; Output: answer), and a hybrid of both.\n\n\n**Data We generate a self-evaluation training**\ndataset with GPT-4, which evaluates different\nmodels responses to questions drawn from ASQA\ntraining set. This dataset comprises inputs of\nquestions and corresponding model answers, with\noutputs including a score and an explanation\nfor each answer. We create the self-evaluation\ndata in two steps. The initial phase involves the\ncreation of a diverse answer pool. This is achieved\nby employing a suite of models with varying\ncomputational capacities, including Llama-2-7b,\nLlama-2-13b, Llama2-70b, Vicuna-13b, and\nChatGPT. Each model generates responses to a\nspectrum of questions drawn from the training\nset of ASQA task, ensuring the resultant answer\npool encompasses a broad quality spectrum, from\nlow to high. Subsequently, we employ GPT-4\nto critically assess these answers, assigning a\nscore and providing a corresponding explanation\nfor its evaluation. This process yields a rich\ndataset, each instance of which encompasses a\nquestion, a model-generated answer, an evaluative\nscore, and a justification for that scoring. This\napproach results in a comprehensive dataset\nwith 2,000 self-evaluation examples (1,800 for\ntraining and 200 for validation), each including\na question, model-generated answer, score, and\njustification. For generation data, we use 80%\nof training ASQA\u2019s dataset (4,353 examples) for\ntraining and the remaining 20% for validation. The\nhybrid dataset combines the self-evaluation and\ngeneration training sets, using the self-evaluation\nvalidation set for assessment.\n\n**Training** **and** **Results** Regarding training,\nwe fine-tune Llama2-13b-chat model using LORA\non this dataset. We maintain consistent parameters\nacross all scenarios: a learning rate of 5e-6, five\nepochs, 100 warm-up steps, and a total batch size\nof 4 (achieved through 4 gradient accumulation\nsteps across four GPUs, with a batch size of 1 per\ndevice). As Table 3 reveals, solely training on selfevaluation (\u2018Evaluation\u2019) did not yield consistent\nimprovements in calibration, possibly due to the\ncomplexity of this task, as well as the limitation\nof LORA fine-tuning. Nonetheless, fine-tuning\nthe model improves the self-consistency method,\nespecially when the generation data is included\nduring training (\u2018Eval + Gen\u2019 and \u2018Generation\u2019).\nThe model becomes more confident in terms of\nself-consistency after fine-tuning.\n\n\n-----\n\n**E.2** **Source Documents**\n\nWe investigate the effect of additional context on\nLLM calibration, focusing on self-consistency confidence with Llama-2-13b-chat and GPT-3.5-turbo\nmodels on the ASQA dataset. We test the model\u2019s\nperformance when supplemented with two different types of source documents: random documents\nrelated to the question and \u2018oracle\u2019 documents directly relevant to the answers, as included in the\ndataset release (Stelmakh et al., 2022). Findings in\nTable 5 reveal that Oracle documents can enhance\nmodel performance and calibration across two out\nof three metrics for both models, while random documents are less effective. These results underscore\nthe importance of relevant contextual information\nin model calibration.\n\n\nCalibration Scores vs. Weight Variation\n\n60\n55\n50\n45\n40\n0 0.2 0.4 0.6 0.8 1\n\n\n70\n50\n30\n10\n\n\n0 0.2 0.4 0.6 0.8 1\n\n_\u03b1_\n\n\n**Model** **Doc** **Corr** **ECE-M** **F10.8** **Score**\n\nN 48.0\u2212 15.9\u2191 3.6\u2212 51.3\u2212\nLlama213b R 39.0 \u2193 14.8\u2193 30.6 \u2191 59.6 \u2191\n\nO 49.5 \u2191 17.5\u2191 20.1 \u2191 65.8 \u2191\n\nN 30.5\u2212 26.7\u2191 58.4\u2212 72.6\u2193\nGPT-3.5turbo R 36.6 \u2191 26.4\u2193 68.2 \u2191 64.8 \u2193\n\nO 27.0 \u2193 24.9\u2193 72.8 \u2191 75.8 \u2191\n\nTable 5: How source documents affect the calibration\nscore. In the document column, \u201cN\u201d means no documents in the input prompt, \u201cR\u201d means randomly selected\ndocuments relevant to the topic, and \u201cO\u201d means the oracle documents relevant to the answer. denotes that\n_\u2191_\nthe calibration score goes up when adding documents,\nwhile means going down. For ECE-M it\u2019s opposite.\n_\u2193_\n\n\nFigure 13: Hybrid confidence elicitation\n\n### F Prompts\n\n\n**E.3** **Hybrid Confidence Elicitation**\n\nWe explore whether combining self-evaluation and\nself-consistency can yield a more accurate confidence distribution on ASQA dataset. By blending confidence distributions from self-evaluation\n(Ci[eval]) and self-consistency (Ci[consist]) into a hybrid distribution Ci[hybrid] = _\u03b1Ci[eval]_ + (1 \u2212\n_\u03b1)Ci[consist], we adjust their relative contributions_\nusing \u03b1. As shown in Figure 13, we observe that\nthe correlation between confidence and correctness\ninitially increases but then declines as \u03b1 varies from\n0 to 1. However, this trend doesn\u2019t extend to other\nmetrics like F1, indicating that while hybrid calibration elicitation may enhance calibration in terms\nof correlation, it may not have the same impact on\nother dimensions.\n\n\nThis section introduces the prompts used for our\nexperiments.\n\n**F.1** **Correctness Evaluation Template**\n\n\nSimilar to contemporary work (Kim et al., 2023),\nour evaluation template for GPT-4 evaluation to\nget the target correctness distribution of an answer\nincludes four components: a clear task description,\nexpertly crafted evaluation criteria for objectivity,\ndemonstrations with a variety of answer qualities\n(best, worst, intermediate) each with a score and\nrationale, and specific evaluation instructions for\nthe LLM, encompassing the question-answer pair\nto be evaluated and a reference answer.\n\n\n-----\n\nEvaluation Template\n\n{task instruction}\n\nYou will be given a question, a reference answer, and a student\u2019s answer. Please evaluate the\nstudent\u2019s answer based on both your knowledge and\nthe reference answer, and provide a score from 0-5 to\nthe student\u2019s answer. Keep in mind that the reference\nanswer is not the sole correct response. Assess for\nboth factual accuracy and relevance to the question.\nThe following are the scoring criterion:\n\n{criterion}\n\nHere are some examples.\n\n{examples}\n\nNow it\u2019s your turn.\n\nQuestion: {question}\n\nReference answer: {reference answer}\n\nStudent\u2019s answer: {answer}\n\nNow please provide your score about this answer in the format of \u201cScore: <Your score>/5\u201d and\ngive your explanation.\n\n\nASQA Criterion\n\n5 - Completely Correct and Highly Relevant: The\nanswer fully addresses the question, resolves the ambiguity, and provides a well-rounded resolution. All\nfacts presented in the answer are accurate and relevant.\n4 - Mostly Correct and Relevant: The answer is very\nrelevant and addresses the ambiguity well, but might\nhave a minor oversight or inaccuracy. All the facts\npresented are accurate and relevant, or with only minor errors.\n3 - Partially Correct and Relevant: The answer is generally on topic and attempts to address the ambiguity,\nbut there might be inaccuracies or omissions. The\nmajority of the facts are correct, with a few errors.\n2 - Flawed but Somewhat Relevant: The answer\nsomewhat addresses the topic but does not fully explore the question\u2019s ambiguity or does not provide a\ncomplete resolution. The facts presented are a mix\nof correct and incorrect information, with about half\nbeing accurate.\n1 - Mostly Incorrect or Mostly Irrelevant: The answer\nslightly touches upon the topic but misses the main\npoint. The majority of the facts presented are incorrect, with only a small portion being accurate.\n0 - Completely Incorrect or Completely Irrelevant:\nThe student\u2019s answer is completely off-topic, not related to the question at all, or contains only incorrect\ninformation.\n\n\n**ELI5 Criterion**\n\n\n**F.2** **Criteria**\n\nBelow are the criteria for various tasks, with a\nspecial note that the CNNDM summarization task\nutilizes a distinct evaluation template.\n\n**ASQA Criterion**\n\n\nELI5 Criterion\n\n5 - Perfectly Addressed, Accurate and Clarity: The\nanswer flawlessly addresses the question with exceptional accuracy and clarity. It simplifies complex\nconcepts effectively and does so in a way that is captivating and memorable.\n4 - Accurate and clear: The answer is accurate, relevant to the question, and presented in a way that is\nengaging and understandable. It simplifies complex\nconcepts effectively but may miss a small opportunity\nfor further clarification or engagement.\n3 - Moderately Accurate and Understandable: The\nanswer is mostly accurate and somewhat understandable. It addresses the question reasonably well but\nmay lack detail or contain some inaccuracies. It may\nuse complex terms or concepts that are not broken\ndown into simpler ideas.\n2 - Relevant but Lacks Clarity or Accuracy: The answer is related to the question but lacks clarity or\ncontains partial inaccuracies. It attempts to simplify\nthe idea but does not do so effectively, leaving room\nfor confusion or misunderstanding.\n1 - Significantly Flawed: The answer addresses the\nquestion to a minimal extent but contains significant\ninaccuracies or misleading information. It might\nshow a basic attempt to simplify the concept but fail\nin accuracy or relevance.\n0 - Completely Inaccurate or Irrelevant: The answer\nis entirely off-topic, irrelevant, or factually incorrect.\nIt fails to address the question and does not simplify\ncomplex ideas.\n\n\n-----\n\nQAMPARI Criterion\n\n- Estimated Accuracy Assessment (0-3 Points)\n\n- 3 Points: All answers provided seem correct based\non available knowledge.\n\n- 2 Points: Majority of the answers seem correct.\n\n- 1 Point: Some answers are correct, but there are\nnotable inaccuracies.\n\n- 0 Points: No answers seem correct or very high\ndegree of inaccuracy.\n\n- Estimated Completeness Assessment (0-2\nPoints)\n\n- 2 Points: The response seems comprehensive,\ncovering a broad range of known or expected correct\nanswers.\n\n- 1 Point: The response covers some correct answers\nbut misses significant known or expected answers.\n\n- 0 Points: The response is highly incomplete,\nmissing most of the known or expected correct\nanswers.\n\n- Total Score (0-5 Scale)\n\n- Add the points from Estimated Accuracy and\nEstimated Completeness.\n\n\n**F.3** **Self-Evaluation Template**\n\n\nSelf Evaluation Template\n\n{task instruction}\n\nYou will be given a question and a student\u2019s\nanswer. Please evaluate the student\u2019s answer, and\nprovide a score from 0-5 to the student\u2019s answer\nbased on the following scoring criterion:\n\n{criterion}\n\nHere are some examples.\n\n{examples}\n\nNow it\u2019s your turn.\n\nQuestion: {question}\n\nAnswer: {answer}\n\nNow please provide your score about this answer in the format of \u201cScore: <Your score>/5\u201d and\ngive your explanation. Assess for both factual\naccuracy and relevance to the question.\n\n\nSummarization Evaluation Template\n\nYou will be given one summary written for a news\narticle.\n\nYour task is to rate the overall quality of the\nsummary with a score from 0 to 5, where 0 is the\nlowest and 5 is the highest.\n\nPlease make sure you read and understand\nthese instructions carefully. Please keep this document open while reviewing, and refer to it as needed.\n\nEvaluation Steps:\n1. Read the news article carefully and identify the\nmain topic and key points.\n2. Read the summary and compare it to the news\narticle. Check if the summary covers the main topic\nand key points of the news article, and if it presents\nthem in a clear and logical order.\n3. Assign a score for the summary quality on a scale\nof 0 to 5, where 0 is the lowest and 5 is the highest.\n\nTask Input:\n\nArticle: {article}\n\nSummary: {summary}\n\nNow please provide your score of the summary in the format of \u201cScore: <Your score>/5\u201d and\ngive your explanation.\n\n\n**F.4** **Self-Consistency Template**\nIn self-consistency approaches, assessing the similarity between two answers requires the use of an additional LLM\nin naive and split/claim methods. For the self-consistencynaive method, this involves an LLM directly providing similarity scores for the pair of answers. Meanwhile, for the\nself-consistency-split/claim method, another LLM is tasked\nwith detecting the presence of sentences from answer 1 in\nanswer 2. The templates for both the naive method and the\nsplit/claim method are outlined below.\n\nSimilarity Comparison Naive Template\n\nYou will be presented with a question followed by\ntwo answers. Evaluate how similar these answers are,\nconsidering their amount of information provided,\nfactual content, effectiveness in addressing the question, format and organization. Conclude by providing\nan integer similarity score between 0 and 5.\nQuestion: {question}\nAnswer 1: {answer1}\nAnswer 2: {answer2}\nNow please give your similarity score in the format\nof \u201cSimilarity score: <Your score>/5\u201d and give your\nexplanation. Make your answer short and concise.\n\nSimilarity Comparison Split Template\n\nYou will receive a sentence and a response; please\nascertain if a similar statement is present in the response.\nSentence: {sentence}\nResponse: {response}\nVerify if the response contains a statement resembling\nthe target sentence. Answer yes or no.\n\n### G Qualitative Analysis\n\nWe showcase successful and failed calibration examples on\nQampari and ASQA with self-consistency method.\n\n\n-----\n\n**type** **content**\n\n\n**QAMPARI Successful Example 1**\n\n\n_Question_ Who directed a film that had P. Balachandran as a screenwriter?\n_Answer_ Kamal, P. Balachandran, T. K. Rajeev Kumar, V. K. Prakash, Rajeev Ravi.\n_Model Answer_ Adu, Ammayum Muyalum, Bhoothakkannadi, Chattambi, Kakkakku Pinnaka...\n\n_Other Answer 1_ Agraharathile Kazhuthai, Kaliyugam, Kodungallur, Kodiyettam ...\n_Other Answer 2_ Kodiyettam, Kuttyedam, Oru CBI Diary Kurippu...\n_Other Answer 3_ Aravindan, K.G. George, John Abraham, Shyam Benegal ...\n_..._ ...\n_Self-consistency scores_ [0, 0, 0, ...] (%)\n\n_Correctness_ Score: 0% Distribution: {0 : 1.0}\n_Confidence score_ Score: 0% Distribution: {0 : 1.0}\n\n\n**QAMPARI Successful Example 2**\n\n\n_Question_ Which cities or municipalities are located in the province of Basilan?\n_Answer_ Akbar, Al-Barka, Hadji Muhtamad, Isabela City, Lamitan, Lantawan, Maluso, Sumisip, TabuanLasa, Tipo-Tipo, Tuburan, Ungkaya Pukan.\n_Model Answer_ Al-Barka, Basilan, Isabela, Lamitan, Tipo-Tipo, Maluso, Sumisip.\n\n_Other Answer 1_ Basilan, Isabela, Lamitan, Lantawan, Tipo-Tipo, Sumisip.\n_Other Answer 2_ Basilan, Tipo-Tipo, Isabela City, Maluso, Sumisip, Tuburan.\n_Other Answer 3_ Basilan, Isabela, Tipo-Tipo, Lamitan, Sumisip, Al-Barka, Maluso, Tuburan.\n_..._ ...\n_Self-consistency scores_ [71.4, 57.1, 85.7, ...](%)\n\n_Correctness_ Score: 83.3% Distribution: {0.8 : 1.0}\n_Confidence_ Score: 76.2% Distribution: {0.6 : 0.11, 0.8 : 0.78, 1.0 : 0.11}\n\n\n**QAMPARI Failed Example 1 (Under Confident)**\n\n\n_Question_ What city or municipality located in the Philipines are in the Tarlac province?\n_Answer_ Anao, Bamban, Camiling, Capas, Concepcion, Gerona, La Paz, Mayantoc, Moncada, Paniqui,\nPura, Ramos, San Clemente, San Jose, San Manuel, Santa Ignacia, Tarlac City, Victoria.\n_Model Answer_ Capas, Concepcion, Gerona, La Paz, Mayantoc, Paniqui, San Jose, Santa Ignacia, Tarlac City,\nVictoria.\n\n_Other Answer 1_ Capas, Concepcion, Camiling, Tarlac City, Paniqui, San Jose, Santa Lucia, Victoria.\n_Other Answer 2_ Capas, Tarlac, Concepcion, Tarlac, Gerona, Tarlac, La Paz, Tarlac, Paniqui, Tarlac, San Jose,\nTarlac, Tarlac City.\n_Other Answer 3_ Capas, Concepcion, Camiling, Tarlac City, San Jose.\n_..._ ...\n_Self-consistency scores_ [60, 60, 30, ...](%)\n\n_Correctness_ Score: 100% Distribution: {1 : 1.0}\n_Confidence_ Score: 51.1% Distribution: {0.4 : 0.56, 0.6 : 0.33, 0.8 : 0.11}\n\n\n**QAMPARI Failed Example 1 (Over Confident)**\n\n\n_Question_ What are some notables mailing list softwares ?\n_Answer_ Dada Mail, Discourse, GNU Mailman, GroupServer, LISTSERV, Majordomo, Organic Groups\nMailing List, Sympa.\n_Model Answer_ Mailchimp, Constant Contact, Campaign Monitor, AWeber, GetResponse, MailPoet, Sendinblue,\nMailerLite, Klaviyo, ConvertKit.\n\n_Other Answer 1_ Mailchimp, AWeber, GetResponse, Campaign Monitor, Constant Contact, Klaviyo, ConvertKit,\nMailPoet, Mailster, Sendinblue, MailerLite.\n_Other Answer 2_ Mailchimp, Constant Contact, AWeber, Campaign Monitor, GetResponse, Klaviyo, MailPoet,\nMailster, Sendinblue, MailerLite, ConvertKit, ActiveCampaign, and Constant Contact.\n_Other Answer 3_ Mailchimp, AWeber, GetResponse, Campaign Monitor, MailerLite, Constant Contact, Klaviyo,\nConvertKit, Sendinblue, and Emma.\n_..._ ...\n_Self-consistency scores_ [100, 100, 90, ...](%)\n\n_Correctness_ Score: 0% Distribution: {0 : 1.0}\n_Confidence score_ Score: 97.8% Distribution: {0.8 : 0.22, 1.0 : 0.78}\n\nTable 6: Examples for QAMPARI\n\n\n-----\n\n**type** **content**\n\n\n**ASQA Successful Example 1**\n\n\n_Question_ What are the three types of enzymes in digestion?\n_Answer_ Digestive enzymes are a group of enzymes that break down polymeric... Lipases split fatty\nacids... Proteases and peptidases split proteins ... Amylases split carbohydrates ... Nucleases\nsplit nucleic acids into nucleotides...\n_Model Answer_ There are three main types of enzymes involved in digestion: proteases, which break down\nproteins; amylases, which break down carbohydrates; and lipases, which break down fats.\nProteases are produced by the stomach and pancreas, while amylases are ... These enzymes work\nin concert ...\n\n_Other Answer 1_ Digestive enzymes are proteins that help ... There are three main types of digestive enzymes:\nproteases, which break down proteins into amino acids; amylases, which break down carbohydrates into simple sugars; and lipases, which break down fats into glycerol and fatty acids. These\nenzymes are produced by different organs and ...\n_Other Answer 2_ There are three main types of enzymes involved in digestion: proteases, which break down\nproteins; amylases, which break down carbohydrates; and lipases, which break down fats. These\nenzymes are produced by the salivary glands, stomach, and pancreas, and work in various parts\nof the digestive system...\n_..._ ...\n_Self-consistency scores_ [100, 100, 0, ...] (%)\n\n_Correctness_ Score: 100% Distribution: {1.0 : 1.0}\n_Confidence score_ Score: 95.6% Distribution: {0.8 : 0.22, 1.0 : 0.78}\n\n\n**ASQA Successful Example 2**\n\n\n_Question_ When did ben rectors new album come out?\n_Answer_ Benjamin Evans Rector is an American singer... He has released seven studio albums, including\nMagic on June 22, 2018, which peaked at No. 1 .. Brand New which released on August 28,\n2015... Older albums such as Something Like This, released on September 13, 2011 and The\nWalking in Between, came out August 20, 2013.\n_Model Answer_ Ben Rector\u2019s new album, \"Magic\", was released on March 25, 2022.\n\n_Other Answer 1_ Ben Rector\u2019s new album, \"Brand New\", was released on March 10th, 2022.\n_Other Answer 2_ Ben Rector, an American singer-songwriter, released his new album \"Magic\" on October 20...\n_..._ ...\n_Self-consistency scores_ [0, 0, ...](%)\n\n_Correctness_ Score: 0% Distribution: {0 : 1.0}\n_Confidence_ Score: 0% Distribution: {0 : 1.0}\n\n\n**ASQA Failed Example 1 (Under Confident)**\n\n\n_Question_ Who plays charlie on it\u2019s always sunny?\n_Answer_ Charlie Day plays the fictional character Charlie Kelly... Day is an American actor, screenwriter...\n_Model Answer_ Charlie Day plays Charlie on It\u2019s Always Sunny in Philadelphia. He is also known for his role as\nDale Arbus ... Day is a member of the improvisational comedy ...\n\n_Other Answer 1_ Dennis is played by Glenn Howerton.\n_Other Answer 2_ Charlie on It\u2019s Always Sunny in Philadelphia is played by Charlie Day.\n_..._ ...\n_Self-consistency scores_ [0, 33.3, ...](%)\n\n_Correctness_ Score: 80% Distribution: {0.8 : 1.0}\n_Confidence_ Score: 31.1% Distribution: {0 : 0.22, 0.4 : 0.78}\n\n\n**ASQA Failed Example 2 (Over Confident)**\n\n\n_Question_ Who sings wake me up when it\u2019s all over?\n_Answer_ \u201cWake Me Up\u201d is a song by Swedish DJ and record producer Avicii. Aloe Blacc, which is the\nstage name for Egbert Nathaniel Dawkins III provides vocals for the song while Mike Einziger\nprovides acoustic guitar. \u201cWake Me When It\u2019s Over\u201d is a song written and recorded by Willie...\n_Model Answer_ \u201cWake Me Up When September Ends\u201d is a song written by Billy\n\n_Other Answer 1_ \u201cWake Me Up When September Ends\u201d is a song by American rock band Green Day, written by\nlead vocalist Billie Joe Armstrong...\n_Other Answer 2_ \u201cWake Me Up When September Ends\u201d is a song by Green Day, written by the band\u2019s lead\nvocalist and guitarist Billie Joe Armstrong...\n_..._ ...\n_Self-consistency scores_ [100, 100, ...](%)\n\n_Correctness_ Score: 0% Distribution: {0 : 1.0}\n_Confidence score_ Score: 77.8% Distribution: {0 : 0.22, 1.0 : 0.78}\n\nTable 7: Examples for ASQA\n\n\n-----\n\n",
    "query": "I am interested in articles related to climate change",
    "references": [
      {
        "arxiv_id": "2211.15006",
        "title": "Fine-tuning language models to find agreement among humans with diverse preferences",
        "relevance_score": 0
      },
      {
        "arxiv_id": "2305.05176",
        "title": "FrugalGPT: How to use large language models while reducing cost and improving performance",
        "relevance_score": 0
      },
      {
        "arxiv_id": "2311.17311",
        "title": "Universal self-consistency for large language model generation",
        "relevance_score": 0
      },
      {
        "arxiv_id": "2106.09685",
        "title": "LoRA: Low-rank adaptation of large language models",
        "relevance_score": 0
      },
      {
        "arxiv_id": "2207.05221",
        "title": "Language models (mostly) know what they know",
        "relevance_score": 0
      },
      {
        "arxiv_id": "2209.12356",
        "title": "News summarization and evaluation in the era of GPT-3",
        "relevance_score": 0
      },
      {
        "arxiv_id": "2106.07998",
        "title": "Revisiting the calibration of modern neural networks",
        "relevance_score": 0
      },
      {
        "arxiv_id": "2311.08401",
        "title": "Fine-tuning language models for factuality",
        "relevance_score": 0
      },
      {
        "arxiv_id": "2306.13063",
        "title": "Can LLMs express their uncertainty? An empirical evaluation of confidence elicitation in LLMs",
        "relevance_score": 0
      },
      {
        "arxiv_id": "2403.20279",
        "title": "LUQ: Long-text uncertainty quantification for LLMs",
        "relevance_score": 0
      },
      {
        "arxiv_id": "2306.05685",
        "title": "Judging LLMs-as-a-judge with MT-Bench and Chatbot Arena",
        "relevance_score": 0
      },
      {
        "arxiv_id": "2307.09288",
        "title": "Llama 2: Open foundation and fine-tuned chat models",
        "relevance_score": 0
      },
      {
        "arxiv_id": "2006.03654",
        "title": "DeBERTa: Decoding-enhanced BERT with disentangled attention",
        "relevance_score": 0
      },
      {
        "arxiv_id": "1907.11692",
        "title": "RoBERTa: A robustly optimized BERT pretraining approach",
        "relevance_score": 0
      },
      {
        "arxiv_id": "2311.03754",
        "title": "Which is better? Exploring prompting strategy for LLM-based metrics",
        "relevance_score": 0
      },
      {
        "arxiv_id": "2302.09664",
        "title": "Semantic uncertainty: Linguistic invariances for uncertainty estimation in natural language generation",
        "relevance_score": 0
      },
      {
        "arxiv_id": "2401.07103",
        "title": "Leveraging large language models for NLG evaluation: A survey",
        "relevance_score": 0
      }
    ]
  },
  {
    "document": "### A Simple Unified Framework for Detecting Out-of-Distribution Samples and Adversarial Attacks\n\n**Kimin Lee[1], Kibok Lee[2], Honglak Lee[3][,][2], Jinwoo Shin[1][,][4]**\n\n1Korea Advanced Institute of Science and Technology (KAIST)\n2University of Michigan\n3Google Brain\n4AItrics\n\n\n###### Abstract\n\n\nDetecting test samples drawn sufficiently far away from the training distribution\nstatistically or adversarially is a fundamental requirement for deploying a good\nclassifier in many real-world machine learning applications. However, deep neural networks with the softmax classifier are known to produce highly overconfident\nposterior distributions even for such abnormal samples. In this paper, we propose\na simple yet effective method for detecting any abnormal samples, which is applicable to any pre-trained softmax neural classifier. We obtain the class conditional\nGaussian distributions with respect to (low- and upper-level) features of the deep\nmodels under Gaussian discriminant analysis, which result in a confidence score\nbased on the Mahalanobis distance. While most prior methods have been evaluated for detecting either out-of-distribution or adversarial samples, but not both,\nthe proposed method achieves the state-of-the-art performances for both cases in\nour experiments. Moreover, we found that our proposed method is more robust\nin harsh cases, e.g., when the training dataset has noisy labels or small number of\nsamples. Finally, we show that the proposed method enjoys broader usage by applying it to class-incremental learning: whenever out-of-distribution samples are\ndetected, our classification rule can incorporate new classes well without further\ntraining deep models.\n\n###### 1 Introduction\n\n\nDeep neural networks (DNNs) have achieved high accuracy on many classification tasks, e.g.,\nspeech recognition [1], object detection [9] and image classification [12]. However, measuring the\npredictive uncertainty still remains a challenging problem [20, 21]. Obtaining well-calibrated predictive uncertainty is indispensable since it could be useful in many machine learning applications\n(e.g., active learning [8] and novelty detection [18]) as well as when deploying DNNs in real-world\nsystems [2], e.g., self-driving cars and secure authentication system [6, 30].\n\nThe predictive uncertainty of DNNs is closely related to the problem of detecting abnormal samples that are drawn far away from in-distribution (i.e., distribution of training samples) statistically\nor adversarially. For detecting out-of-distribution (OOD) samples, recent works have utilized the\nconfidence from the posterior distribution [13, 21]. For example, Hendrycks & Gimpel [13] proposed the maximum value of posterior distribution from the classifier as a baseline method, and it\nis improved by processing the input and output of DNNs [21]. For detecting adversarial samples,\nconfidence scores were proposed based on density estimators to characterize them in feature spaces\nof DNNs [7]. More recently, Ma et al. [22] proposed the local intrinsic dimensionality (LID) and\nempirically showed that the characteristics of test samples can be estimated effectively using the\n\n32nd Conference on Neural Information Processing Systems (NIPS 2018), Montr\u00b4eal, Canada.\n\n\n-----\n\nLID. However, most prior works on this line typically do not evaluate both OOD and adversarial\nsamples. To best of our knowledge, no universal detector is known to work well on both tasks.\n\n**Contribution. In this paper, we propose a simple yet effective method, which is applicable to**\nany pre-trained softmax neural classifier (without re-training) for detecting abnormal test samples\nincluding OOD and adversarial ones. Our high-level idea is to measure the probability density of test\nsample on feature spaces of DNNs utilizing the concept of a \u201cgenerative\u201d (distance-based) classifier.\nSpecifically, we assume that pre-trained features can be fitted well by a class-conditional Gaussian\ndistribution since its posterior distribution can be shown to be equivalent to the softmax classifier\nunder Gaussian discriminant analysis (see Section 2.1 for our justification). Under this assumption,\nwe define the confidence score using the Mahalanobis distance with respect to the closest classconditional distribution, where its parameters are chosen as empirical class means and tied empirical\ncovariance of training samples. To the contrary of conventional beliefs, we found that using the\ncorresponding generative classifier does not sacrifice the softmax classification accuracy. Perhaps\nsurprisingly, its confidence score outperforms softmax-based ones very strongly across multiple\nother tasks: detecting OOD samples, detecting adversarial samples and class-incremental learning.\n\nWe demonstrate the effectiveness of the proposed method using deep convolutional neural networks,\nsuch as DenseNet [14] and ResNet [12] trained for image classification tasks on various datasets\nincluding CIFAR [15], SVHN [28], ImageNet [5] and LSUN [32]. First, for the problem of detecting\nOOD samples, the proposed method outperforms the current state-of-the-art method, ODIN [21], in\nall tested cases. In particular, compared to ODIN, our method improves the true negative rate (TNR),\ni.e., the fraction of detected OOD (e.g., LSUN) samples, from 45.6% to 90.9% on ResNet when\n95% of in-distribution (e.g., CIFAR-100) samples are correctly detected. Next, for the problem\nof detecting adversarial samples, e.g., generated by four attack methods such as FGSM [10], BIM\n\n[16], DeepFool [26] and CW [3], our method outperforms the state-of-the-art detection measure,\nLID [22]. In particular, compared to LID, ours improves the TNR of CW from 82.9% to 95.8% on\nResNet when 95% of normal CIFAR-10 samples are correctly detected.\n\nWe also found that our proposed method is more robust in the choice of its hyperparameters as well\nas against extreme scenarios, e.g., when the training dataset has some noisy, random labels or a\nsmall number of data samples. In particular, Liang et al. [21] tune the hyperparameters of ODIN\nusing validation sets of OOD samples, which is often impossible since the knowledge about OOD\nsamples is not accessible a priori. We show that hyperparameters of the proposed method can be\ntuned only using in-distribution (training) samples, while maintaining its performance. We further\nshow that the proposed method tuned on a simple attack, i.e., FGSM, can be used to detect other\nmore complex attacks such as BIM, DeepFool and CW.\n\nFinally, we apply our method to class-incremental learning [29]: new classes are added progressively\nto a pre-trained classifier. Since the new class samples are drawn from an out-of-training distribution,\nit is natural to expect that one can classify them using our proposed metric without re-training the\ndeep models. Motivated by this, we present a simple method which accommodates a new class at\nany time by simply computing the class mean of the new class and updating the tied covariance of all\nclasses. We show that the proposed method outperforms other baseline methods, such as Euclidean\ndistance-based classifier and re-trained softmax classifier. This evidences that our approach have a\npotential to apply to many other related machine learning tasks, such as active learning [8], ensemble\nlearning [19] and few-shot learning [31].\n\n###### 2 Mahalanobis distance-based score from generative classifier\n\nGiven deep neural networks (DNNs) with the softmax classifier, we propose a simple yet effective\nmethod for detecting abnormal samples such as out-of-distribution (OOD) and adversarial ones. We\nfirst present the proposed confidence score based on an induced generative classifier under Gaussian\ndiscriminant analysis (GDA), and then introduce additional techniques to improve its performance.\nWe also discuss how the confidence score is applicable to incremental learning.\n\n**2.1** **Why Mahalanobis distance-based score?**\n\n**Derivation of generative classifiers from softmax ones.** Let x \u2208X be an input and y \u2208\n= 1, _, C_ be its label. Suppose that a pre-trained softmax neural classifier is given:\n_Y_ _{_ _\u00b7 \u00b7 \u00b7_ _}_\n\n\n-----\n\n100\n\n90\n\n|Col1|1.00 0.95|\n|---|---|\n|0 0.2|0.90 0.85 0.4|\n||Softmax Euclidean Mahalanobis|\n\n\n0 0.5 1.0\n\n\n80\n\n70\n\n\n1.0\n\n0.8\n\n0.6\n\n0.4\n\n0.2\n\n0\n\n\nFPR on out-of-distribution (TinyImageNet)\n\n\n(a) Visualization by t-SNE\n\n\n(b) Classification accuracy\n\n\n(c) ROC curve\n\n\nFigure 1: Experimental results under the ResNet with 34 layers. (a) Visualization of final features\nfrom ResNet trained on CIFAR-10 by t-SNE, where the colors of points indicate the classes of the\ncorresponding objects. (b) Classification test set accuracy of ResNet on CIFAR-10, CIFAR-100 and\nSVHN datasets. (c) Receiver operating characteristic (ROC) curves: the x-axis and y-axis represent\nthe false positive rate (FPR) and true positive rate (TPR), respectively.\n\nexp(wc[\u22a4][f] [(][x][)+][b][c][)]\n_P (y = c|x) =_ \ufffdc[\u2032][ exp][(][w]c[\u22a4][\u2032] _[f]_ [(][x][)+][b][c][\u2032] [)] _[,][ where][ w][c][ and][ b][c][ are the weight and the bias of the soft-]_\n\nmax classifier for class c, and f ( ) denotes the output of the penultimate layer of DNNs. Then,\n\n_\u00b7_\nwithout any modification on the pre-trained softmax neural classifier, we obtain a generative classifier assuming that a class-conditional distribution follows the multivariate Gaussian distribution. Specifically, we define C class-conditional Gaussian distributions with a tied covariance \u03a3:\n_P (f_ (x)|y = c) = N (f (x)|\u00b5c, \u03a3), where \u00b5c is the mean of multivariate Gaussian distribution of\nclass c 1, ..., C . Here, our approach is based on a simple theoretical connection between GDA\n_\u2208{_ _}_\nand the softmax classifier: the posterior distribution defined by the generative classifier under GDA\nwith tied covariance assumption is equivalent to the softmax classifier (see the supplementary material for more details). Therefore, the pre-trained features of the softmax neural classifier f (x) might\nalso follow the class-conditional Gaussian distribution.\n\nTo estimate the parameters of the generative classifier from the pre-trained softmax neural classifier,\nwe compute the empirical class mean and covariance of training samples {(x1, y1), . . ., (xN _, yN_ )}:\n\n|Col1|Softmax|Col3|Col4|Col5|Ma|halanobis|Col8|\n|---|---|---|---|---|---|---|---|\n|||||||||\n|||||||||\n|||||||||\n|CIFA Cla he R -SN n tes char sitiv whe ote ined l di ndi||R-10 ssifi esN E, w t set acte e ra re w s th so stri tion|CIFAR Data catio et w her acc risti te ( a c e ou ftma butio al G|-100 sets n ac ith e th ura c (R TPR nd tput x n n f aus||SV cura 34 l e co cy o OC ), re b a c of eura ollo sian|HN cy aye lors f Re ) cu spe re t the l cl ws dis|\n\n\n_\u00b5c = [1]_\n\ufffd _Nc_\n\n\n\ufffd\n\n_f_ (xi), **\u03a3\ufffd** = [1]\n\n_N_\n\n_i:yi=c_\n\n\n\ufffd\n\n_c_\n\n\n\ufffd\n\n(f (xi) \u2212 _\u00b5\ufffdc) (f_ (xi) \u2212 _\u00b5\ufffdc)[\u22a4]_ _,_ (1)\n_i:yi=c_\n\n\nwhere Nc is the number of training samples with label c. This is equivalent to fitting the classconditional Gaussian distributions with a tied covariance to training samples under the maximum\nlikelihood estimator.\n\n**Mahalanobis distance-based confidence score. Using the above induced class-conditional Gaus-**\nsian distributions, we define the confidence score M (x) using the Mahalanobis distance between\ntest sample x and the closest class-conditional Gaussian distribution, i.e.,\n\n_M_ (x) = maxc _\u2212_ (f (x) \u2212 _\u00b5\ufffdc)[\u22a4]_ **\u03a3[\ufffd]** _[\u2212][1]_ (f (x) \u2212 _\u00b5\ufffdc) ._ (2)\n\n\nNote that this metric corresponds to measuring the log of the probability densities of the test sample.\nHere, we remark that abnormal samples can be characterized better in the representation space of\nDNNs, rather than the \u201clabel-overfitted\u201d output space of softmax-based posterior distribution used\nin the prior works [13, 21] for detecting them. It is because a confidence measure obtained from the\nposterior distribution can show high confidence even for abnormal samples that lie far away from\nthe softmax decision boundary. Feinman et al. [7] and Ma et al. [22] process the DNN features for\ndetecting adversarial samples in a sense, but do not utilize the Mahalanobis distance-based metric,\ni.e., they only utilize the Euclidean distance in their scores. In this paper, we show that Mahalanobis\ndistance is significantly more effective than the Euclidean distance in various tasks.\n\n**Experimental supports for generative classifiers. To evaluate our hypothesis that trained features**\nof DNNs support the assumption of GDA, we measure the classification accuracy as follows:\n\n_y\ufffd(x) = arg minc_ (f (x) \u2212 _\u00b5\ufffdc)[\u22a4]_ **\u03a3[\ufffd]** _[\u2212][1]_ (f (x) \u2212 _\u00b5\ufffdc) ._ (3)\n\n\n-----\n\n**Algorithm 1 Computing the Mahalanobis distance-based confidence score.**\n\n**Input: Test sample x, weights of logistic regression detector \u03b1\u2113, noise \u03b5 and parameters of Gaus-**\nsian distributions {\u00b5\ufffd\u2113,c, **\u03a3[\ufffd]** _\u2113_ : \u2200\u2113, c}\n\n\nInitialize score vectors: M(x) = [M\u2113 : \u2200\u2113]\n**for each layer \u2113** _\u2208_ 1, . . ., L do\n\nFind the closest class: \ufffdc = arg minc (f\u2113(x) \u2212 _\u00b5\ufffd\u2113,c)[\u22a4]\u03a3[\ufffd]_ _[\u2212]\u2113_ [1][(][f][\u2113][(][x][)][ \u2212] _[\u00b5][\ufffd][\u2113,c][)]_\n\n\ufffd \ufffd\nAdd small noise to test sample: \ufffdx = x \u2212 _\u03b5sign_ _\u25bdx (f\u2113(x) \u2212_ _\u00b5\ufffd\u2113,\ufffdc)[\u22a4]_ **\u03a3[\ufffd]** _[\u2212]\u2113_ [1] (f\u2113(x) \u2212 _\u00b5\ufffd\u2113,\ufffdc)_\n\nComputing confidence score: M\u2113 = maxc _\u2212_ (f\u2113(x\ufffd) \u2212 _\u00b5\ufffd\u2113,c)[\u22a4]_ **\u03a3[\ufffd]** _[\u2212]\u2113_ [1] (f\u2113(x\ufffd) \u2212 _\u00b5\ufffd\u2113,c)_\n\n**end for**\n**return Confidence score for test sample** _\u2113_ _[\u03b1][\u2113][M][\u2113]_\n\n[\ufffd]\n\n\n100\n\n90\n\n80\n\n70\n\n60\n\n\n100\n\n90\n\n80\n\n70\n\n60\n\n\n100\n\n90\n\n80\n\n70\n\n60\n\n50\n\n40\n\n30\n\n\n100\n\n90\n\n80\n\n70\n\n60\n\n50\n\n40\n\n30\n\n\n(a) TinyImageNet (b) LSUN (c) SVHN (d) DeepFool\n\nFigure 2: AUROC (%) of threshold-based detector using the confidence score in (2) computed at\ndifferent basic blocks of DenseNet trained on CIFAR-10 dataset. We measure the detection performance using (a) TinyImageNet, (b) LSUN, (c) SVHN and (d) adversarial (DeepFool) samples.\n\n|Col1|Col2|\n|---|---|\n|||\n|||\n|Index of b (c) SV|asic block HN|\n\n|Col1|Col2|\n|---|---|\n|||\n|||\n|Index of b (d) Dee|asic block pFool|\n\n\nWe remark that this corresponds to predicting a class label using the posterior distribution from generative classifier with the uniform class prior. Interestingly, we found that the softmax accuracy (red\nbar) is also achieved by the Mahalanobis distance-based classifier (blue bar), while conventional\nknowledge is that a generative classifier trained from scratch typically performs much worse than a\ndiscriminative classifier such as softmax. For visual interpretation, Figure 1(a) presents embeddings\nof final features from CIFAR-10 test samples constructed by t-SNE [23], where the colors of points\nindicate the classes of the corresponding objects. One can observe that all ten classes are clearly\nseparated in the embedding space, which supports our intuition. In addition, we also show that\nMahalanobis distance-based metric can be very useful in detecting out-of-distribution samples. For\nevaluation, we obtain the receiver operating characteristic (ROC) curve using a simple thresholdbased detector by computing the confidence score M (x) on a test sample x and decide it as positive\n(i.e., in-distribution) if M (x) is above some threshold. The Euclidean distance, which only utilizes\nthe empirical class means, is considered for comparison. We train ResNet on CIFAR-10, and TinyImageNet dataset [5] is used for an out-of-distribution. As shown in Figure 1(c), the Mahalanobis\ndistance-based metric (blue bar) performs better than Euclidean one (green bar) and the maximum\nvalue of the softmax distribution (red bar).\n\n**2.2** **Calibration techniques**\n\n|Col1|Col2|\n|---|---|\n|||\n|Index of b a) TinyIm re 2: AU rent basi ce using|asic block ageNet ROC (% c blocks (a) TinyI|\n\n|Col1|Col2|\n|---|---|\n|||\n|Index of b (b) LS eshold-b seNet tra et, (b) LS|asic block UN ased det ined on UN, (c)|\n\n\n**Input pre-processing. To make in- and out-of-distribution samples more separable, we consider**\nadding a small controlled noise to a test sample. Specifically, for each test sample x, we calculate\nthe pre-processed sample **x by adding the small perturbations as follows:**\n\ufffd\n\n\ufffd \ufffd\n**x\ufffd = x + \u03b5sign (\u25bdxM** (x)) = x \u2212 _\u03b5sign_ _\u25bdx (f_ (x) \u2212 _\u00b5\ufffd\ufffdc)[\u22a4]_ **\u03a3[\ufffd]** _[\u2212][1]_ (f (x) \u2212 _\u00b5\ufffd\ufffdc)_ _,_ (4)\n\nwhere \u03b5 is a magnitude of noise and _c is the index of the closest class. Next, we measure the confi-_\n\ufffd\ndence score using the pre-processed sample. We remark that the noise is generated to increase the\nproposed confidence score (2) unlike adversarial attacks [10]. In our experiments, such perturbation can have stronger effect on separating the in- and out-of-distribution samples. We remark that\nsimilar input pre-processing was studied in [21], where the perturbations are added to increase the\nsoftmax score of the predicted label. However, our method is different in that the noise is generated\nto increase the proposed metric.\n\n\n-----\n\n**Algorithm 2 Updating Mahalanobis distance-based classifier for class-incremental learning.**\n\n**Input: set of samples from a new class {xi : \u2200i = 1 . . . NC+1}, mean and covariance of observed**\nclasses {\u00b5\ufffdc : \u2200c = 1 . . . C}, **\u03a3[\ufffd]**\n\nCompute the new class mean: \ufffd\u00b5C+1 \u2190 _NC1+1_ \ufffdi _[f]_ [(][x][i][)]\n\nCompute the covariance of the new class: **\u03a3[\ufffd]** _C+1 \u2190_ _NC1+1_ \ufffdi[(][f] [(][x][i][)][ \u2212] _[\u00b5][\ufffd][C][+1][)(][f]_ [(][x][i][)][ \u2212] _[\u00b5][\ufffd][C][+1][)][\u22a4]_\n\nUpdate the shared covariance: **\u03a3[\ufffd]** _\u2190_ _CC+1_ **[\u03a3][\ufffd]** [ +] _C1+1_ **[\u03a3][\ufffd]** _[C][+1]_\n\n**return Mean and covariance of all classes {\u00b5\ufffdc : \u2200c = 1 . . . C + 1},** **\u03a3[\ufffd]**\n\n**Feature ensemble. To further improve the performance, we consider measuring and combining the**\nconfidence scores from not only the final features but also the other low-level features in DNNs.\nFormally, given training data, we extract the \u2113-th hidden features of DNNs, denoted by f\u2113(x), and\ncompute their empirical class means and tied covariances, i.e., _\u00b5\u2113,c and_ **\u03a3\u2113. Then, for each test**\n\ufffd [\ufffd]\nsample x, we measure the confidence score from the \u2113-th layer using the formula in (2). One can\nexpect that this simple but natural scheme can bring an extra gain in obtaining a better calibrated\nscore by extracting more input-specific information from the low-level features. We measure the\narea under ROC (AUROC) curves of the threshold-based detector using the confidence score in\n(2) computed at different basic blocks of DenseNet [14] trained on CIFAR-10 dataset, where the\noverall trends on ResNet are similar. Figure 2 shows the performance on various OOD samples such\nas SVHN [28], LSUN [32], TinyImageNet and adversarial samples generated by DeepFool [26],\nwhere the dimensions of the intermediate features are reduced using average pooling (see Section\n3 for more details). As shown in Figure 2, the confidence scores computed at low-level features\noften provide better calibrated ones compared to final features (e.g., LSUN, TinyImageNet and\nDeepFool). To further improve the performance, we design a feature ensemble method as described\nin Algorithm 1. We first extract the confidence scores from all layers, and then integrate them by\nweighted averaging: [\ufffd]\u2113 _[\u03b1][\u2113][M][\u2113][(][x][)][, where][ M][\u2113][(][\u00b7][)][ and][ \u03b1][\u2113]_ [is the confidence score at the][ \u2113][-th layer]\n\nand its weight, respectively. In our experiments, following similar strategies in [22], we choose\nthe weight of each layer \u03b1\u2113 by training a logistic regression detector using validation samples. We\nremark that such weighted averaging of confidence scores can prevent the degradation on the overall\nperformance even in the case when the confidence scores from some layers are not effective: the\ntrained weights (using validation) would be nearly zero for those ineffective layers.\n\n\n**2.3** **Class-incremental learning using Mahalanobis distance-based score**\n\nAs a natural extension, we also show that the Mahalanobis distance-based confidence score can be\nutilized in class-incremental learning tasks [29]: a classifier pre-trained on base classes is progressively updated whenever a new class with corresponding samples occurs. This task is known to be\nchallenging since one has to deal with catastrophic forgetting [24] with a limited memory. To this\nend, recent works have been toward developing new training methods which involve a generative\nmodel or data sampling, but adopting such training methods might incur expensive back-and-forth\ncosts. Based on the proposed confidence score, we develop a simple classification method without\nthe usage of complicated training methods. To do this, we first assume that the classifier is well\npre-trained with a certain amount of base classes, where the assumption is quite reasonable in many\npractical scenarios.[1] In this case, one can expect that not only the classifier can detect OOD samples\nwell, but also might be good for discriminating new classes, as the representation learned with the\nbase classes can characterize new ones. Motivated by this, we present a Mahalanobis distance-based\nclassifier based on (3), which tries to accommodate a new class by simply computing and updating\nthe class mean and covariance, as described in Algorithm 2. The class-incremental adaptation of our\nconfidence score shows its potential to be applied to a wide range of new applications in the future.\n\n1For example, state-of-the-art CNNs trained on large-scale image dataset are off-the-shelf [12, 14], so they\nare a starting point in many computer vision tasks [9, 18, 25].\n\n\n-----\n\nFeature Input TNR Detection AUPR AUPR\nMethod AUROC\nensemble pre-processing at TPR 95% accuracy in out\n\nBaseline [13] - - 32.47 89.88 85.06 85.40 93.96\n\nODIN [21] - - 86.55 96.65 91.08 92.54 98.52\n\n\nMahalanobis\n(ours)\n\n\n - - 54.51 93.92 89.13 91.56 95.95\n - \u2713 92.26 98.30 93.72 96.01 99.28\n\u2713 - 91.45 98.37 93.55 96.43 99.35\n\u2713 \u2713 **96.42** **99.14** **95.75** **98.26** **99.60**\n\n\nTable 1: Contribution of each proposed method on distinguishing in- and out-of-distribution test\nset data. We measure the detection performance using ResNet trained on CIFAR-10, when SVHN\ndataset is used as OOD. All values are percentages and the best results are indicated in bold.\n\n###### 3 Experimental results\n\nIn this section, we demonstrate the effectiveness of the proposed method using deep convolutional\nneural networks such as DenseNet [14] and ResNet [12] on various vision datasets: CIFAR [15],\nSVHN [28], ImageNet [5] and LSUN [32]. Due to the space limitation, we provide the more detailed\n[experimental setups and results in the supplementary material. Our code is available at https:](https://github.com/pokaxpoka/deep_Mahalanobis_detector)\n```\n//github.com/pokaxpoka/deep_Mahalanobis_detector.\n\n```\n**3.1** **Detecting out-of-distribution samples**\n\n**Setup. For the problem of detecting out-of-distribution (OOD) samples, we train DenseNet with 100**\nlayers and ResNet with 34 layers for classifying CIFAR-10, CIFAR-100 and SVHN datasets. The\ndataset used in training is the in-distribution (positive) dataset and the others are considered as OOD\n(negative). We only use test datasets for evaluation. In addition, the TinyImageNet (i.e., subset of\nImageNet dataset) and LSUN datasets are also tested as OOD. For evaluation, we use a thresholdbased detector which measures some confidence score of the test sample, and then classifies the\ntest sample as in-distribution if the confidence score is above some threshold. We measure the\nfollowing metrics: the true negative rate (TNR) at 95% true positive rate (TPR), the area under the\nreceiver operating characteristic curve (AUROC), the area under the precision-recall curve (AUPR),\nand the detection accuracy. For comparison, we consider the baseline method [13], which defines\na confidence score as a maximum value of the posterior distribution, and the state-of-the-art ODIN\n\n[21], which defines the confidence score as a maximum value of the processed posterior distribution.\n\nFor our method, we extract the confidence scores from every end of dense (or residual) block of\nDenseNet (or ResNet). The size of feature maps on each convolutional layers is reduced by average\npooling for computational efficiency: 1, where is the number of channels\n_F \u00d7 H \u00d7 W \u2192F \u00d7_ _F_\nand is the spatial dimension. As shown in Algorithm 1, the output of the logistic regres_H \u00d7 W_\nsion detector is used as the final confidence score in our case. All hyperparameters are tuned on a\nseparate validation set, which consists of 1,000 images from each in- and out-of-distribution pair.\nSimilar to Ma et al. [22], the weights of logistic regression detector are trained using nested cross\nvalidation within the validation set, where the class label is assigned positive for in-distribution samples and assigned negative for OOD samples. Since one might not have OOD validation datasets in\npractice, we also consider tuning the hyperparameters using in-distribution (positive) samples and\ncorresponding adversarial (negative) samples generated by FGSM [10].\n\n**Contribution by each technique and comparison with ODIN. Table 1 validates the contributions**\nof our suggested techniques under the comparison with the baseline method and ODIN. We measure\nthe detection performance using ResNet trained on CIFAR-10, when SVHN dataset is used as OOD.\nWe incrementally apply our techniques to see the stepwise improvement by each component. One\ncan note that our method significantly outperforms the baseline method without feature ensembles\nand input pre-processing. This implies that our method can characterize the OOD samples very\neffectively compared to the posterior distribution. By utilizing the feature ensemble and input preprocessing, the detection performance are further improved compared to that of ODIN. The left-hand\ncolumn of Table 2 reports the detection performance with ODIN for all in- and out-of-distribution\n\n\n-----\n\n|Validation on OOD samples In-dist OOD TNR at TPR 95% AUROC Detection acc. (model) Baseline [13] / ODIN [21] / Mahalanobis (ours)|Validation on adversarial samples TNR at TPR 95% AUROC Detection acc.|\n|---|---|\n||Baseline [13] / ODIN [21] / Mahalanobis (ours)|\n|SVHN 40.2 / 86.2 / 90.8 89.9 / 95.5 / 98.1 83.2 / 91.4 / 93.9 CIFAR-10 TinyImageNet 58.9 / 92.4 / 95.0 94.1 / 98.5 / 98.8 88.5 / 93.9 / 95.0 (DenseNet) LSUN 66.6 / 96.2 / 97.2 95.4 / 99.2 / 99.3 90.3 / 95.7 / 96.3|40.2 / 70.5 / 89.6 89.9 / 92.8 / 97.6 83.2 / 86.5 / 92.6 58.9 / 87.1 / 94.9 94.1 / 97.2 / 98.8 88.5 / 92.1 / 95.0 66.6 / 92.9 / 97.2 95.4 / 98.5 / 99.2 90.3 / 94.3 / 96.2|\n|SVHN 26.7 / 70.6 / 82.5 82.7 / 93.8 / 97.2 75.6 / 86.6 / 91.5 CIFAR-100 TinyImageNet 17.6 / 42.6 / 86.6 71.7 / 85.2 / 97.4 65.7 / 77.0 / 92.2 (DenseNet) LSUN 16.7 / 41.2 / 91.4 70.8 / 85.5 / 98.0 64.9 / 77.1 / 93.9|26.7 / 39.8 / 62.2 82.7 / 88.2 / 91.8 75.6 / 80.7 / 84.6 17.6 / 43.2 / 87.2 71.7 / 85.3 / 97.0 65.7 / 77.2 / 91.8 16.7 / 42.1 / 91.4 70.8 / 85.7 / 97.9 64.9 / 77.3 / 93.8|\n|CIFAR-10 69.3 / 71.7 / 96.8 91.9 / 91.4 / 98.9 86.6 / 85.8 / 95.9 SVHN TinyImageNet 79.8 / 84.1 / 99.9 94.8 / 95.1 / 99.9 90.2 / 90.4 / 98.9 (DenseNet) LSUN 77.1 / 81.1 / 100 94.1 / 94.5 / 99.9 89.1 / 89.2 / 99.3|69.3 / 69.3 / 97.5 91.9 / 91.9 / 98.8 86.6 / 86.6 / 96.3 79.8 / 79.8 / 99.9 94.8 / 94.8 / 99.8 90.2 / 90.2 / 98.9 77.1 / 77.1 / 100 94.1 / 94.1 / 99.9 89.1 / 89.1 / 99.2|\n|SVHN 32.5 / 86.6 / 96.4 89.9 / 96.7 / 99.1 85.1 / 91.1 / 95.8 CIFAR-10 TinyImageNet 44.7 / 72.5 / 97.1 91.0 / 94.0 / 99.5 85.1 / 86.5 / 96.3 (ResNet) LSUN 45.4 / 73.8 / 98.9 91.0 / 94.1 / 99.7 85.3 / 86.7 / 97.7|32.5 / 40.3 / 75.8 89.9 / 86.5 / 95.5 85.1 / 77.8 / 89.1 44.7 / 69.6 / 95.5 91.0 / 93.9 / 99.0 85.1 / 86.0 / 95.4 45.4 / 70.0 / 98.1 91.0 / 93.7 / 99.5 85.3 / 85.8 / 97.2|\n|SVHN 20.3 / 62.7 / 91.9 79.5 / 93.9 / 98.4 73.2 / 88.0 / 93.7 CIFAR-100 TinyImageNet 20.4 / 49.2 / 90.9 77.2 / 87.6 / 98.2 70.8 / 80.1 / 93.3 (ResNet) LSUN 18.8 / 45.6 / 90.9 75.8 / 85.6 / 98.2 69.9 / 78.3 / 93.5|20.3 / 12.2 / 41.9 79.5 / 72.0 / 84.4 73.2 / 67.7 / 76.5 20.4 / 33.5 / 70.3 77.2 / 83.6 / 87.9 70.8 / 75.9 / 84.6 18.8 / 31.6 / 56.6 75.8 / 81.9 / 82.3 69.9 / 74.6 / 79.7|\n|CIFAR-10 78.3 / 79.8 / 98.4 92.9 / 92.1 / 99.3 90.0 / 89.4 / 96.9 SVHN TinyImageNet 79.0 / 82.1 / 99.9 93.5 / 92.0 / 99.9 90.4 / 89.4 / 99.1 (ResNet) LSUN 74.3 / 77.3 / 99.9 91.6 / 89.4 / 99.9 89.0 / 87.2 / 99.5|78.3 / 79.8 / 94.1 92.9 / 92.1 / 97.6 90.0 / 89.4 / 94.6 79.0 / 80.5 / 99.2 93.5 / 92.9 / 99.3 90.4 / 90.1 / 98.8 74.3 / 76.3 / 99.9 91.6 / 90.7 / 99.9 89.0 / 88.2 / 99.5|\n\n\nTable 2: Distinguishing in- and out-of-distribution test set data for image classification under various\nvalidation setups. All values are percentages and the best results are indicated in bold.\n\n\n100\n\n90\n\n80\n\n70\n\n60\n\n\n100\n\n90\n\n80\n\n70\n\n60\n\n\n100\n\n90\n\n80\n\n\nOut-of-distribution: SVHN\n\n\nOut-of-distribution: TinyImageNet\n\n\nOut-of-distribution: SVHN\n\n\nOut-of-distribution: TinyImageNet\n\n\nBaseline\n\n70 ODIN\n\nMahalanobis\n60\n\n\n100\n\n90\n\n80\n\n70\n\n60\n\n\n(a) Small number of training data\n\n\n(b) Training data with random labels\n\n\nFigure 3: Comparison of AUROC (%) under extreme scenarios: (a) small number of training data,\nwhere the x-axis represents the number of training data. (b) Random label is assigned to training\ndata, where the x-axis represents the percentage of training data with random label.\n\ndataset pairs. Our method outperforms the baseline and ODIN for all tested cases. In particular,\nour method improves the TNR, i.e., the fraction of detected LSUN samples, compared to ODIN:\n41.2% 91.4% using DenseNet, when 95% of CIFAR-100 samples are correctly detected.\n_\u2192_\n\n**Comparison of robustness. In order to evaluate the robustness of our method, we measure the**\ndetection performance when all hyperparameters are tuned only using in-distribution and adversarial\nsamples generated by FGSM [10]. As shown in the right-hand column of Table 2, ODIN is working\npoorly compared to the baseline method in some cases (e.g., DenseNet trained on SVHN), while our\nmethod still outperforms the baseline and ODIN consistently. We remark that our method validated\nwithout OOD but adversarial samples even outperforms ODIN validated with OOD. We also verify\nthe robustness of our method under various training setups. Since our method utilizes empirical\nclass mean and covariance of training samples, there is a caveat such that it can be affected by the\nproperties of training data. In order to verify the robustness, we measure the detection performance\nwhen we train ResNet by varying the number of training data and assigning random label to training\ndata on CIFAR-10 dataset. As shown in Figure 3, our method (blue bar) maintains high detection\nperformances even for small number of training data or noisy one, while baseline (red bar) and ODIN\n(yellow bar) do not. Finally, we remark that our method using softmax neural classifier trained by\nstandard cross entropy loss typically outperforms the ODIN using softmax neural classifier trained\nby confidence loss [20] which involves jointly training a generator and a classifier to calibrate the\nposterior distribution even though training such model is computationally more expensive (see the\nsupplementary material for more details).\n\n**3.2** **Detecting adversarial samples**\n\n**Setup. For the problem of detecting adversarial samples, we train DenseNet and ResNet for classi-**\nfying CIFAR-10, CIFAR-100 and SVHN datasets, and the corresponding test dataset is used as the\n\n|Col1|Col2|Col3|Col4|Col5|Col6|Col7|Col8|Col9|Col10|Col11|Col12|Col13|Col14|Col15|\n|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n||||||||||||||||\n||||||||B O M|as D a|el IN ha|in la|e n|ob|is||\n||||||||||||||||\n|ur r ,|5K e e|w|1 3 th h|0 : e|K ( e r|20K a) Co x- e t|30 Sm m axi he|K a p s x|4 l ar -|0 l i r a|K n s e x|5 u o p i|0 m n r s|K e|\n\n|Col1|Col2|Col3|Col4|Col5|Col6|Col7|Col8|Col9|Col10|Col11|Col12|Col13|Col14|Col15|\n|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n||||||||B|as|el|in|e||||\n||||||||O M|DI a|N ha|la|n|ob|is||\n|t U t e|5K ra R h n|i e t|1 n O s|0 i C n|K n u th|20K g d (% mb e|30 ata ) er per|K u c|4 n o e|0 d f n|K e t t|5 r r a|0 e a g|K i e|\n\n|Col1|Col2|Col3|Col4|Col5|Col6|Col7|Col8|Col9|Col10|Col11|Col12|Col13|Col14|Col15|\n|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n||B|as|eli|n|e||||||||||\n||O M|D a|IN hal|a|no|bi|s||||||||\n||||||||||||||||\n|0% sc ta ni|e . n|1 ( n ( g|0% b a b d|) r )|2 io at|0 Tr s R a|% a : a|3 in ( n w|0 i a d i|% n ) o th|4 g s m|0 d ra|% a m l n|t a a|\n\n|Col1|Col2|Col3|Col4|Col5|Col6|Col7|Col8|Col9|Col10|Col11|Col12|Col13|Col14|Col15|\n|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n||B|as|el|in|e||||||||||\n||O M|D a|IN ha|la|no|bi|s||||||||\n||||||||||||||||\n|0% ra b a ab|n e ss e|1 d r i l.|0 o o g|% m f n|2 l t e|0 a r d|% b ai t|3 el n o|0 s i|% n tr|4 g a|0 d i|% a n|t i|\n\n\n-----\n\n|Dataset Model Score (model)|Detection of known attack FGSM BIM DeepFool CW|Detection of unknown attack FGSM (seen) BIM DeepFool CW|\n|---|---|---|\n|KD+PU [7] CIFAR-10 LID [22] Mahalanobis (ours) KD+PU [7] DenseNet CIFAR-100 LID [22] Mahalanobis (ours) KD+PU [7] SVHN LID [22] Mahalanobis (ours)|85.96 96.80 68.05 58.72 98.20 99.74 85.14 80.05 99.94 99.78 83.41 87.31|85.96 3.10 68.34 53.21 98.20 94.55 70.86 71.50 99.94 99.51 83.42 87.95|\n||90.13 89.69 68.29 57.51 99.35 98.17 70.17 73.37 99.86 99.17 77.57 87.05|90.13 66.86 65.30 58.08 99.35 68.62 69.68 72.36 99.86 98.27 75.63 86.20|\n||86.95 82.06 89.51 85.68 99.35 94.87 91.79 94.70 99.85 99.28 95.10 97.03|86.95 83.28 84.38 82.94 99.35 92.21 80.14 85.09 99.85 99.12 93.47 96.95|\n|KD+PU [7] CIFAR-10 LID [22] Mahalanobis (ours) KD+PU [7] ResNet CIFAR-100 LID [22] Mahalanobis (ours) KD+PU [7] SVHN LID [22] Mahalanobis (ours)|81.21 82.28 81.07 55.93 99.69 96.28 88.51 82.23 99.94 99.57 91.57 95.84|83.51 16.16 76.80 56.30 99.69 95.38 71.86 77.53 99.94 98.91 78.06 93.90|\n||89.90 83.67 80.22 77.37 98.73 96.89 71.95 78.67 99.77 96.90 85.26 91.77|89.90 68.85 57.78 73.72 98.73 55.82 63.15 75.03 99.77 96.38 81.95 90.96|\n||82.67 66.19 89.71 76.57 97.86 90.74 92.40 88.24 99.62 97.15 95.73 92.15|82.67 43.21 84.30 67.85 97.86 84.88 67.28 76.58 99.62 95.39 72.20 86.73|\n\n\nTable 3: Comparison of AUROC (%) under various validation setups. For evaluation on unknown\nattack, FGSM samples denoted by \u201cseen\u201d are used for validation. For our method, we use both\nfeature ensemble and input pre-processing. The best results are indicated in bold.\n\npositive samples to measure the performance. We use adversarial images as the negative samples\ngenerated by the following attack methods: FGSM [10], BIM [16], DeepFool [26] and CW [3],\nwhere the detailed explanations can be found in the supplementary material. For comparison, we\nuse a logistic regression detector based on combinations of kernel density (KD) [7] and predictive\nuncertainty (PU), i.e., maximum value of posterior distribution. We also compare the state-of-theart local intrinsic dimensionality (LID) scores [22]. Following the similar strategies in [7, 22], we\nrandomly choose 10% of original test samples for training the logistic regression detectors and the\nremaining test samples are used for evaluation. Using nested cross-validation within the training set,\nall hyper-parameters are tuned.\n\n**Comparison with LID and generalization analysis. The left-hand column of Table 3 reports the**\nAUROC score of a logistic regression detectors for all normal and adversarial pairs. One can note\nthat the proposed method outperforms all tested methods in most cases. In particular, ours improves\nthe AUROC of LID from 82.2% to 95.8% when we detect CW samples using ResNet trained on\nthe CIFAR-10 dataset. Similar to [22], we also evaluate whether the proposed method is tuned on\na simple attack can be generalized to detect other more complex attacks. To this end, we measure\nthe detection performance when we train the logistic regression detector using samples generated by\nFGSM. As shown in the right-hand column of Table 3, our method trained on FGSM can accurately\ndetect much more complex attacks such as BIM, DeepFool and CW. Even though LID can also\ngeneralize well, our method still outperforms it in most cases. A natural question that arises is\nwhether the LID can be useful in detecting OOD samples. We indeed compare the performance of\nour method with that of LID in the supplementary material, where our method still outperforms LID\nin all tested case.\n\n**3.3** **Class-incremental learning**\n\n**Setup. For the task of class-incremental learning, we train ResNet with 34 layers for classifying**\nCIFAR-100 and downsampled ImageNet [4]. As described in Section 2.3, we assume that a classifier\nis pre-trained on a certain amount of base classes and new classes with corresponding datasets are\nincrementally provided one by one. Specifically, we test two different scenarios: in the first scenario,\nhalf of CIFAR-100 classes are bases classes and the rest are new classes. In the second scenario,\nall classes in CIFAR-100 are considered to be base classes and 100 of ImageNet classes are new\nclasses. All scenarios are tested five times and then averaged. Class splits are randomly generated\nfor each trial. For comparison, we consider a softmax classifier, which is fine-tuned whenever new\nclass data come in, and a Euclidean classifier [25], which tries to accommodate a new class by only\ncomputing the class mean. For the softmax classifier, we only update the softmax layer to achieve\nnear-zero cost training [25], and follow the memory management in Rebuffi & Kolesnikov [29]: a\nsmall number of samples from old classes are kept in the limited memory, where the size of the\n\n\n-----\n\n80\n\n70\n\n60\n\n50\n\n40\n\n30\n\n|Col1|Col2|Col3|S E|oftmax uclidean|Col6|\n|---|---|---|---|---|---|\n|||M||ahalanobi|s (ours)|\n|||||||\n|||||||\n|||||||\n\n|Col1|Col2|Col3|Col4|\n|---|---|---|---|\n|||||\n|||||\n|||||\n|Softma|x|||\n|Euclide Mahala|an nobis (ours)|||\n\n|Col1|Col2|S E M|S E|oftmax uclidean|Col6|\n|---|---|---|---|---|---|\n|||||ahalanobi|s (ours)|\n|||||||\n|||||||\n|||||||\n\n|Col1|Col2|Col3|Col4|Col5|\n|---|---|---|---|---|\n||||||\n||||||\n|Softma|x||||\n|Euclide Mahala|an nobis (ours)||||\n\n\n50 60 70 80 90 100\n\nThe number of classes\n\n\n0 20 40 60 80\n\nBase class accuracy (%)\n\n\n80\n\n60\n\n\n30\n\n20\n\n\n40\n\n20\n\n\n0 20 40 60 80\n\nBase class accuracy (%)\n\n\n60\n\n50\n\n40\n\n30\n\n20\n\n10\n\n0\n\n\n100 120 140 160 180 200\n\nThe number of classes\n\n\n10\n\n0\n\n\n(a) Base: half of CIFAR-100 / New: the other half\n\n\n(b) Base: CIFAR-100 / New: ImageNet\n\n\nFigure 4: Experimental results of class-incremental learning on CIFAR-100 and ImageNet datasets.\nIn each experiment, we report (left) AUC with respect to the number of learned classes and, (right)\nthe base-new class accuracy curve after the last new classes is added.\n\nmemory is matched with that for keeping the parameters for Mahalanobis distance-based classifier.\nNamely, the number of old exemplars kept for training the softmax classifier is chosen as the sum of\nthe number of learned classes and the dimension (512 in our experiments) of the hidden features. For\nevaluation, similar to [18], we first draw base-new class accuracy curve by adjusting an additional\nbias to the new class scores, and measure the area under curve (AUC) since averaging base and new\nclass accuracy may cause an imbalanced measure of the performance between base and new classes.\n\n**Comparison with other classifiers. Figure 4 compares the incremental learning performance of**\nmethods in terms of AUC in the two scenarios mentioned above. In each sub-figure, AUC with respect to the number of learned classes (left) and the base-new class accuracy curve after the last new\nclasses is added (right) are drawn. Our proposed Mahalanobis distance-based classifier outperforms\nthe other methods by a significant margin, as the number of new classes increases, although there\nis a crossing in the right figure of Figure 4(b) in small regimes (due to the catastrophic forgetting\nissue). In particular, the AUC of our proposed method is 40.0% (22.1%), which is better than 32.7%\n(15.6%) of the softmax classifier and 32.9% (17.1%) of the Euclidean distance classifier after all\nnew classes are added in the first (second) experiment. We also report the experimental results in\nthe supplementary material for the case when classes of CIFAR-100 are base classes and those of\nCIFAR-10 are new classes, where the overall trend is similar. The experimental results additionally\ndemonstrate the superiority of our confidence score, compared to other plausible ones.\n\n\n###### 4 Conclusion\n\nIn this paper, we propose a simple yet effective method for detecting abnormal test samples including\nboth out-of-distribution and adversarial ones. In essence, our main idea is inducing a generative\nclassifier under LDA assumption, and defining new confidence score based on it. With calibration\ntechniques such as input pre-processing and feature ensemble, our method performs very strongly\nacross multiple tasks: detecting out-of-distribution samples, detecting adversarial attacks and classincremental learning. We also found that our proposed method is more robust in the choice of its\nhyperparameters as well as against extreme scenarios, e.g., when the training dataset has some noisy,\nrandom labels or a small number of data samples. We believe that our approach have a potential to\napply to many other related machine learning tasks, e.g., active learning [8], ensemble learning [19]\nand few-shot learning [31].\n\n\n**Acknowledgements**\n\nThis work was supported in part by Institute for Information & communications Technology Promotion (IITP) grant funded by the Korea government (MSIT) (No.R0132-15-1005, Content visual\nbrowsing technology in the online and offline environments), National Research Council of Science\n& Technology (NST) grant by the Korea government (MSIP) (No. CRC-15-05-ETRI), DARPA\nExplainable AI (XAI) program #313498, Sloan Research Fellowship, and Kwanjeong Educational\nFoundation Scholarship.\n\n\n-----\n\n###### References\n\n[1] Amodei, Dario, Ananthanarayanan, Sundaram, Anubhai, Rishita, Bai, Jingliang, Battenberg,\nEric, Case, Carl, Casper, Jared, Catanzaro, Bryan, Cheng, Qiang, Chen, Guoliang, et al. Deep\nspeech 2: End-to-end speech recognition in english and mandarin. In ICML, 2016.\n\n[2] Amodei, Dario, Olah, Chris, Steinhardt, Jacob, Christiano, Paul, Schulman, John, and Man\u00b4e,\nDan. Concrete problems in ai safety. arXiv preprint arXiv:1606.06565, 2016.\n\n[3] Carlini, Nicholas and Wagner, David. Adversarial examples are not easily detected: Bypassing\nten detection methods. In ACM workshop on AISec, 2017.\n\n[4] Chrabaszcz, Patryk, Loshchilov, Ilya, and Hutter, Frank. A downsampled variant of imagenet\nas an alternative to the cifar datasets. arXiv preprint arXiv:1707.08819, 2017.\n\n[5] Deng, Jia, Dong, Wei, Socher, Richard, Li, Li-Jia, Li, Kai, and Fei-Fei, Li. Imagenet: A\nlarge-scale hierarchical image database. In CVPR, 2009.\n\n[6] Evtimov, Ivan, Eykholt, Kevin, Fernandes, Earlence, Kohno, Tadayoshi, Li, Bo, Prakash, Atul,\nRahmati, Amir, and Song, Dawn. Robust physical-world attacks on machine learning models.\nIn CVPR, 2018.\n\n[7] Feinman, Reuben, Curtin, Ryan R, Shintre, Saurabh, and Gardner, Andrew B. Detecting adversarial samples from artifacts. arXiv preprint arXiv:1703.00410, 2017.\n\n[8] Gal, Yarin, Islam, Riashat, and Ghahramani, Zoubin. Deep bayesian active learning with image\ndata. In ICML, 2017.\n\n[9] Girshick, Ross. Fast r-cnn. In ICCV, 2015.\n\n[10] Goodfellow, Ian J, Shlens, Jonathon, and Szegedy, Christian. Explaining and harnessing adversarial examples. In ICLR, 2015.\n\n[11] Guo, Chuan, Rana, Mayank, Ciss\u00b4e, Moustapha, and van der Maaten, Laurens. Countering\nadversarial images using input transformations. arXiv preprint arXiv:1711.00117, 2017.\n\n[12] He, Kaiming, Zhang, Xiangyu, Ren, Shaoqing, and Sun, Jian. Deep residual learning for image\nrecognition. In CVPR, 2016.\n\n[13] Hendrycks, Dan and Gimpel, Kevin. A baseline for detecting misclassified and out-ofdistribution examples in neural networks. In ICLR, 2017.\n\n[14] Huang, Gao and Liu, Zhuang. Densely connected convolutional networks. In CVPR, 2017.\n\n[15] Krizhevsky, Alex and Hinton, Geoffrey. Learning multiple layers of features from tiny images.\n2009.\n\n[16] Kurakin, Alexey, Goodfellow, Ian, and Bengio, Samy. Adversarial examples in the physical\nworld. arXiv preprint arXiv:1607.02533, 2016.\n\n[17] Lasserre, Julia A, Bishop, Christopher M, and Minka, Thomas P. Principled hybrids of generative and discriminative models. In CVPR, 2006.\n\n[18] Lee, Kibok, Lee, Kimin, Min, Kyle, Zhang, Yuting, Shin, Jinwoo, and Lee, Honglak. Hierarchical novelty detection for visual object recognition. In CVPR, 2018.\n\n[19] Lee, Kimin, Hwang, Changho, Park, KyoungSoo, and Shin, Jinwoo. Confident multiple choice\nlearning. In ICML, 2017.\n\n[20] Lee, Kimin, Lee, Honglak, Lee, Kibok, and Shin, Jinwoo. Training confidence-calibrated\nclassifiers for detecting out-of-distribution samples. In ICLR, 2018.\n\n[21] Liang, Shiyu, Li, Yixuan, and Srikant, R. Principled detection of out-of-distribution examples\nin neural networks. In ICLR, 2018.\n\n\n-----\n\n[22] Ma, Xingjun, Li, Bo, Wang, Yisen, Erfani, Sarah M, Wijewickrema, Sudanthi, Houle,\nMichael E, Schoenebeck, Grant, Song, Dawn, and Bailey, James. Characterizing adversarial subspaces using local intrinsic dimensionality. In ICLR, 2018.\n\n[23] Maaten, Laurens van der and Hinton, Geoffrey. Visualizing data using t-sne. _Journal of_\n_machine learning research, 2008._\n\n[24] McCloskey, Michael and Cohen, Neal J. Catastrophic interference in connectionist networks:\nThe sequential learning problem. In Psychology of learning and motivation. Elsevier, 1989.\n\n[25] Mensink, Thomas, Verbeek, Jakob, Perronnin, Florent, and Csurka, Gabriela. Distance-based\nimage classification: Generalizing to new classes at near-zero cost. IEEE transactions on\n_pattern analysis and machine intelligence, 2013._\n\n[26] Moosavi Dezfooli, Seyed Mohsen, Fawzi, Alhussein, and Frossard, Pascal. Deepfool: a simple\nand accurate method to fool deep neural networks. In CVPR, 2016.\n\n[27] Murphy, Kevin P. Machine learning: a probabilistic perspective. 2012.\n\n[28] Netzer, Yuval, Wang, Tao, Coates, Adam, Bissacco, Alessandro, Wu, Bo, and Ng, Andrew Y.\nReading digits in natural images with unsupervised feature learning. In NIPS workshop, 2011.\n\n[29] Rebuffi, Sylvestre-Alvise and Kolesnikov, Alexander. icarl: Incremental classifier and representation learning. In CVPR, 2017.\n\n[30] Sharif, Mahmood, Bhagavatula, Sruti, Bauer, Lujo, and Reiter, Michael K. Accessorize to a\ncrime: Real and stealthy attacks on state-of-the-art face recognition. In ACM SIGSAC, 2016.\n\n[31] Vinyals, Oriol, Blundell, Charles, Lillicrap, Tim, Wierstra, Daan, et al. Matching networks for\none shot learning. In NIPS, 2016.\n\n[32] Yu, Fisher, Seff, Ari, Zhang, Yinda, Song, Shuran, Funkhouser, Thomas, and Xiao, Jianxiong.\nLsun: Construction of a large-scale image dataset using deep learning with humans in the loop.\n_arXiv preprint arXiv:1506.03365, 2015._\n\n\n-----\n\n### Supplementary Material:\n\n##### A Simple Unified Framework for Detecting Out-of-Distribution Samples and Adversarial Attacks\n\n###### A Preliminaries for Gaussian discriminant analysis\n\nIn this section, we describe the basic concept of the discriminative and generative classifier [27].\nFormally, denote the random variable of the input and label as x and y = 1, _, C_,\n_\u2208X_ _\u2208Y_ _{_ _\u00b7 \u00b7 \u00b7_ _}_\nrespectively. For the classification task, the discriminative classifier directly defines a posterior distribution P (y **x), i.e., learning a direct mapping between input x and label y. A popular model**\n_|_\nfor discriminative classifier is softmax classifier which defines the posterior distribution as follows:\n\nexp(wc[\u22a4][x][+][b][c][)]\n_P (y = c|x) =_ \ufffdc[\u2032][ exp][(][w]c[\u22a4][\u2032] **[x][+][b][c][\u2032]** [)] _[,][ where][ w][c][ and][ b][c][ are weights and bias for a class][ c][, respectively.]_\n\nIn contrast to the discriminative classifier, the generative classifier defines the class conditional distribution P (x _y) and class prior P (y) in order to indirectly define the posterior distribution by_\n_|_\nspecifying the joint distribution P (x, y) = P (y) P (x _y). Gaussian discriminant analysis (GDA) is_\n_|_\na popular method to define the generative classifier by assuming that the class conditional distribution follows the multivariate Gaussian distribution and the class prior follows Bernoulli distribution:\n_P (x|y = c) = N (x|\u00b5c, \u03a3c), P (y = c) =_ \ufffdc\u03b2[\u2032][ \u03b2]c _c[\u2032][,][ where][ \u00b5][c][ and][ \u03a3][c][ are the mean and covariance]_\n\nof multivariate Gaussian distribution, and \u03b2c is the unnormalized prior for class c. This classifier has\nbeen studied in various machine learning areas (e.g., semi-supervised learning [17] and incremental\nlearning [29]).\n\nIn this paper, we focus on the special case of GDA, also known as the linear discriminant analysis\n(LDA). In addition to Gaussian assumption, LDA further assumes that all classes share the same\ncovariance matrix, i.e., \u03a3c = \u03a3. Since the quadratic term is canceled out with this assumption, the\nposterior distribution of generative classifier can be represented as follows:\n\n_P (y = c) P (x|y = c)_ exp \ufffd\u00b5[\u22a4]c **[\u03a3][\u2212][1][x][ \u2212]** [1]2 _[\u00b5]c[\u22a4][\u03a3][\u2212][1][\u00b5][c]_ [+ log][ \u03b2][c]\ufffd\n_P (y = c_ **x) =**\n_|_ \ufffdc[\u2032][ P][ (][y][ =][ c][\u2032][)][ P][ (][x][|][y][ =][ c][\u2032][) =] \ufffdc[\u2032][ exp] \ufffd\u00b5[\u22a4]c[\u2032] **[\u03a3][\u2212][1][x][ \u2212]** [1]2 _[\u00b5]c[\u22a4][\u2032]_ **[\u03a3][\u2212][1][\u00b5][c][\u2032][ + log][ \u03b2][c][\u2032]** [\ufffd] _[.]_\n\n\nOne can note that the above form of posterior distribution is equivalent to the softmax classifier by\nconsidering \u00b5[\u22a4]c **[\u03a3][\u2212][1][ and][ \u2212]** [1]2 _[\u00b5]c[\u22a4][\u03a3][\u2212][1][\u00b5][c]_ [+ log][ \u03b2][c] [as weight and bias of it, respectively. This implies]\n\nthat x might be fitted in Gaussian distribution during training a softmax classifier.\n\n###### B Experimental setup\n\nIn this section, we describe detailed explanation about all the experiments described in Section 3.\n\n**B.1** **Experimental setups in detecting out-of-distribution**\n\n**Detailed model architecture and training. We consider two state-of-the-art neural network archi-**\ntectures: DenseNet [14] and ResNet [12]. For DenseNet, our model follows the same setup as in\nHuang & Liu [14]: 100 layers, growth rate k = 12 and dropout rate 0. Also, we use ResNet with 34\nlayers and dropout rate 0.[2] The softmax classifier is used, and each model is trained by minimizing\nthe cross-entropy loss using SGD with Nesterov momentum. Specifically, we train DenseNet for\n300 epochs with batch size 64 and momentum 0.9. For ResNet, we train it for 200 epochs with\nbatch size 128 and momentum 0.9. The learning rate starts at 0.1 and is dropped by a factor of 10 at\n50% and 75% of the training progress, respectively. The test set errors of DenseNet and ResNet on\nCIFAR-10, CIFAR-100 and SVHN are reported in Table 4.\n\n**Datasets. We train DenseNet and ResNet for classifying CIFAR-10 (or 100) and SVHN datasets:**\nthe former consists of 50,000 training and 10,000 test images with 10 (or 100) image classes, and\nthe latter consists of 73,257 training and 26,032 test images with 10 digits.[3] The corresponding\n\n[2ResNet architecture is available at https://github.com/kuangliu/pytorch-cifar.](https://github.com/kuangliu/pytorch-cifar)\n3We do not use the extra SVHN dataset for training.\n\n\n-----\n\ntest dataset is used as the in-distribution (positive) samples to measure the performance. We use\nrealistic images as the out-of-distribution (negative) samples: the TinyImageNet consists of 10,000\ntest images with 200 image classes from a subset of ImageNet images. The LSUN consists of 10,000\ntest images of 10 different scenes. We downsample each image of TinyImageNet and LSUN to size\n32 32.[4]\n_\u00d7_\n\n**Tested methods. In this paper, we consider the baseline method [13] and ODIN [21] for compari-**\nson. The confidence score in Hendrycks & Gimpel [13] is a maximum value of softmax posterior\ndistribution, i.e., maxy P (y|x). The key idea of ODIN is the temperature scaling which is defined\nas follows:\n\nexp (fy(x)/T )\n_P_ (y = _y_ **x; T** ) = \ufffd\n\ufffd| \ufffd\n\n_y_ [exp (][f][y][(][x][)][/T] [)] _[,]_\n\nwhere T > 0 is the temperature scaling parameter and f = (f1, . . ., fK) is final feature vector of\ndeep neural networks. For each data x, ODIN first calculates the pre-processed image **x by adding**\n\ufffd\nthe small perturbations as follows:\n**x[\u2032]** = x \u2212 _\u03b5odinsign (\u2212\u25bdx log P\u03b8(y = \ufffdy|x; T_ )),\nwhere \u03b5odin is a magnitude of noise and _y is the predicted label._ Next, ODIN feeds the\n\ufffd\npre-processed data into the classifier, computes the maximum value of scaled predictive distribution, i.e., maxy P\u03b8(y|x[\u2032]; T ), and classifies it as positive (i.e., in-distribution) if the confidence score is above some threshold \u03b4. For ODIN, the perturbation noise \u03b5odin is chosen from\n0, 0.0005, 0.001, 0.0014, 0.002, 0.0024, 0.005, 0.01, 0.05, 0.1, 0.2, and the temperature T is cho_{_ _}_\nsen from 1, 10, 100, 1000 .\n_{_ _}_\n\n**Hyper parameters for our method. There are two hyper parameters in our method: the magnitude**\nof noise in (4) and layer indexes for feature ensemble. For all experiments, we extract the confidence\nscores from every end of dense (or residual) block of DenseNet (or ResNet). The size of feature maps\non each convolutional layers is reduced by average pooling for computational efficiency:\n_F \u00d7 H \u00d7_\n1, where is the number of channels and is the spatial dimension. The magnitude\n_W \u2192F \u00d7_ _F_ _H\u00d7W_\nof noise in (4) is chosen from 0, 0.0005, 0.001, 0.0014, 0.002, 0.0024, 0.005, 0.01, 0.05, 0.1, 0.2 .\n_{_ _}_\n\n**Performance metrics. For evaluation, we measure the following metrics to measure the effective-**\nness of the confidence scores in distinguishing in- and out-of-distribution images.\n\n_\u2022 True negative rate (TNR) at 95% true positive rate (TPR). Let TP, TN, FP, and FN de-_\nnote true positive, true negative, false positive and false negative, respectively. We measure\nTNR = TN / (FP+TN), when TPR = TP / (TP+FN) is 95%.\n\n_\u2022 Area under the receiver operating characteristic curve (AUROC). The ROC curve is a_\ngraph plotting TPR against the false positive rate = FP / (FP+TN) by varying a threshold.\n\n_\u2022 Area under the precision-recall curve (AUPR). The PR curve is a graph plotting the_\nprecision = TP / (TP+FP) against recall = TP / (TP+FN) by varying a threshold. AUPR-IN\n(or -OUT) is AUPR where in- (or out-of-) distribution samples are specified as positive.\n\n_\u2022 Detection accuracy. This metric corresponds to the maximum classification probability_\nover all possible thresholds \u03b4:\n1 \u2212 min\u03b4 \ufffdPin (q (x) \u2264 _\u03b4) P (x is from Pin) + Pout (q (x) > \u03b4) P (x is from Pout)_ \ufffd,\n\nwhere q(x) is a confident score. We assume that both positive and negative examples have\nequal probability of appearing in the test set, i.e., P (x is from Pin) = P (x is from Pout).\n\nNote that AUROC, AUPR and detection accuracy are threshold-independent evaluation metrics.\n\n**B.2** **Experimental setups in detecting adversarial samples**\n\n**Adversarial attacks. For the problem of detecting adversarial samples, we consider the following**\nattack methods: fast gradient sign method (FGSM) [10], basic iterative method (BIM) [16], DeepFool [26] and Carlini-Wagner (CW) [3]. The FGSM directly perturbs normal input in the direction\nof the loss gradient. Formally, non-targeted adversarial examples are constructed as\n**xadv = x + \u03b5F GSM** sign (\u25bdx\u2113(y[\u2217], P (y|x))),\n\n[4LSUN and TinyImageNet datasets are available at https://github.com/ShiyuLiang/odin-pytorch.](https://github.com/ShiyuLiang/odin-pytorch)\n\n\n-----\n\nCIFAR-10 CIFAR-100 SVHN\n\n_L\u221e_ Acc. _L\u221e_ Acc. _L\u221e_ Acc.\n\nClean 0 95.19% 0 77.63% 0 96.38%\nFGSM 0.21 20.04% 0.21 4.86% 0.21 56.27%\n\nDenseNet BIM 0.22 0.00% 0.22 0.02% 0.22 0.67%\n\nDeepFool 0.30 0.23% 0.25 0.23% 0.57 0.50%\nCW 0.05 0.10% 0.03 0.16% 0.12 0.54%\n\nClean 0 93.67% 0 78.34% 0 96.68%\nFGSM 0.25 23.98% 0.25 11.67% 0.25 49.33%\n\nResNet BIM 0.26 0.02% 0.26 0.21% 0.26 2.37%\n\nDeepFool 0.36 0.33% 0.27 0.37% 0.62 13.20%\nCW 0.08 0.00% 0.08 0.01% 0.15 0.04%\n\nTable 4: The L\u221e mean perturbation and classification accuracy on clean and adversarial samples.\n\nwhere \u03b5F GSM is a magnitude of noise, y[\u2217] is the ground truth label and \u2113 is a loss function to measure\nthe distance between the prediction and the ground truth. The BIM is an iterative version of FGSM,\nwhich applies FGSM multiple times with a smaller step size. Formally, non-targeted adversarial\nexamples are constructed as\n\n**x[0]adv** [=][ x][,][ x]adv[n][+1] [=][ Clip]x[\u03b5][BIM] _{x[n]adv_ [+][ \u03b1][BIM] [sign] \ufffd\u25bdx[n]adv _[\u2113][(][y][\u2217][, P]_ [(][y][|][x]adv[n] [))]\ufffd},\n\nwhere Clip[\u03b5]x[BIM] means we clip the resulting image to be within the \u03b5BIM -ball of x. DeepFool works\nby finding the closest adversarial examples with geometric formulas. CW is an optimization-based\nmethod which arguably the most effective method. Formally, non-targeted adversarial examples are\nconstructed as\n\narg min\n**xadv** _[\u03bbd][(][x][,][ x][adv][)][ \u2212]_ _[\u2113][(][y][\u2217][, P]_ [(][y][|][x][adv][))][,]\n\nwhere \u03bb is penalty parameter and d( _,_ ) is a metric to quantify the distance between an original\n\n_\u00b7_ _\u00b7_\nimage and its adversarial counterpart. However, compared to FGSM and BIM, this method is much\nslower in practice. For all experiments, L2 distance is used as a constraint. We used the library from\nFaceBook [11] for generating adversarial samples.[5] Table 4 tatistics of adversarial attacks including\nthe L\u221e mean perturbation and classification accuracy on adversarial attacks.\n\n**Tested methods. Ma et al. [22] proposed to characterize adversarial subspaces by using local in-**\ntrinsic dimensionality (LID). Given a test sample x, LID is defined as follows:\n\n|Col1|CIFAR-10 L Acc. \u221e|CIFAR-100 L Acc. \u221e|SVHN L Acc. \u221e|\n|---|---|---|---|\n\n|Clean FGSM DenseNet BIM DeepFool CW|0 95.19% 0.21 20.04% 0.22 0.00% 0.30 0.23% 0.05 0.10%|0 77.63% 0.21 4.86% 0.22 0.02% 0.25 0.23% 0.03 0.16%|0 96.38% 0.21 56.27% 0.22 0.67% 0.57 0.50% 0.12 0.54%|\n|---|---|---|---|\n\n|Clean FGSM ResNet BIM DeepFool CW|0 93.67% 0.25 23.98% 0.26 0.02% 0.36 0.33% 0.08 0.00%|0 78.34% 0.25 11.67% 0.26 0.21% 0.27 0.37% 0.08 0.01%|0 96.68% 0.25 49.33% 0.26 2.37% 0.62 13.20% 0.15 0.04%|\n|---|---|---|---|\n\n\n\ufffd\n\nlog _[r][i][(][x][)]_\n\n_rk(x)_\n\n_i_\n\n\n\ufffd\n\n\n_LID\ufffd_ = \u2212\n\n\n\ufffd\n1\n_k_\n\n\n_,_\n\n\nwhere ri(x) denotes the distance between x and its i-th nearest neighbor within a sample of points\ndrawn from in-distribution, and rk(x) denotes the maximum distance among k nearest neighbors.\nWe commonly extract the LID scores from every end of dense (or residual) block of DenseNet (or\nResNet) similar to ours. Given test sample x and the set Xc of training samples with label c, the\nGaussian kernel density with bandwidth \u03c3 is defined as follows:\n\n\n1\n_KD(x) =_\n\n_|Xc|_\n\n\n\ufffd\n\n_k\u03c3(xi, x),_\n**xi\u2208Xc**\n\n\nwhere k\u03c3(x, y) \u221d exp(\u2212||x \u2212 _y||[2]/\u03c3[2]). For LID and KD, we used the library from Ma et al. [22]._\n\n**Hyper-parameters and training. Following the similar strategies in [7, 22], we randomly choose**\n10% of original test samples for training the logistic regression detectors and the remaining test\nsamples are used for evaluation. The training sets consists of three types of examples: adversarial,\nnormal and noisy. Here, noisy examples are generated by adding random noise to normal examples.\nUsing nested cross validation within the training set, all hyper-parameters including the bandwidth\n\n[5The code is available at https://github.com/facebookresearch/adversarial_image_defenses.](https://github.com/facebookresearch/adversarial_image_defenses)\n\n\n-----\n\n|Col1|LID|Mahalanobis (our)|\n|---|---|---|\n\n\n100\n\n90\n\n80\n\n70\n\n60\n\n\n100\n\n90\n\n80\n\n70\n\n60\n\n\n100\n\n90\n\n80\n\n70\n\n60\n\n\nAdversarial attack: FGSM\n\n\nAdversarial attack: BIM\n\n\n5K 10K 20K 30K 40K 50K\n\n\nAdversarial attack: DeepFool\n\n\nAdversarial attack: CW\n\n\n100\n\n90\n\n80\n\n70\n\n60\n\n\n(a) Small training data: the x-axis represents the number of training data\n\n\n100\n\n90\n\n80\n\n70\n\n60\n\n\n100\n\n90\n\n80\n\n70\n\n60\n\n\n100\n\n90\n\n80\n\n70\n\n60\n\n\n100\n\n90\n\n80\n\n70\n\n60\n\n\n(b) Noisy training data: the x-axis represents the percentage of training data with random label\nFigure 5: Comparison of AUROC (%) under different training data. To evaluate the robustness of\nproposed method, we train ResNet (a) by varying the number of training data and (b) assigning\nrandom label to training data on CIFAR-10 dataset.\n\n|Col1|Col2|Col3|Col4|Col5|Col6|Col7|Col8|Col9|Col10|\n|---|---|---|---|---|---|---|---|---|---|\n|||||||||||\n|||||||||||\n|5|K|10 Ad|K vers|20K arial at|30K tack: FG|4 ( SM|0K a)|50 S|K m|\n|||||||||||\n|||||||||||\n|||||||||||\n|||||||||||\n|0% gu op nd|re o o|10 (b 5 se m|% ) : d la|20% No Co me bel|30 isy mp tho to|% tr ar d, tr|40 ain is ai|% in o we ni|g n n|\n\n|Col1|Col2|Col3|Col4|Col5|Col6|Col7|Col8|Col9|Col10|\n|---|---|---|---|---|---|---|---|---|---|\n|||||||||||\n|||||||||||\n|5K g d|10 at A|K a dve|20 rsari|K al att|30K ack: C|4 W|0K|50|K|\n|||||||||||\n|||||||||||\n|||||||||||\n|||||||||||\n|0% ith lua dat|10 r te a|% an t a|2 do he nd|0% m r (|30 la ob b)|% be us a|40 l tn ssi|% e g|ss n|\n\n\n40\n\n|Col1|Col2|Col3|Col4|Col5|Col6|Col7|Col8|Col9|Col10|Col11|\n|---|---|---|---|---|---|---|---|---|---|---|\n||||||||||||\n||||||||||||\n|5 rai|K ni|10 n A|K g d dve|20 a rsari|K ta: al att|30K th ack: B|4 e IM|0K x-|50 ax|K is s di ry ta|\n||||||||||||\n||||||||||||\n||||||||||||\n||||||||||||\n||||||||||||\n|0% : U ta 80 70 60 50|th R Re o|10 e O s n|% x- C N C|2 ax ( et IF|0% is % (a A|30 rep ) u ) R-|% re n by 1|40 se de 0|% nt r va da||\n|||||||S E|oftmax uclidean Mahalanob||is (ours)||\n||||||||||||\n||||||||||||\n||||||||||||\n\n|Col1|Col2|Col3|Col4|Col5|Col6|Col7|\n|---|---|---|---|---|---|---|\n||||||||\n||||||||\n|5K ese|10 nts Adv|K t ersa|20 he rial a|K 30 nu ttack: D|K 4 mbe eepFo|0K 50 r of ol|\n||||||||\n||||||||\n||||||||\n||||||||\n|0% per en th 60 40 20|10 cen t tr e n|% ta ai u|2 ge ni m|0% of ng ber|30% trai dat of|40% ning a. tra|\n||||||||\n||||||||\n||||||||\n||Softma Euclide Mahala||x an nobis (ours)||||\n\n\n102 104 106 108 110\n\nThe number of classes\n\n\n0 20 40 60 80\n\nBase class accuracy (%)\n\n\n0\n\n\n(a) Base: CIFAR-100 / New: CIFAR-10\n\nFigure 6: Experimental results of class-incremental learning on CIFAR-100 and CIFAR-10 datasets.\nWe report (left) AUC with respect to the number of learned classes and, (right) the base-new class\naccuracy curve after the last new classes is added.\n\n\nparameter for KD, the number of nearest neighbors for LID, and input noise for our method are\ntuned. Specifically, the value of k is chosen from 10, 20, 30, 40, 50, 60, 70, 80, 90 with respect to\n_{_ _}_\na minibatch of size 100, and the bandwidth was chosen from 0.1, 0.25, 0.5, 0.75, 1 . The magnitude\n_{_ _}_\nof noise in (4) is chosen from 0, 0.0005, 0.001, 0.0014, 0.002, 0.0024, 0.005, 0.01, 0.05, 0.1, 0.2 .\n_{_ _}_\n\n###### C More experimental results\n\n\nIn this section, we provide more experimental results.\n\n**C.1** **Robustness of our method in detecting adversarial samples**\n\n\nIn order to verify the robustness, we measure the detection performance when we train ResNet\nby varying the number of training data and assigning random label to training data on CIFAR-10\ndataset. As shown in Figure 5, our method (blue bar) outperforms LID (green bar) for all experiments.\n\n**C.2** **Class-incremental learning**\n\n\nFigure 6 compares the AUCs of tested methods when CIFAR-100 is pre-trained and CIFAR-10 is\nused as new classes. Our proposed Mahalanobis distance-based classifier outperforms the other\nmethods by a significant margin, as the number of new classes increases. The AUC of our proposed\nmethod is 47.7%, which is better than 41.0% of the softmax classifier and 43.0% of the Euclidean\ndistance classifier after all new classes are added.\n\n\n-----\n\n**C.3** **Experimental results on joint confidence loss**\n\nIn addition, we remark that the proposed detector using softmax neural classifier trained by standard\ncross entropy loss typically outperforms the ODIN detector using softmax neural classifier trained\nby confidence loss [19] which involves jointly training a generator and a classifier to calibrate the\nposterior distribution. Also, our detector provides further improvement if one use it with model\ntrained by confidence loss. In other words, our proposed method can improve any pre-trained softmax neural classifier.\n\n\n(a) In-distribution: CIFAR-10\n\nOut-of-distribution: TinyImageNet\n\n\n100\n\n90\n80\n70\n60\n50\n40\n30\n20\n10\n\n0\n\n100\n\n90\n80\n70\n60\n50\n40\n30\n20\n10\n\n0\n\n\nTNR\n\nat TPR 95%\n\n\nOut-of-distribution: SVHN\n\nTNR AUROC Detection\n\nTPR 95% accuracy\n\nOut-of-distribution: CIFAR-10\n\n\nTNR\n\nat TPR 95%\n\n\nOut-of-distribution: TinyImageNet\n\n\nOut-of-distribution: LSUN\n\nTNR AUROC Detection\n\nat TPR 95% accuracy\n\nOut-of-distribution: LSUN\n\nTNR AUROC Detection\n\nat TPR 95% accuracy\n\n\nTNR\n\nat TPR 95%\n\n\nAUROC Detection\n\naccuracy\n\n\n100\n\n90\n80\n70\n60\n50\n40\n30\n20\n10\n\n0\n\n100\n\n90\n80\n70\n60\n50\n40\n30\n20\n10\n\n0\n\n\nAUROC Detection\n\naccuracy\n\n\n100\n\n90\n80\n70\n60\n50\n40\n30\n20\n10\n\n0\n\n100\n\n90\n80\n70\n60\n50\n40\n30\n20\n10\n\n0\n\n\nAUROC Detection\n\naccuracy\n\n\n(b) In-distribution: SVHN\nFigure 7: Performances of the baseline detector [13], ODIN detector [21] and Mahalanobis detector\nunder various training losses.\n\n**C.4** **Comparison with ODIN**\n\nIn-dist TNR at TPR 95% AUROC Detection accuracy AUPR in AUPR out\nOut-of-dist\n(model) Baseline [13] / ODIN [21] / Mahalanobis (ours)\n\n\nCIFAR-10\n(DenseNet)\n\nCIFAR-100\n(DenseNet)\n\nSVHN\n(DenseNet)\n\nCIFAR-10\n(ResNet)\n\nCIFAR-100\n(ResNet)\n\nSVHN\n(ResNet)\n\n\nSVHN 40.2 / 86.2 / 90.8 89.9 / 95.5 / 98.1 83.2 / 91.4 / 93.9 83.1 / 78.8 / 96.6 94.7 / 98.3 / 99.2\nTinyImageNet 58.9 / 92.4 / 95.0 94.1 / 98.5 / 98.8 88.5 / 93.9 / 95.0 95.3 / 98.5 / 98.8 92.3 / 98.5 / 98.8\nLSUN 66.6 / 96.2 / 97.2 95.4 / 99.2 / 99.3 90.3 / 95.7 / 96.3 96.5 / 99.3 / 99.3 94.1 / 99.2 / 99.1\n\nSVHN 26.7 / 70.6 / 82.5 82.7 / 93.8 / 97.2 75.6 / 86.6 / 91.5 74.3 / 87.1 / 94.8 91.0 / 97.3 / 98.8\nTinyImageNet 17.6 / 42.6 / 86.6 71.7 / 85.2 / 97.4 65.7 / 77.0 / 92.2 74.2 / 85.6 / 97.6 69.0 / 84.5 / 97.2\nLSUN 16.7 / 41.2 / 91.4 70.8 / 85.5 / 98.0 64.9 / 77.1 / 93.9 74.1 / 86.4 / 98.2 67.9 / 84.2 / 97.5\n\nCIFAR-10 69.3 / 71.7 / 96.8 91.9 / 91.4 / 98.9 86.6 / 85.8 / 95.9 95.7 / 95.2 / 99.6 82.8 / 84.5 / 95.8\nTinyImageNet 79.8 / 84.1 / 99.9 94.8 / 95.1 / 99.9 90.2 / 90.4 / 98.9 97.2 / 97.1 / 99.9 88.4 / 91.4 / 99.6\nLSUN 77.1 / 81.1 / 100.0 94.1 / 94.5 / 99.9 89.1 / 89.2 / 99.3 97.0 / 97.0 / 99.9 87.4 / 90.5 / 99.7\n\nSVHN 32.5 / 86.6 / 96.4 89.9 / 96.7 / 99.1 85.1 / 91.1 / 95.8 85.4 / 92.5 / 98.3 94.0 / 98.5 / 99.6\nTinyImageNet 44.7 / 72.5 / 97.1 91.0 / 94.0 / 99.5 85.1 / 86.5 / 96.3 92.5 / 94.2 / 99.5 88.4 / 94.1 / 99.5\nLSUN 45.4 / 73.8 / 98.9 91.0 / 94.1 / 99.7 85.3 / 86.7 / 97.7 92.5 / 94.2 / 99.7 88.6 / 94.3 / 99.7\n\nSVHN 20.3 / 62.7 / 91.9 79.5 / 93.9 / 98.4 73.2 / 88.0 / 93.7 64.8 / 89.0 / 96.4 89.0 / 96.9 / 99.3\nTinyImageNet 20.4 / 49.2 / 90.9 77.2 / 87.6 / 98.2 70.8 / 80.1 / 93.3 79.7 / 87.1 / 98.2 73.3 / 87.4 / 98.2\nLSUN 18.8 / 45.6 / 90.9 75.8 / 85.6 / 98.2 69.9 / 78.3 / 93.5 77.6 / 84.5 / 98.4 72.0 / 85.7 / 97.8\n\nCIFAR-10 78.3 / 79.8 / 98.4 92.9 / 92.1 / 99.3 90.0 / 89.4 / 96.9 95.1 / 94.0 / 99.7 85.7 / 86.8 / 97.0\nTinyImageNet 79.0 / 82.1 / 99.9 93.5 / 92.0 / 99.9 90.4 / 89.4 / 99.1 95.7 / 93.9 / 99.9 86.2 / 88.1 / 99.1\nLSUN 74.3 / 77.3 / 99.9 91.6 / 89.4 / 99.9 89.0 / 87.2 / 99.5 94.2 / 92.1 / 99.9 84.0 / 85.5 / 99.1\n\n\nTable 5: Distinguishing in- and out-of-distribution test set data for image classification. We tune the\nhyper-parameters using validation set of in- and out-of-distributions. All values are percentages and\nthe best results are indicated in bold.\n\n\n-----\n\nIn-dist TNR at TPR 95% AUROC Detection accuracy AUPR in AUPR out\nOut-of-dist\n(model) Baseline [13] / ODIN [21] / Mahalanobis (ours)\n\n\nCIFAR-10\n(DenseNet)\n\nCIFAR-100\n(DenseNet)\n\nSVHN\n(DenseNet)\n\nCIFAR-10\n(ResNet)\n\nCIFAR-100\n(ResNet)\n\nSVHN\n(ResNet)\n\n\nSVHN 40.2 / 70.5 / 89.6 89.9 / 92.8 / 97.6 83.2 / 86.5 / 92.6 83.1 / 72.1 / 94.5 94.7 / 97.4 / 99.0\nTinyImageNet 58.9 / 87.1 / 94.9 94.1 / 97.2 / 98.8 88.5 / 92.1 / 95.0 95.3 / 94.7 / 98.7 92.3 / 97.0 / 98.8\nLSUN 66.6 / 92.9 / 97.2 95.4 / 98.5 / 99.2 90.3 / 94.3 / 96.2 96.5 / 97.7 / 99.3 94.1 / 98.2 / 99.2\n\nSVHN 26.7 / 39.8 / 62.2 82.7 / 88.2 / 91.8 75.6 / 80.7 / 84.6 74.3 / 80.8 / 82.6 91.0 / 94.0 / 95.8\nTinyImageNet 17.6 / 43.2 / 87.2 71.7 / 85.3 / 97.0 65.7 / 77.2 / 91.8 74.2 / 85.8 / 96.2 69.0 / 84.7 / 97.1\nLSUN 16.7 / 42.1 / 91.4 70.8 / 85.7 / 97.9 64.9 / 77.3 / 93.8 74.1 / 86.7 / 98.1 67.9 / 84.6 / 97.6\n\nCIFAR-10 69.3 / 69.3 / 97.5 91.9 / 91.9 / 98.8 86.6 / 86.6 / 96.3 95.7 / 95.7 / 99.6 82.8 / 82.8 / 95.1\nTinyImageNet 79.8 / 79.8 / 99.9 94.8 / 94.8 / 99.8 90.2 / 90.2 / 98.9 97.2 / 97.2 / 99.9 88.4 / 88.4 / 99.5\nLSUN 77.1 / 77.1 / 100 94.1 / 94.1 / 99.9 89.1 / 89.1 / 99.2 97.0 / 97.0 / 99.9 87.4 / 87.4 / 99.6\n\nSVHN 32.5 / 40.3 / 75.8 89.9 / 86.5 / 95.5 85.1 / 77.8 / 89.1 85.4 / 77.8 / 91.0 94.0 / 93.7 / 98.0\nTinyImageNet 44.7 / 69.6 / 95.5 91.0 / 93.9 / 99.0 85.1 / 86.0 / 95.4 92.5 / 94.3 / 98.6 88.4 / 93.7 / 99.1\nLSUN 45.4 / 70.0 / 98.1 91.0 / 93.7 / 99.5 85.3 / 85.8 / 97.2 92.5 / 94.1 / 99.5 88.6 / 93.6 / 99.5\n\nSVHN 20.3 / 12.2 / 41.9 79.5 / 72.0 / 84.4 73.2 / 67.7 / 76.5 64.8 / 48.6 / 69.1 89.0 / 84.9 / 92.7\nTinyImageNet 20.4 / 33.5 / 70.3 77.2 / 83.6 / 87.9 70.8 / 75.9 / 84.6 79.7 / 84.5 / 76.8 73.3 / 81.7 / 90.7\nLSUN 18.8 / 31.6 / 56.6 75.8 / 81.9 / 82.3 69.9 / 74.6 / 79.7 77.6 / 82.1 / 70.3 72.0 / 80.3 / 85.3\n\nCIFAR-10 78.3 / 79.8 / 94.1 92.9 / 92.1 / 97.6 90.0 / 89.4 / 94.6 95.1 / 94.0 / 98.1 85.7 / 86.8 / 94.7\nTinyImageNet 79.0 / 80.5 / 99.2 93.5 / 92.9 / 99.3 90.4 / 90.1 / 98.8 95.7 / 94.8 / 98.8 86.2 / 87.5 / 98.3\nLSUN 74.3 / 76.3 / 99.9 91.6 / 90.7 / 99.9 89.0 / 88.2 / 99.5 94.2 / 93.0 / 99.9 84.0 / 85.0 / 98.8\n\n\nTable 6: Distinguishing in- and out-of-distribution test set data for image classification when we tune\nthe hyper-parameters of ODIN and our method only using in-distribution and adversarial (FGSM)\nsamples. All values are percentages and boldface values indicate relative the better results.\n\n**C.5** **LID for detecting out-of-distribution samples**\n\nFigure 8 and 9 shows the performance of the ODIN [21], LID [22] and Mahalanobis detector for\neach in- and out-of-distribution pair. We remark that the proposed method outperforms all tested\nmethods.\n\n|Col1|Col2|ODIN|Col4|LID|Col6|Mahalanobis (our)|\n|---|---|---|---|---|---|---|\n\n\n100\n\n90\n\n80\n\n70\n\n\n100\n\n90\n\n80\n\n70\n\n100\n\n90\n\n80\n\n70\n\n60\n\n50\n\n40\n\n\n100\n\n90\n\n80\n\n70\n\n100\n\n90\n\n80\n\n70\n\n60\n\n50\n\n40\n\n100\n\n90\n\n80\n\n70\n\n|Col1|Col2|Col3|Col4|Col5|Col6|Col7|Col8|Col9|\n|---|---|---|---|---|---|---|---|---|\n||||||||||\n||||||||||\n||||||||||\n||||||||||\n|at T|TNR PR|95% Out-|A of-dist|URO ributi|C on: S|D a VHN|etecti ccura|on cy|\n||||||||||\n||||||||||\n||||||||||\n||||||||||\n||||||||||\n|at T|TNR PR 9 O|5% ut-of-|A distri|URO butio|C n: CIF|De ac AR-10|tectio cura|n cy|\n||||||||||\n||||||||||\n||||||||||\n||||||||||\n\n|Col1|Col2|Col3|Col4|Col5|Col6|Col7|Col8|Col9|\n|---|---|---|---|---|---|---|---|---|\n||||||||||\n||||||||||\n||||||||||\n||||||||||\n|at T ) I|TNR PR n-d|95% ist Out-|A ribu of-dist|URO tio ributi|C n: on: L|D a CI SUN|etecti ccura FA|on cy R-|\n||||||||||\n||||||||||\n||||||||||\n||||||||||\n||||||||||\n|at T In|TNR PR 9 -d|5% istr Out-|A ibu of-dist|URO tio ributi|C n: on: L|De ac CIF SUN|tectio cura A|n cy R-1|\n||||||||||\n||||||||||\n||||||||||\n||||||||||\n||||||||||\n\n|Col1|Col2|Col3|Col4|Col5|Col6|Col7|Col8|Col9|\n|---|---|---|---|---|---|---|---|---|\n||||||||||\n||||||||||\n||||||||||\n||||||||||\n|at|TNR TPR Ou|95% t-of-di|A stribu|URO tion:|C TinyI|D a mageN|etecti ccura et|on cy|\n||||||||||\n||||||||||\n||||||||||\n||||||||||\n|at T|TNR PR 9 Ou|5% t-of-di|A stribu|URO tion:|C TinyI|De ac mageN|tectio cura et|n cy|\n||||||||||\n||||||||||\n||||||||||\n||||||||||\n||||||||||\n\n\nTNR\n\nat TPR 95%\n\n\nOut-of-distribution: SVHN\n\n\nOut-of-distribution: LSUN\n\n\nOut-of-distribution: TinyImageNet\n\n\n(a) In-distribution: CIFAR-10\n\nOut-of-distribution: LSUN\n\n100\n\n90\n\n80\n\n70\n\n60\n\n50\n\n40\n\n\n(b) In-distribution: CIFAR-100\n\n\nTNR\n\nat TPR 95%\n\n\nTNR\n\nat TPR 95%\n\n\nAUROC Detection\n\naccuracy\n\n\n100\n\n90\n\n80\n\n70\n\n\nAUROC Detection\n\naccuracy\n\n\n100\n\n90\n\n80\n\n70\n\n\nAUROC Detection\n\naccuracy\n\n\n(c) In-distribution: SVHN\nFigure 8: Distinguishing in- and out-of-distribution test set data for image classification using\nResNet.\n\n\n-----\n\n|Col1|Col2|ODIN|Col4|LID|Col6|Mahalanobis (our)|\n|---|---|---|---|---|---|---|\n\n\n100\n\n90\n\n80\n\n\n100\n\n90\n\n80\n\n100\n\n90\n\n80\n\n70\n\n60\n\n50\n\n40\n\n\n100\n\n90\n\n80\n\n100\n\n90\n\n80\n\n70\n\n60\n\n50\n\n40\n\n100\n\n90\n\n80\n\n70\n\n\nOut-of-distribution: SVHN\n\n\n100\n\n90\n\n80\n\n70\n\n\nOut-of-distribution: LSUN\n\n\nOut-of-distribution: TinyImageNet\n\n\n(a) In-distribution: CIFAR-10\n\nOut-of-distribution: LSUN\n\n100\n\n90\n\n80\n\n70\n\n60\n\n50\n\n40\n\n\n(b) In-distribution: CIFAR-100\n\n\n100\n\n90\n\n80\n\n70\n\n\n(c) In-distribution: SVHN\nFigure 9: Distinguishing in- and out-of-distribution test set data for image classification using\nDenseNet.\n\n###### D Evaluation on ImageNet dataset\n\nIn this section, we verify the performance of the proposed method using the ImageNet 2012 classification dataset [5] that consists of 1000 classes. The models are trained on the 1.28 million\ntraining images, and evaluated on the 50k validation images. For all experiments, we use the\n[pre-trained ResNet [12] which is available at https://github.com/pytorch/vision/blob/](https://github.com/pytorch/vision/blob/master/torchvision/models/resnet.py)\n```\nmaster/torchvision/models/resnet.py. First, we measure the classification accuracy of gen\n```\nerative classifier from the pre-trained model as follows:\n\n_y\ufffd(x) = arg minc_ (f (x) \u2212 _\u00b5\ufffdc)[\u22a4]_ **\u03a3[\ufffd]** _[\u2212][1]_ (f (x) \u2212 _\u00b5\ufffdc) + log_ _\u03b2[\ufffd]c,_\n\nwhere _\u03b2[\ufffd]c =_ _[N]N[c]_ [is an empirical class prior. We remark that this corresponds to predicting a class]\n\nlabel using the posterior distribution from generative with LDA assumption. Table 7 shows the\ntop-1 classification accuracy on ImageNet 2012 dataset. One can note that the proposed generative\nclassifier can perform reasonably well even though the softmax classifier outperforms it in all cases.\nHowever, we remark that the gap between them is decreasing as the training accuracy increases, i.e.,\nthe pre-trained model learned more strong representations.\n\nModel Softmax (training) Softmax (validation) Generative (validation)\n\nResNet (101 layers) 86.55 75.66 73.49\nResNet (18 layers) 69.06 68.69 63.32\n\nTable 7: Top-1 accuracy (%) of ResNets on ImageNet 2012 dataset.\n\nNext, we also evaluate the detection performance of the Mahalanobis distance-based detector on\nImageNet 2012 dataset using ResNets with 18 layers. For evaluation, we consider the problem of\n\n|Col1|Col2|Col3|Col4|Col5|Col6|Col7|Col8|Col9|\n|---|---|---|---|---|---|---|---|---|\n||||||||||\n|at T|TNR PR|95% Out-|A of-dist|URO ributi|C on: S|D a VHN|etecti ccura|on cy|\n||||||||||\n||||||||||\n||||||||||\n||||||||||\n||||||||||\n|at T|TNR PR 9 O|5% ut-of-|A distri|URO butio|C n: CIF|De ac AR-10|tectio cura|n cy|\n||||||||||\n||||||||||\n||||||||||\n||||||||||\n||||||||||\n|at T : t. al cti d im ed|TNR PR 9 Di ua on ata ag R|5% stin tio , w set es, esN|A gu n e [5 an et|URO is o ve ] d [1|C hin n I rify tha ev 2]|De ac g i m th t c alu w|tectio cura n- ag e on ate hic|n cy an e pe sis d h|\n\n|Col1|Col2|Col3|Col4|Col5|Col6|Col7|Col8|Col9|\n|---|---|---|---|---|---|---|---|---|\n|at T ) I|TNR PR n-d|95% ist Out-|A ribu of-dist|URO tio ributi|C n: on: L|D a CI SUN|etecti ccura FA|on cy R-|\n||||||||||\n||||||||||\n||||||||||\n||||||||||\n|at T In|TNR PR 9 -d|5% istr Out-|A ibu of-dist|URO tio ributi|C n: on: L|De ac CIF SUN|tectio cura A|n cy R-1|\n||||||||||\n||||||||||\n||||||||||\n|at T (c) t-o da an 1 he ail|TNR PR 9 In f- ta ce 00 50 ab|5% -di dis se of 0 c k le|A stri tri t th las val at|URO bu but e se id ht|C tion io pro s. ati tp|De ac : S n t po T on s:|tectio cura V est se he im //|n cy HN se d m m ag gi|\n\n|Col1|Col2|Col3|Col4|Col5|Col6|Col7|Col8|Col9|\n|---|---|---|---|---|---|---|---|---|\n||||||||||\n|at|TNR TPR Ou|95% t-of-di|A stribu|URO tion:|C TinyI|D a mageN|etecti ccura et|on cy|\n||||||||||\n||||||||||\n||||||||||\n||||||||||\n|at T|TNR PR 9 Ou|5% t-of-di|A stribu|URO tion:|C TinyI|De ac mageN|tectio cura et|n cy|\n||||||||||\n||||||||||\n||||||||||\n||||||||||\n|at T ta d a Fo .c|TNR PR 9 fo usi re r a o|5% r i ng tra ll m/p|A ma th ine ex yt|URO ge e I d pe o|C cl ma on rim rch|De ac ass ge th en /v|tectio cura ifi Ne e ts, i|n cy cat t 2 1.2 w sio|\n\n\n-----\n\n# Review comment90 100 100 100\n\n8070 KD + PULIDOurs 9080 9080 9080\n\n60 70 70 70\n\n##### \u2022 Generating the garbage images matching mean & variance5040 605040 605040 605040\n\n3020100        - Initialize random vector X3020100 KD + PULIDOurs 3020100 BaselineODINLIDOurs 3020100 BaselineODINLIDOurs\n\nat TPR 95%\u2022TNR Find X which optimize the following objective (final layer attack):AUROC Detection accuracy at TPR 95%TNR AUROC Detection accuracy at TPR 95%TNR AUROC Detection accuracy at TPR 95%TNR AUROC Detection accuracy\n\n\n#### 2\n\n|70 \u2022 60 50 40 30|LID GeOurns e \u2022 In|rat itia|i liz|ng t e r|h an|80 e ga70 60 50 dom34 00|rb v|a ec|g to|e r|i X|m|a|ge KD|s + PU|80 ma70t 60 50 40 30|c|h|i|n|g|Col23|m|e|a B|n asel|ine|80 & va70r 60 50 40 30|ia|n|c|e|Col34|Col35|B|asel|ine|Col39|\n|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n\n\n(a) FGSM (b) BIM (c) Scenario 1 (d) Scenario 2\n\nFigure 10: (a)/(b) Distinguishing clean and adversarial samples using ResNet with 18 layers on\n\n##### \u2022ImageNet 2012 validation set. (c)/(d) Distinguishing clean and garbage samples using ResNet 18 Experimental results\n\nlayers trained on CIFAR-10 dataset.\u2022 Model: ResNet-34 trained on CIFAR-10 (Success rate: 89.00 %)\n\nClass 0  class 1.  class 2.  class 3.  class 4.  class 5.  class 6.  class 7.  class 8.  class 9.\n\nFigure 11: The generated garbage sample and its target class.\n\ndetecting adversarial samples generated by FGSM [10] and BIM [16]. Similar to Section 3.2, we\nextract the confidence scores from every end of residual block of ResNet. Figure 10(a) and 10(b)\nshow the performance of various detectors. One can note that the proposed Mahalanobis distancebased detector outperforms all tested methods including LID. These results imply that our method\ncan be working well for the large-scale datasets.\n\n\n###### E Adaptive attacks against Mahalanobis distance-based detector\n\nIn this section, we evaluate the robustness of our method by generating the garbage images which\nmay fool the Mahalanobis distance-based detector in a white-box setting, i.e., one can access to the\nparameters of the classifier and that of the Mahalanobis distance-based detector. Here, we remark\nthat accessing the parameters of the Mahalanobis distance-based detector, i.e., sample means and\ncovariance, is not mild assumption since the information about training data is required to compute\nthem. To attack our method, we generate a garbage images xg by minimizing the Mahalanobis\ndistance as follows:\n\narg min\n**xg** [(][f] [(][x][g][)][ \u2212] _[\u00b5][\ufffd][c][)][\u22a4]_ **[\u03a3][\ufffd]** _[\u2212][1][ (][f]_ [(][x][g][)][ \u2212] _[\u00b5][\ufffd][c][)][,]_\n\nwhere c is a target class. We test two different scenarios using ResNet with 34 layers trained on\nCIFAR-10 dataset. In the first scenario, we generate the garbage images only using a penultimate\nlayer of DNNs. In the second scenario, we attack every end of residual block of ResNet. Figure 11\nshows the generated samples by minimizing the Mahalanobis distance. Even though the generated\nsample looks like the random noise, it successfully fools the pre-trained classifier, i.e., it is classified\nas the target class. We measure the detection performance of the baseline [13], ODIN [21], LID\n\n[22] and the proposed Mahalanobis distance-based detector. As shown in Figure 10(c) and 10(d),\nour method can distinguish CIFAR-10 test and garbage images for both scenarios better than the\ntested methods. In particular, we remark that the input pre-processing is very useful in detecting\nsuch garbage samples. These results imply that our proposed method is robust to the attacks.\n\n###### F Hybrid inference of generative and discriminative classifiers\n\nIn this paper, we show that the generative classifier can be very useful in characterizing the abnormal\nsamples such as OOD and adversarial samples. Here, a caveat is that the generative classifier might\ndegrade the classification performance. In order to handle this issue, we introduce a hybrid inference\nof generative and discriminative classifiers. Given a generative classifier with GDA assumptions, the\nposterior distribution of generative classifier via Bayes rule is given as:\n\n_P (y = c) P (x|y = c)_ exp \ufffd\u00b5[\u22a4]c **[\u03a3][\u2212][1][x][ \u2212]** [1]2 _[\u00b5]c[\u22a4][\u03a3][\u2212][1][\u00b5][c]_ [+ log][ \u03b2][c]\ufffd\n_P (y = c_ **x) =**\n_|_ \ufffdc[\u2032][ P][ (][y][ =][ c][\u2032][)][ P][ (][x][|][y][ =][ c][\u2032][) =] \ufffdc[\u2032][ exp] \ufffd\u00b5[\u22a4]c[\u2032] **[\u03a3][\u2212][1][x][ \u2212]** [1]2 _[\u00b5]c[\u22a4][\u2032]_ **[\u03a3][\u2212][1][\u00b5][c][\u2032][ + log][ \u03b2][c][\u2032]** [\ufffd] _[.]_\n\n\n(b) BIM (c) Scenario 1\n\nFigure 10: (a)/(b) Distinguishing clean and adversarial samples using ResNet with 18 layers on\n\n\n-----\n\nTo match this with a standard softmax classifier\u2019s weights, the parameters of the generative classifier\nhave to satisfy the following conditions:\n\n_\u00b5c = \u03a3wc, log \u03b2c \u2212_ 0.5\u00b5[\u22a4]c [\u03a3][\u2212][1][\u00b5][c] [=][ b][c][,]\n\nwhere wc and bc are weights and bias for a class c, respectively. Using the empirical covariance\n\u03a3\ufffd as shown in (1), one can induce the parameters of another generative classifier which has same\ndecision boundary with the softmax classifier as follows:\n\n_\u00b5\u02dcc =_ \u03a3[\ufffd]wc, _\u03b2[\u02dc]c =_ \ufffd exp(0.5\u02dc\u00b5[\u22a4]c [\u03a3][\ufffd] _[\u2212][1][\u00b5][\u02dc][c]_ _[\u2212]_ _[b][c][)]_ _._\n\n_c[\u2032][ exp(0][.][5\u02dc][\u00b5]c[\u22a4][\u2032][ \ufffd][\u03a3][\u2212][1][\u00b5][\u02dc][c][\u2032][ \u2212]_ _[b][c][\u2032]_ [)]\n\nHere, we normalize the _\u03b2[\u02dc]c to satisfy_ [\ufffd]c _[\u03b2][\u02dc][c][ = 1][. Then, using this generative classifier, we define new]_\n\nhybrid posterior distribution which combines the softmax- and sample-based generative classifiers:\n\n_Ph(y|x)_\n\n\ufffd \ufffd \ufffd \ufffd \ufffd\ufffd\n= exp _\u03bb_ _\u00b5\ufffd[\u22a4]c_ **[\u03a3][\ufffd]** _[\u2212][1][x][ \u2212]_ [0][.][5][\u00b5][\ufffd]c[\u22a4][\u03a3][\ufffd] _[\u2212][1][\u00b5][\ufffd][c]_ [+ log][ \ufffd][\u03b2][c] + (1 \u2212 _\u03bb)_ _\u00b5\u02dc[\u22a4]c_ **[\u03a3][\ufffd]** _[\u2212][1][x][ \u2212]_ [0][.][5][\u00b5][\u02dc]c[\u22a4][\u03a3][\ufffd] _[\u2212][1][\u00b5][\u02dc][c]_ [+ log \u02dc][\u03b2][c] _,_\n\n\ufffd \ufffd \ufffd \ufffd \ufffd\ufffd\n\ufffdc[\u2032][ exp] _\u03bb_ _\u00b5\ufffd[\u22a4]c[\u2032][ \ufffd][\u03a3][\u2212][1][x][ \u2212]_ [0][.][5][\u00b5][\ufffd][\u22a4]c[\u2032][ \ufffd][\u03a3][\u2212][1][\u00b5][\ufffd][c][\u2032][ + log][ \ufffd][\u03b2][c][\u2032] + (1 \u2212 _\u03bb)_ _\u00b5\u02dc[\u22a4]c[\u2032][ \ufffd][\u03a3][\u2212][1][x][ \u2212]_ [0][.][5][\u00b5][\u02dc][\u22a4]c[\u2032][ \ufffd][\u03a3][\u2212][1][\u00b5][\u02dc][c][\u2032][ + log \u02dc][\u03b2][c][\u2032]\n\nwhere \u03bb [0, 1] is a hyper-parameter. This hybrid model can be interpreted as ensemble of softmax\n_\u2208_\nand generative classifiers, and one can expect that it can improve the classification performance.\nTable 8 compares the classification accuracy of softmax, generative and hybrid classifiers. One can\nnote that the hybrid model improves the classification accuracy, where we determine the optimal\ntuning parameter between the two objectives using the validation set. We also remark that such\nhybrid model can be useful in detecting the abnormal samples, where we pursue these tasks in the\nfuture.\n\nModel Dataset Softmax Generative Hybrid\n\nCIFAR-10 95.16 94.76 95.00\nDenseNet CIFAR-100 77.64 74.01 77.71\nSVHN 96.42 96.32 96.34\n\nCIFAR-10 93.61 94.13 94.11\nResNet CIFAR-100 78.08 77.86 77.96\nSVHN 96.62 96.58 96.59\n\nTable 8: Classification test set accuracy (%) of DenseNet and ResNet on CIFAR-10, CIFAR-100\nand SVHN datasets.\n\n\n-----\n\n",
    "query": "I am interested in articles electric cars",
    "references": [
      {
        "arxiv_id": "1606.06565",
        "title": "Concrete problems in ai safety",
        "relevance_score": 1,
        "relevance_score_explanation": "The paper mentions this arXiv preprint in the context of AI safety, which is tangentially related to the topic of electric cars (as AI safety is relevant to the development of self-driving cars, a type of electric car)."
      },
      {
        "arxiv_id": "1707.08819",
        "title": "A downsampled variant of imagenet as an alternative to the cifar datasets",
        "relevance_score": 0,
        "relevance_score_explanation": "This paper is about a downsampled variant of ImageNet and is not related to electric cars."
      },
      {
        "arxiv_id": "1703.00410",
        "title": "Detecting adversarial samples from artifacts",
        "relevance_score": 0,
        "relevance_score_explanation": "This paper discusses detecting adversarial samples from artifacts in neural networks, which is not directly related to electric cars."
      },
      {
        "arxiv_id": "1711.00117",
        "title": "Countering adversarial images using input transformations",
        "relevance_score": 0,
        "relevance_score_explanation": "This article focuses on counteracting adversarial images using input transformations and is not related to electric cars."
      },
      {
        "arxiv_id": "1607.02533",
        "title": "Adversarial examples in the physical world",
        "relevance_score": 0,
        "relevance_score_explanation": "This paper discusses adversarial examples in the physical world, which is not directly related to electric cars."
      },
      {
        "arxiv_id": "1506.03365",
        "title": "Lsun: Construction of a large-scale image dataset using deep learning with humans in the loop",
        "relevance_score": 0,
        "relevance_score_explanation": "This paper describes the LSUN dataset, which is not related to electric cars."
      }
    ]
  },
  {
    "document": "### A Simple Unified Framework for Detecting Out-of-Distribution Samples and Adversarial Attacks\n\n**Kimin Lee[1], Kibok Lee[2], Honglak Lee[3][,][2], Jinwoo Shin[1][,][4]**\n\n1Korea Advanced Institute of Science and Technology (KAIST)\n2University of Michigan\n3Google Brain\n4AItrics\n\n\n###### Abstract\n\n\nDetecting test samples drawn sufficiently far away from the training distribution\nstatistically or adversarially is a fundamental requirement for deploying a good\nclassifier in many real-world machine learning applications. However, deep neural networks with the softmax classifier are known to produce highly overconfident\nposterior distributions even for such abnormal samples. In this paper, we propose\na simple yet effective method for detecting any abnormal samples, which is applicable to any pre-trained softmax neural classifier. We obtain the class conditional\nGaussian distributions with respect to (low- and upper-level) features of the deep\nmodels under Gaussian discriminant analysis, which result in a confidence score\nbased on the Mahalanobis distance. While most prior methods have been evaluated for detecting either out-of-distribution or adversarial samples, but not both,\nthe proposed method achieves the state-of-the-art performances for both cases in\nour experiments. Moreover, we found that our proposed method is more robust\nin harsh cases, e.g., when the training dataset has noisy labels or small number of\nsamples. Finally, we show that the proposed method enjoys broader usage by applying it to class-incremental learning: whenever out-of-distribution samples are\ndetected, our classification rule can incorporate new classes well without further\ntraining deep models.\n\n###### 1 Introduction\n\n\nDeep neural networks (DNNs) have achieved high accuracy on many classification tasks, e.g.,\nspeech recognition [1], object detection [9] and image classification [12]. However, measuring the\npredictive uncertainty still remains a challenging problem [20, 21]. Obtaining well-calibrated predictive uncertainty is indispensable since it could be useful in many machine learning applications\n(e.g., active learning [8] and novelty detection [18]) as well as when deploying DNNs in real-world\nsystems [2], e.g., self-driving cars and secure authentication system [6, 30].\n\nThe predictive uncertainty of DNNs is closely related to the problem of detecting abnormal samples that are drawn far away from in-distribution (i.e., distribution of training samples) statistically\nor adversarially. For detecting out-of-distribution (OOD) samples, recent works have utilized the\nconfidence from the posterior distribution [13, 21]. For example, Hendrycks & Gimpel [13] proposed the maximum value of posterior distribution from the classifier as a baseline method, and it\nis improved by processing the input and output of DNNs [21]. For detecting adversarial samples,\nconfidence scores were proposed based on density estimators to characterize them in feature spaces\nof DNNs [7]. More recently, Ma et al. [22] proposed the local intrinsic dimensionality (LID) and\nempirically showed that the characteristics of test samples can be estimated effectively using the\n\n32nd Conference on Neural Information Processing Systems (NIPS 2018), Montr\u00b4eal, Canada.\n\n\n-----\n\nLID. However, most prior works on this line typically do not evaluate both OOD and adversarial\nsamples. To best of our knowledge, no universal detector is known to work well on both tasks.\n\n**Contribution. In this paper, we propose a simple yet effective method, which is applicable to**\nany pre-trained softmax neural classifier (without re-training) for detecting abnormal test samples\nincluding OOD and adversarial ones. Our high-level idea is to measure the probability density of test\nsample on feature spaces of DNNs utilizing the concept of a \u201cgenerative\u201d (distance-based) classifier.\nSpecifically, we assume that pre-trained features can be fitted well by a class-conditional Gaussian\ndistribution since its posterior distribution can be shown to be equivalent to the softmax classifier\nunder Gaussian discriminant analysis (see Section 2.1 for our justification). Under this assumption,\nwe define the confidence score using the Mahalanobis distance with respect to the closest classconditional distribution, where its parameters are chosen as empirical class means and tied empirical\ncovariance of training samples. To the contrary of conventional beliefs, we found that using the\ncorresponding generative classifier does not sacrifice the softmax classification accuracy. Perhaps\nsurprisingly, its confidence score outperforms softmax-based ones very strongly across multiple\nother tasks: detecting OOD samples, detecting adversarial samples and class-incremental learning.\n\nWe demonstrate the effectiveness of the proposed method using deep convolutional neural networks,\nsuch as DenseNet [14] and ResNet [12] trained for image classification tasks on various datasets\nincluding CIFAR [15], SVHN [28], ImageNet [5] and LSUN [32]. First, for the problem of detecting\nOOD samples, the proposed method outperforms the current state-of-the-art method, ODIN [21], in\nall tested cases. In particular, compared to ODIN, our method improves the true negative rate (TNR),\ni.e., the fraction of detected OOD (e.g., LSUN) samples, from 45.6% to 90.9% on ResNet when\n95% of in-distribution (e.g., CIFAR-100) samples are correctly detected. Next, for the problem\nof detecting adversarial samples, e.g., generated by four attack methods such as FGSM [10], BIM\n\n[16], DeepFool [26] and CW [3], our method outperforms the state-of-the-art detection measure,\nLID [22]. In particular, compared to LID, ours improves the TNR of CW from 82.9% to 95.8% on\nResNet when 95% of normal CIFAR-10 samples are correctly detected.\n\nWe also found that our proposed method is more robust in the choice of its hyperparameters as well\nas against extreme scenarios, e.g., when the training dataset has some noisy, random labels or a\nsmall number of data samples. In particular, Liang et al. [21] tune the hyperparameters of ODIN\nusing validation sets of OOD samples, which is often impossible since the knowledge about OOD\nsamples is not accessible a priori. We show that hyperparameters of the proposed method can be\ntuned only using in-distribution (training) samples, while maintaining its performance. We further\nshow that the proposed method tuned on a simple attack, i.e., FGSM, can be used to detect other\nmore complex attacks such as BIM, DeepFool and CW.\n\nFinally, we apply our method to class-incremental learning [29]: new classes are added progressively\nto a pre-trained classifier. Since the new class samples are drawn from an out-of-training distribution,\nit is natural to expect that one can classify them using our proposed metric without re-training the\ndeep models. Motivated by this, we present a simple method which accommodates a new class at\nany time by simply computing the class mean of the new class and updating the tied covariance of all\nclasses. We show that the proposed method outperforms other baseline methods, such as Euclidean\ndistance-based classifier and re-trained softmax classifier. This evidences that our approach have a\npotential to apply to many other related machine learning tasks, such as active learning [8], ensemble\nlearning [19] and few-shot learning [31].\n\n###### 2 Mahalanobis distance-based score from generative classifier\n\nGiven deep neural networks (DNNs) with the softmax classifier, we propose a simple yet effective\nmethod for detecting abnormal samples such as out-of-distribution (OOD) and adversarial ones. We\nfirst present the proposed confidence score based on an induced generative classifier under Gaussian\ndiscriminant analysis (GDA), and then introduce additional techniques to improve its performance.\nWe also discuss how the confidence score is applicable to incremental learning.\n\n**2.1** **Why Mahalanobis distance-based score?**\n\n**Derivation of generative classifiers from softmax ones.** Let x \u2208X be an input and y \u2208\n= 1, _, C_ be its label. Suppose that a pre-trained softmax neural classifier is given:\n_Y_ _{_ _\u00b7 \u00b7 \u00b7_ _}_\n\n\n-----\n\n100\n\n90\n\n|Col1|1.00 0.95|\n|---|---|\n|0 0.2|0.90 0.85 0.4|\n||Softmax Euclidean Mahalanobis|\n\n\n0 0.5 1.0\n\n\n80\n\n70\n\n\n1.0\n\n0.8\n\n0.6\n\n0.4\n\n0.2\n\n0\n\n\nFPR on out-of-distribution (TinyImageNet)\n\n\n(a) Visualization by t-SNE\n\n\n(b) Classification accuracy\n\n\n(c) ROC curve\n\n\nFigure 1: Experimental results under the ResNet with 34 layers. (a) Visualization of final features\nfrom ResNet trained on CIFAR-10 by t-SNE, where the colors of points indicate the classes of the\ncorresponding objects. (b) Classification test set accuracy of ResNet on CIFAR-10, CIFAR-100 and\nSVHN datasets. (c) Receiver operating characteristic (ROC) curves: the x-axis and y-axis represent\nthe false positive rate (FPR) and true positive rate (TPR), respectively.\n\nexp(wc[\u22a4][f] [(][x][)+][b][c][)]\n_P (y = c|x) =_ \ufffdc[\u2032][ exp][(][w]c[\u22a4][\u2032] _[f]_ [(][x][)+][b][c][\u2032] [)] _[,][ where][ w][c][ and][ b][c][ are the weight and the bias of the soft-]_\n\nmax classifier for class c, and f ( ) denotes the output of the penultimate layer of DNNs. Then,\n\n_\u00b7_\nwithout any modification on the pre-trained softmax neural classifier, we obtain a generative classifier assuming that a class-conditional distribution follows the multivariate Gaussian distribution. Specifically, we define C class-conditional Gaussian distributions with a tied covariance \u03a3:\n_P (f_ (x)|y = c) = N (f (x)|\u00b5c, \u03a3), where \u00b5c is the mean of multivariate Gaussian distribution of\nclass c 1, ..., C . Here, our approach is based on a simple theoretical connection between GDA\n_\u2208{_ _}_\nand the softmax classifier: the posterior distribution defined by the generative classifier under GDA\nwith tied covariance assumption is equivalent to the softmax classifier (see the supplementary material for more details). Therefore, the pre-trained features of the softmax neural classifier f (x) might\nalso follow the class-conditional Gaussian distribution.\n\nTo estimate the parameters of the generative classifier from the pre-trained softmax neural classifier,\nwe compute the empirical class mean and covariance of training samples {(x1, y1), . . ., (xN _, yN_ )}:\n\n|Col1|Softmax|Col3|Col4|Col5|Ma|halanobis|Col8|\n|---|---|---|---|---|---|---|---|\n|||||||||\n|||||||||\n|||||||||\n|CIFA Cla he R -SN n tes char sitiv whe ote ined l di ndi||R-10 ssifi esN E, w t set acte e ra re w s th so stri tion|CIFAR Data catio et w her acc risti te ( a c e ou ftma butio al G|-100 sets n ac ith e th ura c (R TPR nd tput x n n f aus||SV cura 34 l e co cy o OC ), re b a c of eura ollo sian|HN cy aye lors f Re ) cu spe re t the l cl ws dis|\n\n\n_\u00b5c = [1]_\n\ufffd _Nc_\n\n\n\ufffd\n\n_f_ (xi), **\u03a3\ufffd** = [1]\n\n_N_\n\n_i:yi=c_\n\n\n\ufffd\n\n_c_\n\n\n\ufffd\n\n(f (xi) \u2212 _\u00b5\ufffdc) (f_ (xi) \u2212 _\u00b5\ufffdc)[\u22a4]_ _,_ (1)\n_i:yi=c_\n\n\nwhere Nc is the number of training samples with label c. This is equivalent to fitting the classconditional Gaussian distributions with a tied covariance to training samples under the maximum\nlikelihood estimator.\n\n**Mahalanobis distance-based confidence score. Using the above induced class-conditional Gaus-**\nsian distributions, we define the confidence score M (x) using the Mahalanobis distance between\ntest sample x and the closest class-conditional Gaussian distribution, i.e.,\n\n_M_ (x) = maxc _\u2212_ (f (x) \u2212 _\u00b5\ufffdc)[\u22a4]_ **\u03a3[\ufffd]** _[\u2212][1]_ (f (x) \u2212 _\u00b5\ufffdc) ._ (2)\n\n\nNote that this metric corresponds to measuring the log of the probability densities of the test sample.\nHere, we remark that abnormal samples can be characterized better in the representation space of\nDNNs, rather than the \u201clabel-overfitted\u201d output space of softmax-based posterior distribution used\nin the prior works [13, 21] for detecting them. It is because a confidence measure obtained from the\nposterior distribution can show high confidence even for abnormal samples that lie far away from\nthe softmax decision boundary. Feinman et al. [7] and Ma et al. [22] process the DNN features for\ndetecting adversarial samples in a sense, but do not utilize the Mahalanobis distance-based metric,\ni.e., they only utilize the Euclidean distance in their scores. In this paper, we show that Mahalanobis\ndistance is significantly more effective than the Euclidean distance in various tasks.\n\n**Experimental supports for generative classifiers. To evaluate our hypothesis that trained features**\nof DNNs support the assumption of GDA, we measure the classification accuracy as follows:\n\n_y\ufffd(x) = arg minc_ (f (x) \u2212 _\u00b5\ufffdc)[\u22a4]_ **\u03a3[\ufffd]** _[\u2212][1]_ (f (x) \u2212 _\u00b5\ufffdc) ._ (3)\n\n\n-----\n\n**Algorithm 1 Computing the Mahalanobis distance-based confidence score.**\n\n**Input: Test sample x, weights of logistic regression detector \u03b1\u2113, noise \u03b5 and parameters of Gaus-**\nsian distributions {\u00b5\ufffd\u2113,c, **\u03a3[\ufffd]** _\u2113_ : \u2200\u2113, c}\n\n\nInitialize score vectors: M(x) = [M\u2113 : \u2200\u2113]\n**for each layer \u2113** _\u2208_ 1, . . ., L do\n\nFind the closest class: \ufffdc = arg minc (f\u2113(x) \u2212 _\u00b5\ufffd\u2113,c)[\u22a4]\u03a3[\ufffd]_ _[\u2212]\u2113_ [1][(][f][\u2113][(][x][)][ \u2212] _[\u00b5][\ufffd][\u2113,c][)]_\n\n\ufffd \ufffd\nAdd small noise to test sample: \ufffdx = x \u2212 _\u03b5sign_ _\u25bdx (f\u2113(x) \u2212_ _\u00b5\ufffd\u2113,\ufffdc)[\u22a4]_ **\u03a3[\ufffd]** _[\u2212]\u2113_ [1] (f\u2113(x) \u2212 _\u00b5\ufffd\u2113,\ufffdc)_\n\nComputing confidence score: M\u2113 = maxc _\u2212_ (f\u2113(x\ufffd) \u2212 _\u00b5\ufffd\u2113,c)[\u22a4]_ **\u03a3[\ufffd]** _[\u2212]\u2113_ [1] (f\u2113(x\ufffd) \u2212 _\u00b5\ufffd\u2113,c)_\n\n**end for**\n**return Confidence score for test sample** _\u2113_ _[\u03b1][\u2113][M][\u2113]_\n\n[\ufffd]\n\n\n100\n\n90\n\n80\n\n70\n\n60\n\n\n100\n\n90\n\n80\n\n70\n\n60\n\n\n100\n\n90\n\n80\n\n70\n\n60\n\n50\n\n40\n\n30\n\n\n100\n\n90\n\n80\n\n70\n\n60\n\n50\n\n40\n\n30\n\n\n(a) TinyImageNet (b) LSUN (c) SVHN (d) DeepFool\n\nFigure 2: AUROC (%) of threshold-based detector using the confidence score in (2) computed at\ndifferent basic blocks of DenseNet trained on CIFAR-10 dataset. We measure the detection performance using (a) TinyImageNet, (b) LSUN, (c) SVHN and (d) adversarial (DeepFool) samples.\n\n|Col1|Col2|\n|---|---|\n|||\n|||\n|Index of b (c) SV|asic block HN|\n\n|Col1|Col2|\n|---|---|\n|||\n|||\n|Index of b (d) Dee|asic block pFool|\n\n\nWe remark that this corresponds to predicting a class label using the posterior distribution from generative classifier with the uniform class prior. Interestingly, we found that the softmax accuracy (red\nbar) is also achieved by the Mahalanobis distance-based classifier (blue bar), while conventional\nknowledge is that a generative classifier trained from scratch typically performs much worse than a\ndiscriminative classifier such as softmax. For visual interpretation, Figure 1(a) presents embeddings\nof final features from CIFAR-10 test samples constructed by t-SNE [23], where the colors of points\nindicate the classes of the corresponding objects. One can observe that all ten classes are clearly\nseparated in the embedding space, which supports our intuition. In addition, we also show that\nMahalanobis distance-based metric can be very useful in detecting out-of-distribution samples. For\nevaluation, we obtain the receiver operating characteristic (ROC) curve using a simple thresholdbased detector by computing the confidence score M (x) on a test sample x and decide it as positive\n(i.e., in-distribution) if M (x) is above some threshold. The Euclidean distance, which only utilizes\nthe empirical class means, is considered for comparison. We train ResNet on CIFAR-10, and TinyImageNet dataset [5] is used for an out-of-distribution. As shown in Figure 1(c), the Mahalanobis\ndistance-based metric (blue bar) performs better than Euclidean one (green bar) and the maximum\nvalue of the softmax distribution (red bar).\n\n**2.2** **Calibration techniques**\n\n|Col1|Col2|\n|---|---|\n|||\n|Index of b a) TinyIm re 2: AU rent basi ce using|asic block ageNet ROC (% c blocks (a) TinyI|\n\n|Col1|Col2|\n|---|---|\n|||\n|Index of b (b) LS eshold-b seNet tra et, (b) LS|asic block UN ased det ined on UN, (c)|\n\n\n**Input pre-processing. To make in- and out-of-distribution samples more separable, we consider**\nadding a small controlled noise to a test sample. Specifically, for each test sample x, we calculate\nthe pre-processed sample **x by adding the small perturbations as follows:**\n\ufffd\n\n\ufffd \ufffd\n**x\ufffd = x + \u03b5sign (\u25bdxM** (x)) = x \u2212 _\u03b5sign_ _\u25bdx (f_ (x) \u2212 _\u00b5\ufffd\ufffdc)[\u22a4]_ **\u03a3[\ufffd]** _[\u2212][1]_ (f (x) \u2212 _\u00b5\ufffd\ufffdc)_ _,_ (4)\n\nwhere \u03b5 is a magnitude of noise and _c is the index of the closest class. Next, we measure the confi-_\n\ufffd\ndence score using the pre-processed sample. We remark that the noise is generated to increase the\nproposed confidence score (2) unlike adversarial attacks [10]. In our experiments, such perturbation can have stronger effect on separating the in- and out-of-distribution samples. We remark that\nsimilar input pre-processing was studied in [21], where the perturbations are added to increase the\nsoftmax score of the predicted label. However, our method is different in that the noise is generated\nto increase the proposed metric.\n\n\n-----\n\n**Algorithm 2 Updating Mahalanobis distance-based classifier for class-incremental learning.**\n\n**Input: set of samples from a new class {xi : \u2200i = 1 . . . NC+1}, mean and covariance of observed**\nclasses {\u00b5\ufffdc : \u2200c = 1 . . . C}, **\u03a3[\ufffd]**\n\nCompute the new class mean: \ufffd\u00b5C+1 \u2190 _NC1+1_ \ufffdi _[f]_ [(][x][i][)]\n\nCompute the covariance of the new class: **\u03a3[\ufffd]** _C+1 \u2190_ _NC1+1_ \ufffdi[(][f] [(][x][i][)][ \u2212] _[\u00b5][\ufffd][C][+1][)(][f]_ [(][x][i][)][ \u2212] _[\u00b5][\ufffd][C][+1][)][\u22a4]_\n\nUpdate the shared covariance: **\u03a3[\ufffd]** _\u2190_ _CC+1_ **[\u03a3][\ufffd]** [ +] _C1+1_ **[\u03a3][\ufffd]** _[C][+1]_\n\n**return Mean and covariance of all classes {\u00b5\ufffdc : \u2200c = 1 . . . C + 1},** **\u03a3[\ufffd]**\n\n**Feature ensemble. To further improve the performance, we consider measuring and combining the**\nconfidence scores from not only the final features but also the other low-level features in DNNs.\nFormally, given training data, we extract the \u2113-th hidden features of DNNs, denoted by f\u2113(x), and\ncompute their empirical class means and tied covariances, i.e., _\u00b5\u2113,c and_ **\u03a3\u2113. Then, for each test**\n\ufffd [\ufffd]\nsample x, we measure the confidence score from the \u2113-th layer using the formula in (2). One can\nexpect that this simple but natural scheme can bring an extra gain in obtaining a better calibrated\nscore by extracting more input-specific information from the low-level features. We measure the\narea under ROC (AUROC) curves of the threshold-based detector using the confidence score in\n(2) computed at different basic blocks of DenseNet [14] trained on CIFAR-10 dataset, where the\noverall trends on ResNet are similar. Figure 2 shows the performance on various OOD samples such\nas SVHN [28], LSUN [32], TinyImageNet and adversarial samples generated by DeepFool [26],\nwhere the dimensions of the intermediate features are reduced using average pooling (see Section\n3 for more details). As shown in Figure 2, the confidence scores computed at low-level features\noften provide better calibrated ones compared to final features (e.g., LSUN, TinyImageNet and\nDeepFool). To further improve the performance, we design a feature ensemble method as described\nin Algorithm 1. We first extract the confidence scores from all layers, and then integrate them by\nweighted averaging: [\ufffd]\u2113 _[\u03b1][\u2113][M][\u2113][(][x][)][, where][ M][\u2113][(][\u00b7][)][ and][ \u03b1][\u2113]_ [is the confidence score at the][ \u2113][-th layer]\n\nand its weight, respectively. In our experiments, following similar strategies in [22], we choose\nthe weight of each layer \u03b1\u2113 by training a logistic regression detector using validation samples. We\nremark that such weighted averaging of confidence scores can prevent the degradation on the overall\nperformance even in the case when the confidence scores from some layers are not effective: the\ntrained weights (using validation) would be nearly zero for those ineffective layers.\n\n\n**2.3** **Class-incremental learning using Mahalanobis distance-based score**\n\nAs a natural extension, we also show that the Mahalanobis distance-based confidence score can be\nutilized in class-incremental learning tasks [29]: a classifier pre-trained on base classes is progressively updated whenever a new class with corresponding samples occurs. This task is known to be\nchallenging since one has to deal with catastrophic forgetting [24] with a limited memory. To this\nend, recent works have been toward developing new training methods which involve a generative\nmodel or data sampling, but adopting such training methods might incur expensive back-and-forth\ncosts. Based on the proposed confidence score, we develop a simple classification method without\nthe usage of complicated training methods. To do this, we first assume that the classifier is well\npre-trained with a certain amount of base classes, where the assumption is quite reasonable in many\npractical scenarios.[1] In this case, one can expect that not only the classifier can detect OOD samples\nwell, but also might be good for discriminating new classes, as the representation learned with the\nbase classes can characterize new ones. Motivated by this, we present a Mahalanobis distance-based\nclassifier based on (3), which tries to accommodate a new class by simply computing and updating\nthe class mean and covariance, as described in Algorithm 2. The class-incremental adaptation of our\nconfidence score shows its potential to be applied to a wide range of new applications in the future.\n\n1For example, state-of-the-art CNNs trained on large-scale image dataset are off-the-shelf [12, 14], so they\nare a starting point in many computer vision tasks [9, 18, 25].\n\n\n-----\n\nFeature Input TNR Detection AUPR AUPR\nMethod AUROC\nensemble pre-processing at TPR 95% accuracy in out\n\nBaseline [13] - - 32.47 89.88 85.06 85.40 93.96\n\nODIN [21] - - 86.55 96.65 91.08 92.54 98.52\n\n\nMahalanobis\n(ours)\n\n\n - - 54.51 93.92 89.13 91.56 95.95\n - \u2713 92.26 98.30 93.72 96.01 99.28\n\u2713 - 91.45 98.37 93.55 96.43 99.35\n\u2713 \u2713 **96.42** **99.14** **95.75** **98.26** **99.60**\n\n\nTable 1: Contribution of each proposed method on distinguishing in- and out-of-distribution test\nset data. We measure the detection performance using ResNet trained on CIFAR-10, when SVHN\ndataset is used as OOD. All values are percentages and the best results are indicated in bold.\n\n###### 3 Experimental results\n\nIn this section, we demonstrate the effectiveness of the proposed method using deep convolutional\nneural networks such as DenseNet [14] and ResNet [12] on various vision datasets: CIFAR [15],\nSVHN [28], ImageNet [5] and LSUN [32]. Due to the space limitation, we provide the more detailed\n[experimental setups and results in the supplementary material. Our code is available at https:](https://github.com/pokaxpoka/deep_Mahalanobis_detector)\n```\n//github.com/pokaxpoka/deep_Mahalanobis_detector.\n\n```\n**3.1** **Detecting out-of-distribution samples**\n\n**Setup. For the problem of detecting out-of-distribution (OOD) samples, we train DenseNet with 100**\nlayers and ResNet with 34 layers for classifying CIFAR-10, CIFAR-100 and SVHN datasets. The\ndataset used in training is the in-distribution (positive) dataset and the others are considered as OOD\n(negative). We only use test datasets for evaluation. In addition, the TinyImageNet (i.e., subset of\nImageNet dataset) and LSUN datasets are also tested as OOD. For evaluation, we use a thresholdbased detector which measures some confidence score of the test sample, and then classifies the\ntest sample as in-distribution if the confidence score is above some threshold. We measure the\nfollowing metrics: the true negative rate (TNR) at 95% true positive rate (TPR), the area under the\nreceiver operating characteristic curve (AUROC), the area under the precision-recall curve (AUPR),\nand the detection accuracy. For comparison, we consider the baseline method [13], which defines\na confidence score as a maximum value of the posterior distribution, and the state-of-the-art ODIN\n\n[21], which defines the confidence score as a maximum value of the processed posterior distribution.\n\nFor our method, we extract the confidence scores from every end of dense (or residual) block of\nDenseNet (or ResNet). The size of feature maps on each convolutional layers is reduced by average\npooling for computational efficiency: 1, where is the number of channels\n_F \u00d7 H \u00d7 W \u2192F \u00d7_ _F_\nand is the spatial dimension. As shown in Algorithm 1, the output of the logistic regres_H \u00d7 W_\nsion detector is used as the final confidence score in our case. All hyperparameters are tuned on a\nseparate validation set, which consists of 1,000 images from each in- and out-of-distribution pair.\nSimilar to Ma et al. [22], the weights of logistic regression detector are trained using nested cross\nvalidation within the validation set, where the class label is assigned positive for in-distribution samples and assigned negative for OOD samples. Since one might not have OOD validation datasets in\npractice, we also consider tuning the hyperparameters using in-distribution (positive) samples and\ncorresponding adversarial (negative) samples generated by FGSM [10].\n\n**Contribution by each technique and comparison with ODIN. Table 1 validates the contributions**\nof our suggested techniques under the comparison with the baseline method and ODIN. We measure\nthe detection performance using ResNet trained on CIFAR-10, when SVHN dataset is used as OOD.\nWe incrementally apply our techniques to see the stepwise improvement by each component. One\ncan note that our method significantly outperforms the baseline method without feature ensembles\nand input pre-processing. This implies that our method can characterize the OOD samples very\neffectively compared to the posterior distribution. By utilizing the feature ensemble and input preprocessing, the detection performance are further improved compared to that of ODIN. The left-hand\ncolumn of Table 2 reports the detection performance with ODIN for all in- and out-of-distribution\n\n\n-----\n\n|Validation on OOD samples In-dist OOD TNR at TPR 95% AUROC Detection acc. (model) Baseline [13] / ODIN [21] / Mahalanobis (ours)|Validation on adversarial samples TNR at TPR 95% AUROC Detection acc.|\n|---|---|\n||Baseline [13] / ODIN [21] / Mahalanobis (ours)|\n|SVHN 40.2 / 86.2 / 90.8 89.9 / 95.5 / 98.1 83.2 / 91.4 / 93.9 CIFAR-10 TinyImageNet 58.9 / 92.4 / 95.0 94.1 / 98.5 / 98.8 88.5 / 93.9 / 95.0 (DenseNet) LSUN 66.6 / 96.2 / 97.2 95.4 / 99.2 / 99.3 90.3 / 95.7 / 96.3|40.2 / 70.5 / 89.6 89.9 / 92.8 / 97.6 83.2 / 86.5 / 92.6 58.9 / 87.1 / 94.9 94.1 / 97.2 / 98.8 88.5 / 92.1 / 95.0 66.6 / 92.9 / 97.2 95.4 / 98.5 / 99.2 90.3 / 94.3 / 96.2|\n|SVHN 26.7 / 70.6 / 82.5 82.7 / 93.8 / 97.2 75.6 / 86.6 / 91.5 CIFAR-100 TinyImageNet 17.6 / 42.6 / 86.6 71.7 / 85.2 / 97.4 65.7 / 77.0 / 92.2 (DenseNet) LSUN 16.7 / 41.2 / 91.4 70.8 / 85.5 / 98.0 64.9 / 77.1 / 93.9|26.7 / 39.8 / 62.2 82.7 / 88.2 / 91.8 75.6 / 80.7 / 84.6 17.6 / 43.2 / 87.2 71.7 / 85.3 / 97.0 65.7 / 77.2 / 91.8 16.7 / 42.1 / 91.4 70.8 / 85.7 / 97.9 64.9 / 77.3 / 93.8|\n|CIFAR-10 69.3 / 71.7 / 96.8 91.9 / 91.4 / 98.9 86.6 / 85.8 / 95.9 SVHN TinyImageNet 79.8 / 84.1 / 99.9 94.8 / 95.1 / 99.9 90.2 / 90.4 / 98.9 (DenseNet) LSUN 77.1 / 81.1 / 100 94.1 / 94.5 / 99.9 89.1 / 89.2 / 99.3|69.3 / 69.3 / 97.5 91.9 / 91.9 / 98.8 86.6 / 86.6 / 96.3 79.8 / 79.8 / 99.9 94.8 / 94.8 / 99.8 90.2 / 90.2 / 98.9 77.1 / 77.1 / 100 94.1 / 94.1 / 99.9 89.1 / 89.1 / 99.2|\n|SVHN 32.5 / 86.6 / 96.4 89.9 / 96.7 / 99.1 85.1 / 91.1 / 95.8 CIFAR-10 TinyImageNet 44.7 / 72.5 / 97.1 91.0 / 94.0 / 99.5 85.1 / 86.5 / 96.3 (ResNet) LSUN 45.4 / 73.8 / 98.9 91.0 / 94.1 / 99.7 85.3 / 86.7 / 97.7|32.5 / 40.3 / 75.8 89.9 / 86.5 / 95.5 85.1 / 77.8 / 89.1 44.7 / 69.6 / 95.5 91.0 / 93.9 / 99.0 85.1 / 86.0 / 95.4 45.4 / 70.0 / 98.1 91.0 / 93.7 / 99.5 85.3 / 85.8 / 97.2|\n|SVHN 20.3 / 62.7 / 91.9 79.5 / 93.9 / 98.4 73.2 / 88.0 / 93.7 CIFAR-100 TinyImageNet 20.4 / 49.2 / 90.9 77.2 / 87.6 / 98.2 70.8 / 80.1 / 93.3 (ResNet) LSUN 18.8 / 45.6 / 90.9 75.8 / 85.6 / 98.2 69.9 / 78.3 / 93.5|20.3 / 12.2 / 41.9 79.5 / 72.0 / 84.4 73.2 / 67.7 / 76.5 20.4 / 33.5 / 70.3 77.2 / 83.6 / 87.9 70.8 / 75.9 / 84.6 18.8 / 31.6 / 56.6 75.8 / 81.9 / 82.3 69.9 / 74.6 / 79.7|\n|CIFAR-10 78.3 / 79.8 / 98.4 92.9 / 92.1 / 99.3 90.0 / 89.4 / 96.9 SVHN TinyImageNet 79.0 / 82.1 / 99.9 93.5 / 92.0 / 99.9 90.4 / 89.4 / 99.1 (ResNet) LSUN 74.3 / 77.3 / 99.9 91.6 / 89.4 / 99.9 89.0 / 87.2 / 99.5|78.3 / 79.8 / 94.1 92.9 / 92.1 / 97.6 90.0 / 89.4 / 94.6 79.0 / 80.5 / 99.2 93.5 / 92.9 / 99.3 90.4 / 90.1 / 98.8 74.3 / 76.3 / 99.9 91.6 / 90.7 / 99.9 89.0 / 88.2 / 99.5|\n\n\nTable 2: Distinguishing in- and out-of-distribution test set data for image classification under various\nvalidation setups. All values are percentages and the best results are indicated in bold.\n\n\n100\n\n90\n\n80\n\n70\n\n60\n\n\n100\n\n90\n\n80\n\n70\n\n60\n\n\n100\n\n90\n\n80\n\n\nOut-of-distribution: SVHN\n\n\nOut-of-distribution: TinyImageNet\n\n\nOut-of-distribution: SVHN\n\n\nOut-of-distribution: TinyImageNet\n\n\nBaseline\n\n70 ODIN\n\nMahalanobis\n60\n\n\n100\n\n90\n\n80\n\n70\n\n60\n\n\n(a) Small number of training data\n\n\n(b) Training data with random labels\n\n\nFigure 3: Comparison of AUROC (%) under extreme scenarios: (a) small number of training data,\nwhere the x-axis represents the number of training data. (b) Random label is assigned to training\ndata, where the x-axis represents the percentage of training data with random label.\n\ndataset pairs. Our method outperforms the baseline and ODIN for all tested cases. In particular,\nour method improves the TNR, i.e., the fraction of detected LSUN samples, compared to ODIN:\n41.2% 91.4% using DenseNet, when 95% of CIFAR-100 samples are correctly detected.\n_\u2192_\n\n**Comparison of robustness. In order to evaluate the robustness of our method, we measure the**\ndetection performance when all hyperparameters are tuned only using in-distribution and adversarial\nsamples generated by FGSM [10]. As shown in the right-hand column of Table 2, ODIN is working\npoorly compared to the baseline method in some cases (e.g., DenseNet trained on SVHN), while our\nmethod still outperforms the baseline and ODIN consistently. We remark that our method validated\nwithout OOD but adversarial samples even outperforms ODIN validated with OOD. We also verify\nthe robustness of our method under various training setups. Since our method utilizes empirical\nclass mean and covariance of training samples, there is a caveat such that it can be affected by the\nproperties of training data. In order to verify the robustness, we measure the detection performance\nwhen we train ResNet by varying the number of training data and assigning random label to training\ndata on CIFAR-10 dataset. As shown in Figure 3, our method (blue bar) maintains high detection\nperformances even for small number of training data or noisy one, while baseline (red bar) and ODIN\n(yellow bar) do not. Finally, we remark that our method using softmax neural classifier trained by\nstandard cross entropy loss typically outperforms the ODIN using softmax neural classifier trained\nby confidence loss [20] which involves jointly training a generator and a classifier to calibrate the\nposterior distribution even though training such model is computationally more expensive (see the\nsupplementary material for more details).\n\n**3.2** **Detecting adversarial samples**\n\n**Setup. For the problem of detecting adversarial samples, we train DenseNet and ResNet for classi-**\nfying CIFAR-10, CIFAR-100 and SVHN datasets, and the corresponding test dataset is used as the\n\n|Col1|Col2|Col3|Col4|Col5|Col6|Col7|Col8|Col9|Col10|Col11|Col12|Col13|Col14|Col15|\n|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n||||||||||||||||\n||||||||B O M|as D a|el IN ha|in la|e n|ob|is||\n||||||||||||||||\n|ur r ,|5K e e|w|1 3 th h|0 : e|K ( e r|20K a) Co x- e t|30 Sm m axi he|K a p s x|4 l ar -|0 l i r a|K n s e x|5 u o p i|0 m n r s|K e|\n\n|Col1|Col2|Col3|Col4|Col5|Col6|Col7|Col8|Col9|Col10|Col11|Col12|Col13|Col14|Col15|\n|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n||||||||B|as|el|in|e||||\n||||||||O M|DI a|N ha|la|n|ob|is||\n|t U t e|5K ra R h n|i e t|1 n O s|0 i C n|K n u th|20K g d (% mb e|30 ata ) er per|K u c|4 n o e|0 d f n|K e t t|5 r r a|0 e a g|K i e|\n\n|Col1|Col2|Col3|Col4|Col5|Col6|Col7|Col8|Col9|Col10|Col11|Col12|Col13|Col14|Col15|\n|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n||B|as|eli|n|e||||||||||\n||O M|D a|IN hal|a|no|bi|s||||||||\n||||||||||||||||\n|0% sc ta ni|e . n|1 ( n ( g|0% b a b d|) r )|2 io at|0 Tr s R a|% a : a|3 in ( n w|0 i a d i|% n ) o th|4 g s m|0 d ra|% a m l n|t a a|\n\n|Col1|Col2|Col3|Col4|Col5|Col6|Col7|Col8|Col9|Col10|Col11|Col12|Col13|Col14|Col15|\n|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n||B|as|el|in|e||||||||||\n||O M|D a|IN ha|la|no|bi|s||||||||\n||||||||||||||||\n|0% ra b a ab|n e ss e|1 d r i l.|0 o o g|% m f n|2 l t e|0 a r d|% b ai t|3 el n o|0 s i|% n tr|4 g a|0 d i|% a n|t i|\n\n\n-----\n\n|Dataset Model Score (model)|Detection of known attack FGSM BIM DeepFool CW|Detection of unknown attack FGSM (seen) BIM DeepFool CW|\n|---|---|---|\n|KD+PU [7] CIFAR-10 LID [22] Mahalanobis (ours) KD+PU [7] DenseNet CIFAR-100 LID [22] Mahalanobis (ours) KD+PU [7] SVHN LID [22] Mahalanobis (ours)|85.96 96.80 68.05 58.72 98.20 99.74 85.14 80.05 99.94 99.78 83.41 87.31|85.96 3.10 68.34 53.21 98.20 94.55 70.86 71.50 99.94 99.51 83.42 87.95|\n||90.13 89.69 68.29 57.51 99.35 98.17 70.17 73.37 99.86 99.17 77.57 87.05|90.13 66.86 65.30 58.08 99.35 68.62 69.68 72.36 99.86 98.27 75.63 86.20|\n||86.95 82.06 89.51 85.68 99.35 94.87 91.79 94.70 99.85 99.28 95.10 97.03|86.95 83.28 84.38 82.94 99.35 92.21 80.14 85.09 99.85 99.12 93.47 96.95|\n|KD+PU [7] CIFAR-10 LID [22] Mahalanobis (ours) KD+PU [7] ResNet CIFAR-100 LID [22] Mahalanobis (ours) KD+PU [7] SVHN LID [22] Mahalanobis (ours)|81.21 82.28 81.07 55.93 99.69 96.28 88.51 82.23 99.94 99.57 91.57 95.84|83.51 16.16 76.80 56.30 99.69 95.38 71.86 77.53 99.94 98.91 78.06 93.90|\n||89.90 83.67 80.22 77.37 98.73 96.89 71.95 78.67 99.77 96.90 85.26 91.77|89.90 68.85 57.78 73.72 98.73 55.82 63.15 75.03 99.77 96.38 81.95 90.96|\n||82.67 66.19 89.71 76.57 97.86 90.74 92.40 88.24 99.62 97.15 95.73 92.15|82.67 43.21 84.30 67.85 97.86 84.88 67.28 76.58 99.62 95.39 72.20 86.73|\n\n\nTable 3: Comparison of AUROC (%) under various validation setups. For evaluation on unknown\nattack, FGSM samples denoted by \u201cseen\u201d are used for validation. For our method, we use both\nfeature ensemble and input pre-processing. The best results are indicated in bold.\n\npositive samples to measure the performance. We use adversarial images as the negative samples\ngenerated by the following attack methods: FGSM [10], BIM [16], DeepFool [26] and CW [3],\nwhere the detailed explanations can be found in the supplementary material. For comparison, we\nuse a logistic regression detector based on combinations of kernel density (KD) [7] and predictive\nuncertainty (PU), i.e., maximum value of posterior distribution. We also compare the state-of-theart local intrinsic dimensionality (LID) scores [22]. Following the similar strategies in [7, 22], we\nrandomly choose 10% of original test samples for training the logistic regression detectors and the\nremaining test samples are used for evaluation. Using nested cross-validation within the training set,\nall hyper-parameters are tuned.\n\n**Comparison with LID and generalization analysis. The left-hand column of Table 3 reports the**\nAUROC score of a logistic regression detectors for all normal and adversarial pairs. One can note\nthat the proposed method outperforms all tested methods in most cases. In particular, ours improves\nthe AUROC of LID from 82.2% to 95.8% when we detect CW samples using ResNet trained on\nthe CIFAR-10 dataset. Similar to [22], we also evaluate whether the proposed method is tuned on\na simple attack can be generalized to detect other more complex attacks. To this end, we measure\nthe detection performance when we train the logistic regression detector using samples generated by\nFGSM. As shown in the right-hand column of Table 3, our method trained on FGSM can accurately\ndetect much more complex attacks such as BIM, DeepFool and CW. Even though LID can also\ngeneralize well, our method still outperforms it in most cases. A natural question that arises is\nwhether the LID can be useful in detecting OOD samples. We indeed compare the performance of\nour method with that of LID in the supplementary material, where our method still outperforms LID\nin all tested case.\n\n**3.3** **Class-incremental learning**\n\n**Setup. For the task of class-incremental learning, we train ResNet with 34 layers for classifying**\nCIFAR-100 and downsampled ImageNet [4]. As described in Section 2.3, we assume that a classifier\nis pre-trained on a certain amount of base classes and new classes with corresponding datasets are\nincrementally provided one by one. Specifically, we test two different scenarios: in the first scenario,\nhalf of CIFAR-100 classes are bases classes and the rest are new classes. In the second scenario,\nall classes in CIFAR-100 are considered to be base classes and 100 of ImageNet classes are new\nclasses. All scenarios are tested five times and then averaged. Class splits are randomly generated\nfor each trial. For comparison, we consider a softmax classifier, which is fine-tuned whenever new\nclass data come in, and a Euclidean classifier [25], which tries to accommodate a new class by only\ncomputing the class mean. For the softmax classifier, we only update the softmax layer to achieve\nnear-zero cost training [25], and follow the memory management in Rebuffi & Kolesnikov [29]: a\nsmall number of samples from old classes are kept in the limited memory, where the size of the\n\n\n-----\n\n80\n\n70\n\n60\n\n50\n\n40\n\n30\n\n|Col1|Col2|Col3|S E|oftmax uclidean|Col6|\n|---|---|---|---|---|---|\n|||M||ahalanobi|s (ours)|\n|||||||\n|||||||\n|||||||\n\n|Col1|Col2|Col3|Col4|\n|---|---|---|---|\n|||||\n|||||\n|||||\n|Softma|x|||\n|Euclide Mahala|an nobis (ours)|||\n\n|Col1|Col2|S E M|S E|oftmax uclidean|Col6|\n|---|---|---|---|---|---|\n|||||ahalanobi|s (ours)|\n|||||||\n|||||||\n|||||||\n\n|Col1|Col2|Col3|Col4|Col5|\n|---|---|---|---|---|\n||||||\n||||||\n|Softma|x||||\n|Euclide Mahala|an nobis (ours)||||\n\n\n50 60 70 80 90 100\n\nThe number of classes\n\n\n0 20 40 60 80\n\nBase class accuracy (%)\n\n\n80\n\n60\n\n\n30\n\n20\n\n\n40\n\n20\n\n\n0 20 40 60 80\n\nBase class accuracy (%)\n\n\n60\n\n50\n\n40\n\n30\n\n20\n\n10\n\n0\n\n\n100 120 140 160 180 200\n\nThe number of classes\n\n\n10\n\n0\n\n\n(a) Base: half of CIFAR-100 / New: the other half\n\n\n(b) Base: CIFAR-100 / New: ImageNet\n\n\nFigure 4: Experimental results of class-incremental learning on CIFAR-100 and ImageNet datasets.\nIn each experiment, we report (left) AUC with respect to the number of learned classes and, (right)\nthe base-new class accuracy curve after the last new classes is added.\n\nmemory is matched with that for keeping the parameters for Mahalanobis distance-based classifier.\nNamely, the number of old exemplars kept for training the softmax classifier is chosen as the sum of\nthe number of learned classes and the dimension (512 in our experiments) of the hidden features. For\nevaluation, similar to [18], we first draw base-new class accuracy curve by adjusting an additional\nbias to the new class scores, and measure the area under curve (AUC) since averaging base and new\nclass accuracy may cause an imbalanced measure of the performance between base and new classes.\n\n**Comparison with other classifiers. Figure 4 compares the incremental learning performance of**\nmethods in terms of AUC in the two scenarios mentioned above. In each sub-figure, AUC with respect to the number of learned classes (left) and the base-new class accuracy curve after the last new\nclasses is added (right) are drawn. Our proposed Mahalanobis distance-based classifier outperforms\nthe other methods by a significant margin, as the number of new classes increases, although there\nis a crossing in the right figure of Figure 4(b) in small regimes (due to the catastrophic forgetting\nissue). In particular, the AUC of our proposed method is 40.0% (22.1%), which is better than 32.7%\n(15.6%) of the softmax classifier and 32.9% (17.1%) of the Euclidean distance classifier after all\nnew classes are added in the first (second) experiment. We also report the experimental results in\nthe supplementary material for the case when classes of CIFAR-100 are base classes and those of\nCIFAR-10 are new classes, where the overall trend is similar. The experimental results additionally\ndemonstrate the superiority of our confidence score, compared to other plausible ones.\n\n\n###### 4 Conclusion\n\nIn this paper, we propose a simple yet effective method for detecting abnormal test samples including\nboth out-of-distribution and adversarial ones. In essence, our main idea is inducing a generative\nclassifier under LDA assumption, and defining new confidence score based on it. With calibration\ntechniques such as input pre-processing and feature ensemble, our method performs very strongly\nacross multiple tasks: detecting out-of-distribution samples, detecting adversarial attacks and classincremental learning. We also found that our proposed method is more robust in the choice of its\nhyperparameters as well as against extreme scenarios, e.g., when the training dataset has some noisy,\nrandom labels or a small number of data samples. We believe that our approach have a potential to\napply to many other related machine learning tasks, e.g., active learning [8], ensemble learning [19]\nand few-shot learning [31].\n\n\n**Acknowledgements**\n\nThis work was supported in part by Institute for Information & communications Technology Promotion (IITP) grant funded by the Korea government (MSIT) (No.R0132-15-1005, Content visual\nbrowsing technology in the online and offline environments), National Research Council of Science\n& Technology (NST) grant by the Korea government (MSIP) (No. CRC-15-05-ETRI), DARPA\nExplainable AI (XAI) program #313498, Sloan Research Fellowship, and Kwanjeong Educational\nFoundation Scholarship.\n\n\n-----\n\n###### References\n\n[1] Amodei, Dario, Ananthanarayanan, Sundaram, Anubhai, Rishita, Bai, Jingliang, Battenberg,\nEric, Case, Carl, Casper, Jared, Catanzaro, Bryan, Cheng, Qiang, Chen, Guoliang, et al. Deep\nspeech 2: End-to-end speech recognition in english and mandarin. In ICML, 2016.\n\n[2] Amodei, Dario, Olah, Chris, Steinhardt, Jacob, Christiano, Paul, Schulman, John, and Man\u00b4e,\nDan. Concrete problems in ai safety. arXiv preprint arXiv:1606.06565, 2016.\n\n[3] Carlini, Nicholas and Wagner, David. Adversarial examples are not easily detected: Bypassing\nten detection methods. In ACM workshop on AISec, 2017.\n\n[4] Chrabaszcz, Patryk, Loshchilov, Ilya, and Hutter, Frank. A downsampled variant of imagenet\nas an alternative to the cifar datasets. arXiv preprint arXiv:1707.08819, 2017.\n\n[5] Deng, Jia, Dong, Wei, Socher, Richard, Li, Li-Jia, Li, Kai, and Fei-Fei, Li. Imagenet: A\nlarge-scale hierarchical image database. In CVPR, 2009.\n\n[6] Evtimov, Ivan, Eykholt, Kevin, Fernandes, Earlence, Kohno, Tadayoshi, Li, Bo, Prakash, Atul,\nRahmati, Amir, and Song, Dawn. Robust physical-world attacks on machine learning models.\nIn CVPR, 2018.\n\n[7] Feinman, Reuben, Curtin, Ryan R, Shintre, Saurabh, and Gardner, Andrew B. Detecting adversarial samples from artifacts. arXiv preprint arXiv:1703.00410, 2017.\n\n[8] Gal, Yarin, Islam, Riashat, and Ghahramani, Zoubin. Deep bayesian active learning with image\ndata. In ICML, 2017.\n\n[9] Girshick, Ross. Fast r-cnn. In ICCV, 2015.\n\n[10] Goodfellow, Ian J, Shlens, Jonathon, and Szegedy, Christian. Explaining and harnessing adversarial examples. In ICLR, 2015.\n\n[11] Guo, Chuan, Rana, Mayank, Ciss\u00b4e, Moustapha, and van der Maaten, Laurens. Countering\nadversarial images using input transformations. arXiv preprint arXiv:1711.00117, 2017.\n\n[12] He, Kaiming, Zhang, Xiangyu, Ren, Shaoqing, and Sun, Jian. Deep residual learning for image\nrecognition. In CVPR, 2016.\n\n[13] Hendrycks, Dan and Gimpel, Kevin. A baseline for detecting misclassified and out-ofdistribution examples in neural networks. In ICLR, 2017.\n\n[14] Huang, Gao and Liu, Zhuang. Densely connected convolutional networks. In CVPR, 2017.\n\n[15] Krizhevsky, Alex and Hinton, Geoffrey. Learning multiple layers of features from tiny images.\n2009.\n\n[16] Kurakin, Alexey, Goodfellow, Ian, and Bengio, Samy. Adversarial examples in the physical\nworld. arXiv preprint arXiv:1607.02533, 2016.\n\n[17] Lasserre, Julia A, Bishop, Christopher M, and Minka, Thomas P. Principled hybrids of generative and discriminative models. In CVPR, 2006.\n\n[18] Lee, Kibok, Lee, Kimin, Min, Kyle, Zhang, Yuting, Shin, Jinwoo, and Lee, Honglak. Hierarchical novelty detection for visual object recognition. In CVPR, 2018.\n\n[19] Lee, Kimin, Hwang, Changho, Park, KyoungSoo, and Shin, Jinwoo. Confident multiple choice\nlearning. In ICML, 2017.\n\n[20] Lee, Kimin, Lee, Honglak, Lee, Kibok, and Shin, Jinwoo. Training confidence-calibrated\nclassifiers for detecting out-of-distribution samples. In ICLR, 2018.\n\n[21] Liang, Shiyu, Li, Yixuan, and Srikant, R. Principled detection of out-of-distribution examples\nin neural networks. In ICLR, 2018.\n\n\n-----\n\n[22] Ma, Xingjun, Li, Bo, Wang, Yisen, Erfani, Sarah M, Wijewickrema, Sudanthi, Houle,\nMichael E, Schoenebeck, Grant, Song, Dawn, and Bailey, James. Characterizing adversarial subspaces using local intrinsic dimensionality. In ICLR, 2018.\n\n[23] Maaten, Laurens van der and Hinton, Geoffrey. Visualizing data using t-sne. _Journal of_\n_machine learning research, 2008._\n\n[24] McCloskey, Michael and Cohen, Neal J. Catastrophic interference in connectionist networks:\nThe sequential learning problem. In Psychology of learning and motivation. Elsevier, 1989.\n\n[25] Mensink, Thomas, Verbeek, Jakob, Perronnin, Florent, and Csurka, Gabriela. Distance-based\nimage classification: Generalizing to new classes at near-zero cost. IEEE transactions on\n_pattern analysis and machine intelligence, 2013._\n\n[26] Moosavi Dezfooli, Seyed Mohsen, Fawzi, Alhussein, and Frossard, Pascal. Deepfool: a simple\nand accurate method to fool deep neural networks. In CVPR, 2016.\n\n[27] Murphy, Kevin P. Machine learning: a probabilistic perspective. 2012.\n\n[28] Netzer, Yuval, Wang, Tao, Coates, Adam, Bissacco, Alessandro, Wu, Bo, and Ng, Andrew Y.\nReading digits in natural images with unsupervised feature learning. In NIPS workshop, 2011.\n\n[29] Rebuffi, Sylvestre-Alvise and Kolesnikov, Alexander. icarl: Incremental classifier and representation learning. In CVPR, 2017.\n\n[30] Sharif, Mahmood, Bhagavatula, Sruti, Bauer, Lujo, and Reiter, Michael K. Accessorize to a\ncrime: Real and stealthy attacks on state-of-the-art face recognition. In ACM SIGSAC, 2016.\n\n[31] Vinyals, Oriol, Blundell, Charles, Lillicrap, Tim, Wierstra, Daan, et al. Matching networks for\none shot learning. In NIPS, 2016.\n\n[32] Yu, Fisher, Seff, Ari, Zhang, Yinda, Song, Shuran, Funkhouser, Thomas, and Xiao, Jianxiong.\nLsun: Construction of a large-scale image dataset using deep learning with humans in the loop.\n_arXiv preprint arXiv:1506.03365, 2015._\n\n\n-----\n\n### Supplementary Material:\n\n##### A Simple Unified Framework for Detecting Out-of-Distribution Samples and Adversarial Attacks\n\n###### A Preliminaries for Gaussian discriminant analysis\n\nIn this section, we describe the basic concept of the discriminative and generative classifier [27].\nFormally, denote the random variable of the input and label as x and y = 1, _, C_,\n_\u2208X_ _\u2208Y_ _{_ _\u00b7 \u00b7 \u00b7_ _}_\nrespectively. For the classification task, the discriminative classifier directly defines a posterior distribution P (y **x), i.e., learning a direct mapping between input x and label y. A popular model**\n_|_\nfor discriminative classifier is softmax classifier which defines the posterior distribution as follows:\n\nexp(wc[\u22a4][x][+][b][c][)]\n_P (y = c|x) =_ \ufffdc[\u2032][ exp][(][w]c[\u22a4][\u2032] **[x][+][b][c][\u2032]** [)] _[,][ where][ w][c][ and][ b][c][ are weights and bias for a class][ c][, respectively.]_\n\nIn contrast to the discriminative classifier, the generative classifier defines the class conditional distribution P (x _y) and class prior P (y) in order to indirectly define the posterior distribution by_\n_|_\nspecifying the joint distribution P (x, y) = P (y) P (x _y). Gaussian discriminant analysis (GDA) is_\n_|_\na popular method to define the generative classifier by assuming that the class conditional distribution follows the multivariate Gaussian distribution and the class prior follows Bernoulli distribution:\n_P (x|y = c) = N (x|\u00b5c, \u03a3c), P (y = c) =_ \ufffdc\u03b2[\u2032][ \u03b2]c _c[\u2032][,][ where][ \u00b5][c][ and][ \u03a3][c][ are the mean and covariance]_\n\nof multivariate Gaussian distribution, and \u03b2c is the unnormalized prior for class c. This classifier has\nbeen studied in various machine learning areas (e.g., semi-supervised learning [17] and incremental\nlearning [29]).\n\nIn this paper, we focus on the special case of GDA, also known as the linear discriminant analysis\n(LDA). In addition to Gaussian assumption, LDA further assumes that all classes share the same\ncovariance matrix, i.e., \u03a3c = \u03a3. Since the quadratic term is canceled out with this assumption, the\nposterior distribution of generative classifier can be represented as follows:\n\n_P (y = c) P (x|y = c)_ exp \ufffd\u00b5[\u22a4]c **[\u03a3][\u2212][1][x][ \u2212]** [1]2 _[\u00b5]c[\u22a4][\u03a3][\u2212][1][\u00b5][c]_ [+ log][ \u03b2][c]\ufffd\n_P (y = c_ **x) =**\n_|_ \ufffdc[\u2032][ P][ (][y][ =][ c][\u2032][)][ P][ (][x][|][y][ =][ c][\u2032][) =] \ufffdc[\u2032][ exp] \ufffd\u00b5[\u22a4]c[\u2032] **[\u03a3][\u2212][1][x][ \u2212]** [1]2 _[\u00b5]c[\u22a4][\u2032]_ **[\u03a3][\u2212][1][\u00b5][c][\u2032][ + log][ \u03b2][c][\u2032]** [\ufffd] _[.]_\n\n\nOne can note that the above form of posterior distribution is equivalent to the softmax classifier by\nconsidering \u00b5[\u22a4]c **[\u03a3][\u2212][1][ and][ \u2212]** [1]2 _[\u00b5]c[\u22a4][\u03a3][\u2212][1][\u00b5][c]_ [+ log][ \u03b2][c] [as weight and bias of it, respectively. This implies]\n\nthat x might be fitted in Gaussian distribution during training a softmax classifier.\n\n###### B Experimental setup\n\nIn this section, we describe detailed explanation about all the experiments described in Section 3.\n\n**B.1** **Experimental setups in detecting out-of-distribution**\n\n**Detailed model architecture and training. We consider two state-of-the-art neural network archi-**\ntectures: DenseNet [14] and ResNet [12]. For DenseNet, our model follows the same setup as in\nHuang & Liu [14]: 100 layers, growth rate k = 12 and dropout rate 0. Also, we use ResNet with 34\nlayers and dropout rate 0.[2] The softmax classifier is used, and each model is trained by minimizing\nthe cross-entropy loss using SGD with Nesterov momentum. Specifically, we train DenseNet for\n300 epochs with batch size 64 and momentum 0.9. For ResNet, we train it for 200 epochs with\nbatch size 128 and momentum 0.9. The learning rate starts at 0.1 and is dropped by a factor of 10 at\n50% and 75% of the training progress, respectively. The test set errors of DenseNet and ResNet on\nCIFAR-10, CIFAR-100 and SVHN are reported in Table 4.\n\n**Datasets. We train DenseNet and ResNet for classifying CIFAR-10 (or 100) and SVHN datasets:**\nthe former consists of 50,000 training and 10,000 test images with 10 (or 100) image classes, and\nthe latter consists of 73,257 training and 26,032 test images with 10 digits.[3] The corresponding\n\n[2ResNet architecture is available at https://github.com/kuangliu/pytorch-cifar.](https://github.com/kuangliu/pytorch-cifar)\n3We do not use the extra SVHN dataset for training.\n\n\n-----\n\ntest dataset is used as the in-distribution (positive) samples to measure the performance. We use\nrealistic images as the out-of-distribution (negative) samples: the TinyImageNet consists of 10,000\ntest images with 200 image classes from a subset of ImageNet images. The LSUN consists of 10,000\ntest images of 10 different scenes. We downsample each image of TinyImageNet and LSUN to size\n32 32.[4]\n_\u00d7_\n\n**Tested methods. In this paper, we consider the baseline method [13] and ODIN [21] for compari-**\nson. The confidence score in Hendrycks & Gimpel [13] is a maximum value of softmax posterior\ndistribution, i.e., maxy P (y|x). The key idea of ODIN is the temperature scaling which is defined\nas follows:\n\nexp (fy(x)/T )\n_P_ (y = _y_ **x; T** ) = \ufffd\n\ufffd| \ufffd\n\n_y_ [exp (][f][y][(][x][)][/T] [)] _[,]_\n\nwhere T > 0 is the temperature scaling parameter and f = (f1, . . ., fK) is final feature vector of\ndeep neural networks. For each data x, ODIN first calculates the pre-processed image **x by adding**\n\ufffd\nthe small perturbations as follows:\n**x[\u2032]** = x \u2212 _\u03b5odinsign (\u2212\u25bdx log P\u03b8(y = \ufffdy|x; T_ )),\nwhere \u03b5odin is a magnitude of noise and _y is the predicted label._ Next, ODIN feeds the\n\ufffd\npre-processed data into the classifier, computes the maximum value of scaled predictive distribution, i.e., maxy P\u03b8(y|x[\u2032]; T ), and classifies it as positive (i.e., in-distribution) if the confidence score is above some threshold \u03b4. For ODIN, the perturbation noise \u03b5odin is chosen from\n0, 0.0005, 0.001, 0.0014, 0.002, 0.0024, 0.005, 0.01, 0.05, 0.1, 0.2, and the temperature T is cho_{_ _}_\nsen from 1, 10, 100, 1000 .\n_{_ _}_\n\n**Hyper parameters for our method. There are two hyper parameters in our method: the magnitude**\nof noise in (4) and layer indexes for feature ensemble. For all experiments, we extract the confidence\nscores from every end of dense (or residual) block of DenseNet (or ResNet). The size of feature maps\non each convolutional layers is reduced by average pooling for computational efficiency:\n_F \u00d7 H \u00d7_\n1, where is the number of channels and is the spatial dimension. The magnitude\n_W \u2192F \u00d7_ _F_ _H\u00d7W_\nof noise in (4) is chosen from 0, 0.0005, 0.001, 0.0014, 0.002, 0.0024, 0.005, 0.01, 0.05, 0.1, 0.2 .\n_{_ _}_\n\n**Performance metrics. For evaluation, we measure the following metrics to measure the effective-**\nness of the confidence scores in distinguishing in- and out-of-distribution images.\n\n_\u2022 True negative rate (TNR) at 95% true positive rate (TPR). Let TP, TN, FP, and FN de-_\nnote true positive, true negative, false positive and false negative, respectively. We measure\nTNR = TN / (FP+TN), when TPR = TP / (TP+FN) is 95%.\n\n_\u2022 Area under the receiver operating characteristic curve (AUROC). The ROC curve is a_\ngraph plotting TPR against the false positive rate = FP / (FP+TN) by varying a threshold.\n\n_\u2022 Area under the precision-recall curve (AUPR). The PR curve is a graph plotting the_\nprecision = TP / (TP+FP) against recall = TP / (TP+FN) by varying a threshold. AUPR-IN\n(or -OUT) is AUPR where in- (or out-of-) distribution samples are specified as positive.\n\n_\u2022 Detection accuracy. This metric corresponds to the maximum classification probability_\nover all possible thresholds \u03b4:\n1 \u2212 min\u03b4 \ufffdPin (q (x) \u2264 _\u03b4) P (x is from Pin) + Pout (q (x) > \u03b4) P (x is from Pout)_ \ufffd,\n\nwhere q(x) is a confident score. We assume that both positive and negative examples have\nequal probability of appearing in the test set, i.e., P (x is from Pin) = P (x is from Pout).\n\nNote that AUROC, AUPR and detection accuracy are threshold-independent evaluation metrics.\n\n**B.2** **Experimental setups in detecting adversarial samples**\n\n**Adversarial attacks. For the problem of detecting adversarial samples, we consider the following**\nattack methods: fast gradient sign method (FGSM) [10], basic iterative method (BIM) [16], DeepFool [26] and Carlini-Wagner (CW) [3]. The FGSM directly perturbs normal input in the direction\nof the loss gradient. Formally, non-targeted adversarial examples are constructed as\n**xadv = x + \u03b5F GSM** sign (\u25bdx\u2113(y[\u2217], P (y|x))),\n\n[4LSUN and TinyImageNet datasets are available at https://github.com/ShiyuLiang/odin-pytorch.](https://github.com/ShiyuLiang/odin-pytorch)\n\n\n-----\n\nCIFAR-10 CIFAR-100 SVHN\n\n_L\u221e_ Acc. _L\u221e_ Acc. _L\u221e_ Acc.\n\nClean 0 95.19% 0 77.63% 0 96.38%\nFGSM 0.21 20.04% 0.21 4.86% 0.21 56.27%\n\nDenseNet BIM 0.22 0.00% 0.22 0.02% 0.22 0.67%\n\nDeepFool 0.30 0.23% 0.25 0.23% 0.57 0.50%\nCW 0.05 0.10% 0.03 0.16% 0.12 0.54%\n\nClean 0 93.67% 0 78.34% 0 96.68%\nFGSM 0.25 23.98% 0.25 11.67% 0.25 49.33%\n\nResNet BIM 0.26 0.02% 0.26 0.21% 0.26 2.37%\n\nDeepFool 0.36 0.33% 0.27 0.37% 0.62 13.20%\nCW 0.08 0.00% 0.08 0.01% 0.15 0.04%\n\nTable 4: The L\u221e mean perturbation and classification accuracy on clean and adversarial samples.\n\nwhere \u03b5F GSM is a magnitude of noise, y[\u2217] is the ground truth label and \u2113 is a loss function to measure\nthe distance between the prediction and the ground truth. The BIM is an iterative version of FGSM,\nwhich applies FGSM multiple times with a smaller step size. Formally, non-targeted adversarial\nexamples are constructed as\n\n**x[0]adv** [=][ x][,][ x]adv[n][+1] [=][ Clip]x[\u03b5][BIM] _{x[n]adv_ [+][ \u03b1][BIM] [sign] \ufffd\u25bdx[n]adv _[\u2113][(][y][\u2217][, P]_ [(][y][|][x]adv[n] [))]\ufffd},\n\nwhere Clip[\u03b5]x[BIM] means we clip the resulting image to be within the \u03b5BIM -ball of x. DeepFool works\nby finding the closest adversarial examples with geometric formulas. CW is an optimization-based\nmethod which arguably the most effective method. Formally, non-targeted adversarial examples are\nconstructed as\n\narg min\n**xadv** _[\u03bbd][(][x][,][ x][adv][)][ \u2212]_ _[\u2113][(][y][\u2217][, P]_ [(][y][|][x][adv][))][,]\n\nwhere \u03bb is penalty parameter and d( _,_ ) is a metric to quantify the distance between an original\n\n_\u00b7_ _\u00b7_\nimage and its adversarial counterpart. However, compared to FGSM and BIM, this method is much\nslower in practice. For all experiments, L2 distance is used as a constraint. We used the library from\nFaceBook [11] for generating adversarial samples.[5] Table 4 tatistics of adversarial attacks including\nthe L\u221e mean perturbation and classification accuracy on adversarial attacks.\n\n**Tested methods. Ma et al. [22] proposed to characterize adversarial subspaces by using local in-**\ntrinsic dimensionality (LID). Given a test sample x, LID is defined as follows:\n\n|Col1|CIFAR-10 L Acc. \u221e|CIFAR-100 L Acc. \u221e|SVHN L Acc. \u221e|\n|---|---|---|---|\n\n|Clean FGSM DenseNet BIM DeepFool CW|0 95.19% 0.21 20.04% 0.22 0.00% 0.30 0.23% 0.05 0.10%|0 77.63% 0.21 4.86% 0.22 0.02% 0.25 0.23% 0.03 0.16%|0 96.38% 0.21 56.27% 0.22 0.67% 0.57 0.50% 0.12 0.54%|\n|---|---|---|---|\n\n|Clean FGSM ResNet BIM DeepFool CW|0 93.67% 0.25 23.98% 0.26 0.02% 0.36 0.33% 0.08 0.00%|0 78.34% 0.25 11.67% 0.26 0.21% 0.27 0.37% 0.08 0.01%|0 96.68% 0.25 49.33% 0.26 2.37% 0.62 13.20% 0.15 0.04%|\n|---|---|---|---|\n\n\n\ufffd\n\nlog _[r][i][(][x][)]_\n\n_rk(x)_\n\n_i_\n\n\n\ufffd\n\n\n_LID\ufffd_ = \u2212\n\n\n\ufffd\n1\n_k_\n\n\n_,_\n\n\nwhere ri(x) denotes the distance between x and its i-th nearest neighbor within a sample of points\ndrawn from in-distribution, and rk(x) denotes the maximum distance among k nearest neighbors.\nWe commonly extract the LID scores from every end of dense (or residual) block of DenseNet (or\nResNet) similar to ours. Given test sample x and the set Xc of training samples with label c, the\nGaussian kernel density with bandwidth \u03c3 is defined as follows:\n\n\n1\n_KD(x) =_\n\n_|Xc|_\n\n\n\ufffd\n\n_k\u03c3(xi, x),_\n**xi\u2208Xc**\n\n\nwhere k\u03c3(x, y) \u221d exp(\u2212||x \u2212 _y||[2]/\u03c3[2]). For LID and KD, we used the library from Ma et al. [22]._\n\n**Hyper-parameters and training. Following the similar strategies in [7, 22], we randomly choose**\n10% of original test samples for training the logistic regression detectors and the remaining test\nsamples are used for evaluation. The training sets consists of three types of examples: adversarial,\nnormal and noisy. Here, noisy examples are generated by adding random noise to normal examples.\nUsing nested cross validation within the training set, all hyper-parameters including the bandwidth\n\n[5The code is available at https://github.com/facebookresearch/adversarial_image_defenses.](https://github.com/facebookresearch/adversarial_image_defenses)\n\n\n-----\n\n|Col1|LID|Mahalanobis (our)|\n|---|---|---|\n\n\n100\n\n90\n\n80\n\n70\n\n60\n\n\n100\n\n90\n\n80\n\n70\n\n60\n\n\n100\n\n90\n\n80\n\n70\n\n60\n\n\nAdversarial attack: FGSM\n\n\nAdversarial attack: BIM\n\n\n5K 10K 20K 30K 40K 50K\n\n\nAdversarial attack: DeepFool\n\n\nAdversarial attack: CW\n\n\n100\n\n90\n\n80\n\n70\n\n60\n\n\n(a) Small training data: the x-axis represents the number of training data\n\n\n100\n\n90\n\n80\n\n70\n\n60\n\n\n100\n\n90\n\n80\n\n70\n\n60\n\n\n100\n\n90\n\n80\n\n70\n\n60\n\n\n100\n\n90\n\n80\n\n70\n\n60\n\n\n(b) Noisy training data: the x-axis represents the percentage of training data with random label\nFigure 5: Comparison of AUROC (%) under different training data. To evaluate the robustness of\nproposed method, we train ResNet (a) by varying the number of training data and (b) assigning\nrandom label to training data on CIFAR-10 dataset.\n\n|Col1|Col2|Col3|Col4|Col5|Col6|Col7|Col8|Col9|Col10|\n|---|---|---|---|---|---|---|---|---|---|\n|||||||||||\n|||||||||||\n|5|K|10 Ad|K vers|20K arial at|30K tack: FG|4 ( SM|0K a)|50 S|K m|\n|||||||||||\n|||||||||||\n|||||||||||\n|||||||||||\n|0% gu op nd|re o o|10 (b 5 se m|% ) : d la|20% No Co me bel|30 isy mp tho to|% tr ar d, tr|40 ain is ai|% in o we ni|g n n|\n\n|Col1|Col2|Col3|Col4|Col5|Col6|Col7|Col8|Col9|Col10|\n|---|---|---|---|---|---|---|---|---|---|\n|||||||||||\n|||||||||||\n|5K g d|10 at A|K a dve|20 rsari|K al att|30K ack: C|4 W|0K|50|K|\n|||||||||||\n|||||||||||\n|||||||||||\n|||||||||||\n|0% ith lua dat|10 r te a|% an t a|2 do he nd|0% m r (|30 la ob b)|% be us a|40 l tn ssi|% e g|ss n|\n\n\n40\n\n|Col1|Col2|Col3|Col4|Col5|Col6|Col7|Col8|Col9|Col10|Col11|\n|---|---|---|---|---|---|---|---|---|---|---|\n||||||||||||\n||||||||||||\n|5 rai|K ni|10 n A|K g d dve|20 a rsari|K ta: al att|30K th ack: B|4 e IM|0K x-|50 ax|K is s di ry ta|\n||||||||||||\n||||||||||||\n||||||||||||\n||||||||||||\n||||||||||||\n|0% : U ta 80 70 60 50|th R Re o|10 e O s n|% x- C N C|2 ax ( et IF|0% is % (a A|30 rep ) u ) R-|% re n by 1|40 se de 0|% nt r va da||\n|||||||S E|oftmax uclidean Mahalanob||is (ours)||\n||||||||||||\n||||||||||||\n||||||||||||\n\n|Col1|Col2|Col3|Col4|Col5|Col6|Col7|\n|---|---|---|---|---|---|---|\n||||||||\n||||||||\n|5K ese|10 nts Adv|K t ersa|20 he rial a|K 30 nu ttack: D|K 4 mbe eepFo|0K 50 r of ol|\n||||||||\n||||||||\n||||||||\n||||||||\n|0% per en th 60 40 20|10 cen t tr e n|% ta ai u|2 ge ni m|0% of ng ber|30% trai dat of|40% ning a. tra|\n||||||||\n||||||||\n||||||||\n||Softma Euclide Mahala||x an nobis (ours)||||\n\n\n102 104 106 108 110\n\nThe number of classes\n\n\n0 20 40 60 80\n\nBase class accuracy (%)\n\n\n0\n\n\n(a) Base: CIFAR-100 / New: CIFAR-10\n\nFigure 6: Experimental results of class-incremental learning on CIFAR-100 and CIFAR-10 datasets.\nWe report (left) AUC with respect to the number of learned classes and, (right) the base-new class\naccuracy curve after the last new classes is added.\n\n\nparameter for KD, the number of nearest neighbors for LID, and input noise for our method are\ntuned. Specifically, the value of k is chosen from 10, 20, 30, 40, 50, 60, 70, 80, 90 with respect to\n_{_ _}_\na minibatch of size 100, and the bandwidth was chosen from 0.1, 0.25, 0.5, 0.75, 1 . The magnitude\n_{_ _}_\nof noise in (4) is chosen from 0, 0.0005, 0.001, 0.0014, 0.002, 0.0024, 0.005, 0.01, 0.05, 0.1, 0.2 .\n_{_ _}_\n\n###### C More experimental results\n\n\nIn this section, we provide more experimental results.\n\n**C.1** **Robustness of our method in detecting adversarial samples**\n\n\nIn order to verify the robustness, we measure the detection performance when we train ResNet\nby varying the number of training data and assigning random label to training data on CIFAR-10\ndataset. As shown in Figure 5, our method (blue bar) outperforms LID (green bar) for all experiments.\n\n**C.2** **Class-incremental learning**\n\n\nFigure 6 compares the AUCs of tested methods when CIFAR-100 is pre-trained and CIFAR-10 is\nused as new classes. Our proposed Mahalanobis distance-based classifier outperforms the other\nmethods by a significant margin, as the number of new classes increases. The AUC of our proposed\nmethod is 47.7%, which is better than 41.0% of the softmax classifier and 43.0% of the Euclidean\ndistance classifier after all new classes are added.\n\n\n-----\n\n**C.3** **Experimental results on joint confidence loss**\n\nIn addition, we remark that the proposed detector using softmax neural classifier trained by standard\ncross entropy loss typically outperforms the ODIN detector using softmax neural classifier trained\nby confidence loss [19] which involves jointly training a generator and a classifier to calibrate the\nposterior distribution. Also, our detector provides further improvement if one use it with model\ntrained by confidence loss. In other words, our proposed method can improve any pre-trained softmax neural classifier.\n\n\n(a) In-distribution: CIFAR-10\n\nOut-of-distribution: TinyImageNet\n\n\n100\n\n90\n80\n70\n60\n50\n40\n30\n20\n10\n\n0\n\n100\n\n90\n80\n70\n60\n50\n40\n30\n20\n10\n\n0\n\n\nTNR\n\nat TPR 95%\n\n\nOut-of-distribution: SVHN\n\nTNR AUROC Detection\n\nTPR 95% accuracy\n\nOut-of-distribution: CIFAR-10\n\n\nTNR\n\nat TPR 95%\n\n\nOut-of-distribution: TinyImageNet\n\n\nOut-of-distribution: LSUN\n\nTNR AUROC Detection\n\nat TPR 95% accuracy\n\nOut-of-distribution: LSUN\n\nTNR AUROC Detection\n\nat TPR 95% accuracy\n\n\nTNR\n\nat TPR 95%\n\n\nAUROC Detection\n\naccuracy\n\n\n100\n\n90\n80\n70\n60\n50\n40\n30\n20\n10\n\n0\n\n100\n\n90\n80\n70\n60\n50\n40\n30\n20\n10\n\n0\n\n\nAUROC Detection\n\naccuracy\n\n\n100\n\n90\n80\n70\n60\n50\n40\n30\n20\n10\n\n0\n\n100\n\n90\n80\n70\n60\n50\n40\n30\n20\n10\n\n0\n\n\nAUROC Detection\n\naccuracy\n\n\n(b) In-distribution: SVHN\nFigure 7: Performances of the baseline detector [13], ODIN detector [21] and Mahalanobis detector\nunder various training losses.\n\n**C.4** **Comparison with ODIN**\n\nIn-dist TNR at TPR 95% AUROC Detection accuracy AUPR in AUPR out\nOut-of-dist\n(model) Baseline [13] / ODIN [21] / Mahalanobis (ours)\n\n\nCIFAR-10\n(DenseNet)\n\nCIFAR-100\n(DenseNet)\n\nSVHN\n(DenseNet)\n\nCIFAR-10\n(ResNet)\n\nCIFAR-100\n(ResNet)\n\nSVHN\n(ResNet)\n\n\nSVHN 40.2 / 86.2 / 90.8 89.9 / 95.5 / 98.1 83.2 / 91.4 / 93.9 83.1 / 78.8 / 96.6 94.7 / 98.3 / 99.2\nTinyImageNet 58.9 / 92.4 / 95.0 94.1 / 98.5 / 98.8 88.5 / 93.9 / 95.0 95.3 / 98.5 / 98.8 92.3 / 98.5 / 98.8\nLSUN 66.6 / 96.2 / 97.2 95.4 / 99.2 / 99.3 90.3 / 95.7 / 96.3 96.5 / 99.3 / 99.3 94.1 / 99.2 / 99.1\n\nSVHN 26.7 / 70.6 / 82.5 82.7 / 93.8 / 97.2 75.6 / 86.6 / 91.5 74.3 / 87.1 / 94.8 91.0 / 97.3 / 98.8\nTinyImageNet 17.6 / 42.6 / 86.6 71.7 / 85.2 / 97.4 65.7 / 77.0 / 92.2 74.2 / 85.6 / 97.6 69.0 / 84.5 / 97.2\nLSUN 16.7 / 41.2 / 91.4 70.8 / 85.5 / 98.0 64.9 / 77.1 / 93.9 74.1 / 86.4 / 98.2 67.9 / 84.2 / 97.5\n\nCIFAR-10 69.3 / 71.7 / 96.8 91.9 / 91.4 / 98.9 86.6 / 85.8 / 95.9 95.7 / 95.2 / 99.6 82.8 / 84.5 / 95.8\nTinyImageNet 79.8 / 84.1 / 99.9 94.8 / 95.1 / 99.9 90.2 / 90.4 / 98.9 97.2 / 97.1 / 99.9 88.4 / 91.4 / 99.6\nLSUN 77.1 / 81.1 / 100.0 94.1 / 94.5 / 99.9 89.1 / 89.2 / 99.3 97.0 / 97.0 / 99.9 87.4 / 90.5 / 99.7\n\nSVHN 32.5 / 86.6 / 96.4 89.9 / 96.7 / 99.1 85.1 / 91.1 / 95.8 85.4 / 92.5 / 98.3 94.0 / 98.5 / 99.6\nTinyImageNet 44.7 / 72.5 / 97.1 91.0 / 94.0 / 99.5 85.1 / 86.5 / 96.3 92.5 / 94.2 / 99.5 88.4 / 94.1 / 99.5\nLSUN 45.4 / 73.8 / 98.9 91.0 / 94.1 / 99.7 85.3 / 86.7 / 97.7 92.5 / 94.2 / 99.7 88.6 / 94.3 / 99.7\n\nSVHN 20.3 / 62.7 / 91.9 79.5 / 93.9 / 98.4 73.2 / 88.0 / 93.7 64.8 / 89.0 / 96.4 89.0 / 96.9 / 99.3\nTinyImageNet 20.4 / 49.2 / 90.9 77.2 / 87.6 / 98.2 70.8 / 80.1 / 93.3 79.7 / 87.1 / 98.2 73.3 / 87.4 / 98.2\nLSUN 18.8 / 45.6 / 90.9 75.8 / 85.6 / 98.2 69.9 / 78.3 / 93.5 77.6 / 84.5 / 98.4 72.0 / 85.7 / 97.8\n\nCIFAR-10 78.3 / 79.8 / 98.4 92.9 / 92.1 / 99.3 90.0 / 89.4 / 96.9 95.1 / 94.0 / 99.7 85.7 / 86.8 / 97.0\nTinyImageNet 79.0 / 82.1 / 99.9 93.5 / 92.0 / 99.9 90.4 / 89.4 / 99.1 95.7 / 93.9 / 99.9 86.2 / 88.1 / 99.1\nLSUN 74.3 / 77.3 / 99.9 91.6 / 89.4 / 99.9 89.0 / 87.2 / 99.5 94.2 / 92.1 / 99.9 84.0 / 85.5 / 99.1\n\n\nTable 5: Distinguishing in- and out-of-distribution test set data for image classification. We tune the\nhyper-parameters using validation set of in- and out-of-distributions. All values are percentages and\nthe best results are indicated in bold.\n\n\n-----\n\nIn-dist TNR at TPR 95% AUROC Detection accuracy AUPR in AUPR out\nOut-of-dist\n(model) Baseline [13] / ODIN [21] / Mahalanobis (ours)\n\n\nCIFAR-10\n(DenseNet)\n\nCIFAR-100\n(DenseNet)\n\nSVHN\n(DenseNet)\n\nCIFAR-10\n(ResNet)\n\nCIFAR-100\n(ResNet)\n\nSVHN\n(ResNet)\n\n\nSVHN 40.2 / 70.5 / 89.6 89.9 / 92.8 / 97.6 83.2 / 86.5 / 92.6 83.1 / 72.1 / 94.5 94.7 / 97.4 / 99.0\nTinyImageNet 58.9 / 87.1 / 94.9 94.1 / 97.2 / 98.8 88.5 / 92.1 / 95.0 95.3 / 94.7 / 98.7 92.3 / 97.0 / 98.8\nLSUN 66.6 / 92.9 / 97.2 95.4 / 98.5 / 99.2 90.3 / 94.3 / 96.2 96.5 / 97.7 / 99.3 94.1 / 98.2 / 99.2\n\nSVHN 26.7 / 39.8 / 62.2 82.7 / 88.2 / 91.8 75.6 / 80.7 / 84.6 74.3 / 80.8 / 82.6 91.0 / 94.0 / 95.8\nTinyImageNet 17.6 / 43.2 / 87.2 71.7 / 85.3 / 97.0 65.7 / 77.2 / 91.8 74.2 / 85.8 / 96.2 69.0 / 84.7 / 97.1\nLSUN 16.7 / 42.1 / 91.4 70.8 / 85.7 / 97.9 64.9 / 77.3 / 93.8 74.1 / 86.7 / 98.1 67.9 / 84.6 / 97.6\n\nCIFAR-10 69.3 / 69.3 / 97.5 91.9 / 91.9 / 98.8 86.6 / 86.6 / 96.3 95.7 / 95.7 / 99.6 82.8 / 82.8 / 95.1\nTinyImageNet 79.8 / 79.8 / 99.9 94.8 / 94.8 / 99.8 90.2 / 90.2 / 98.9 97.2 / 97.2 / 99.9 88.4 / 88.4 / 99.5\nLSUN 77.1 / 77.1 / 100 94.1 / 94.1 / 99.9 89.1 / 89.1 / 99.2 97.0 / 97.0 / 99.9 87.4 / 87.4 / 99.6\n\nSVHN 32.5 / 40.3 / 75.8 89.9 / 86.5 / 95.5 85.1 / 77.8 / 89.1 85.4 / 77.8 / 91.0 94.0 / 93.7 / 98.0\nTinyImageNet 44.7 / 69.6 / 95.5 91.0 / 93.9 / 99.0 85.1 / 86.0 / 95.4 92.5 / 94.3 / 98.6 88.4 / 93.7 / 99.1\nLSUN 45.4 / 70.0 / 98.1 91.0 / 93.7 / 99.5 85.3 / 85.8 / 97.2 92.5 / 94.1 / 99.5 88.6 / 93.6 / 99.5\n\nSVHN 20.3 / 12.2 / 41.9 79.5 / 72.0 / 84.4 73.2 / 67.7 / 76.5 64.8 / 48.6 / 69.1 89.0 / 84.9 / 92.7\nTinyImageNet 20.4 / 33.5 / 70.3 77.2 / 83.6 / 87.9 70.8 / 75.9 / 84.6 79.7 / 84.5 / 76.8 73.3 / 81.7 / 90.7\nLSUN 18.8 / 31.6 / 56.6 75.8 / 81.9 / 82.3 69.9 / 74.6 / 79.7 77.6 / 82.1 / 70.3 72.0 / 80.3 / 85.3\n\nCIFAR-10 78.3 / 79.8 / 94.1 92.9 / 92.1 / 97.6 90.0 / 89.4 / 94.6 95.1 / 94.0 / 98.1 85.7 / 86.8 / 94.7\nTinyImageNet 79.0 / 80.5 / 99.2 93.5 / 92.9 / 99.3 90.4 / 90.1 / 98.8 95.7 / 94.8 / 98.8 86.2 / 87.5 / 98.3\nLSUN 74.3 / 76.3 / 99.9 91.6 / 90.7 / 99.9 89.0 / 88.2 / 99.5 94.2 / 93.0 / 99.9 84.0 / 85.0 / 98.8\n\n\nTable 6: Distinguishing in- and out-of-distribution test set data for image classification when we tune\nthe hyper-parameters of ODIN and our method only using in-distribution and adversarial (FGSM)\nsamples. All values are percentages and boldface values indicate relative the better results.\n\n**C.5** **LID for detecting out-of-distribution samples**\n\nFigure 8 and 9 shows the performance of the ODIN [21], LID [22] and Mahalanobis detector for\neach in- and out-of-distribution pair. We remark that the proposed method outperforms all tested\nmethods.\n\n|Col1|Col2|ODIN|Col4|LID|Col6|Mahalanobis (our)|\n|---|---|---|---|---|---|---|\n\n\n100\n\n90\n\n80\n\n70\n\n\n100\n\n90\n\n80\n\n70\n\n100\n\n90\n\n80\n\n70\n\n60\n\n50\n\n40\n\n\n100\n\n90\n\n80\n\n70\n\n100\n\n90\n\n80\n\n70\n\n60\n\n50\n\n40\n\n100\n\n90\n\n80\n\n70\n\n|Col1|Col2|Col3|Col4|Col5|Col6|Col7|Col8|Col9|\n|---|---|---|---|---|---|---|---|---|\n||||||||||\n||||||||||\n||||||||||\n||||||||||\n|at T|TNR PR|95% Out-|A of-dist|URO ributi|C on: S|D a VHN|etecti ccura|on cy|\n||||||||||\n||||||||||\n||||||||||\n||||||||||\n||||||||||\n|at T|TNR PR 9 O|5% ut-of-|A distri|URO butio|C n: CIF|De ac AR-10|tectio cura|n cy|\n||||||||||\n||||||||||\n||||||||||\n||||||||||\n\n|Col1|Col2|Col3|Col4|Col5|Col6|Col7|Col8|Col9|\n|---|---|---|---|---|---|---|---|---|\n||||||||||\n||||||||||\n||||||||||\n||||||||||\n|at T ) I|TNR PR n-d|95% ist Out-|A ribu of-dist|URO tio ributi|C n: on: L|D a CI SUN|etecti ccura FA|on cy R-|\n||||||||||\n||||||||||\n||||||||||\n||||||||||\n||||||||||\n|at T In|TNR PR 9 -d|5% istr Out-|A ibu of-dist|URO tio ributi|C n: on: L|De ac CIF SUN|tectio cura A|n cy R-1|\n||||||||||\n||||||||||\n||||||||||\n||||||||||\n||||||||||\n\n|Col1|Col2|Col3|Col4|Col5|Col6|Col7|Col8|Col9|\n|---|---|---|---|---|---|---|---|---|\n||||||||||\n||||||||||\n||||||||||\n||||||||||\n|at|TNR TPR Ou|95% t-of-di|A stribu|URO tion:|C TinyI|D a mageN|etecti ccura et|on cy|\n||||||||||\n||||||||||\n||||||||||\n||||||||||\n|at T|TNR PR 9 Ou|5% t-of-di|A stribu|URO tion:|C TinyI|De ac mageN|tectio cura et|n cy|\n||||||||||\n||||||||||\n||||||||||\n||||||||||\n||||||||||\n\n\nTNR\n\nat TPR 95%\n\n\nOut-of-distribution: SVHN\n\n\nOut-of-distribution: LSUN\n\n\nOut-of-distribution: TinyImageNet\n\n\n(a) In-distribution: CIFAR-10\n\nOut-of-distribution: LSUN\n\n100\n\n90\n\n80\n\n70\n\n60\n\n50\n\n40\n\n\n(b) In-distribution: CIFAR-100\n\n\nTNR\n\nat TPR 95%\n\n\nTNR\n\nat TPR 95%\n\n\nAUROC Detection\n\naccuracy\n\n\n100\n\n90\n\n80\n\n70\n\n\nAUROC Detection\n\naccuracy\n\n\n100\n\n90\n\n80\n\n70\n\n\nAUROC Detection\n\naccuracy\n\n\n(c) In-distribution: SVHN\nFigure 8: Distinguishing in- and out-of-distribution test set data for image classification using\nResNet.\n\n\n-----\n\n|Col1|Col2|ODIN|Col4|LID|Col6|Mahalanobis (our)|\n|---|---|---|---|---|---|---|\n\n\n100\n\n90\n\n80\n\n\n100\n\n90\n\n80\n\n100\n\n90\n\n80\n\n70\n\n60\n\n50\n\n40\n\n\n100\n\n90\n\n80\n\n100\n\n90\n\n80\n\n70\n\n60\n\n50\n\n40\n\n100\n\n90\n\n80\n\n70\n\n\nOut-of-distribution: SVHN\n\n\n100\n\n90\n\n80\n\n70\n\n\nOut-of-distribution: LSUN\n\n\nOut-of-distribution: TinyImageNet\n\n\n(a) In-distribution: CIFAR-10\n\nOut-of-distribution: LSUN\n\n100\n\n90\n\n80\n\n70\n\n60\n\n50\n\n40\n\n\n(b) In-distribution: CIFAR-100\n\n\n100\n\n90\n\n80\n\n70\n\n\n(c) In-distribution: SVHN\nFigure 9: Distinguishing in- and out-of-distribution test set data for image classification using\nDenseNet.\n\n###### D Evaluation on ImageNet dataset\n\nIn this section, we verify the performance of the proposed method using the ImageNet 2012 classification dataset [5] that consists of 1000 classes. The models are trained on the 1.28 million\ntraining images, and evaluated on the 50k validation images. For all experiments, we use the\n[pre-trained ResNet [12] which is available at https://github.com/pytorch/vision/blob/](https://github.com/pytorch/vision/blob/master/torchvision/models/resnet.py)\n```\nmaster/torchvision/models/resnet.py. First, we measure the classification accuracy of gen\n```\nerative classifier from the pre-trained model as follows:\n\n_y\ufffd(x) = arg minc_ (f (x) \u2212 _\u00b5\ufffdc)[\u22a4]_ **\u03a3[\ufffd]** _[\u2212][1]_ (f (x) \u2212 _\u00b5\ufffdc) + log_ _\u03b2[\ufffd]c,_\n\nwhere _\u03b2[\ufffd]c =_ _[N]N[c]_ [is an empirical class prior. We remark that this corresponds to predicting a class]\n\nlabel using the posterior distribution from generative with LDA assumption. Table 7 shows the\ntop-1 classification accuracy on ImageNet 2012 dataset. One can note that the proposed generative\nclassifier can perform reasonably well even though the softmax classifier outperforms it in all cases.\nHowever, we remark that the gap between them is decreasing as the training accuracy increases, i.e.,\nthe pre-trained model learned more strong representations.\n\nModel Softmax (training) Softmax (validation) Generative (validation)\n\nResNet (101 layers) 86.55 75.66 73.49\nResNet (18 layers) 69.06 68.69 63.32\n\nTable 7: Top-1 accuracy (%) of ResNets on ImageNet 2012 dataset.\n\nNext, we also evaluate the detection performance of the Mahalanobis distance-based detector on\nImageNet 2012 dataset using ResNets with 18 layers. For evaluation, we consider the problem of\n\n|Col1|Col2|Col3|Col4|Col5|Col6|Col7|Col8|Col9|\n|---|---|---|---|---|---|---|---|---|\n||||||||||\n|at T|TNR PR|95% Out-|A of-dist|URO ributi|C on: S|D a VHN|etecti ccura|on cy|\n||||||||||\n||||||||||\n||||||||||\n||||||||||\n||||||||||\n|at T|TNR PR 9 O|5% ut-of-|A distri|URO butio|C n: CIF|De ac AR-10|tectio cura|n cy|\n||||||||||\n||||||||||\n||||||||||\n||||||||||\n||||||||||\n|at T : t. al cti d im ed|TNR PR 9 Di ua on ata ag R|5% stin tio , w set es, esN|A gu n e [5 an et|URO is o ve ] d [1|C hin n I rify tha ev 2]|De ac g i m th t c alu w|tectio cura n- ag e on ate hic|n cy an e pe sis d h|\n\n|Col1|Col2|Col3|Col4|Col5|Col6|Col7|Col8|Col9|\n|---|---|---|---|---|---|---|---|---|\n|at T ) I|TNR PR n-d|95% ist Out-|A ribu of-dist|URO tio ributi|C n: on: L|D a CI SUN|etecti ccura FA|on cy R-|\n||||||||||\n||||||||||\n||||||||||\n||||||||||\n|at T In|TNR PR 9 -d|5% istr Out-|A ibu of-dist|URO tio ributi|C n: on: L|De ac CIF SUN|tectio cura A|n cy R-1|\n||||||||||\n||||||||||\n||||||||||\n|at T (c) t-o da an 1 he ail|TNR PR 9 In f- ta ce 00 50 ab|5% -di dis se of 0 c k le|A stri tri t th las val at|URO bu but e se id ht|C tion io pro s. ati tp|De ac : S n t po T on s:|tectio cura V est se he im //|n cy HN se d m m ag gi|\n\n|Col1|Col2|Col3|Col4|Col5|Col6|Col7|Col8|Col9|\n|---|---|---|---|---|---|---|---|---|\n||||||||||\n|at|TNR TPR Ou|95% t-of-di|A stribu|URO tion:|C TinyI|D a mageN|etecti ccura et|on cy|\n||||||||||\n||||||||||\n||||||||||\n||||||||||\n|at T|TNR PR 9 Ou|5% t-of-di|A stribu|URO tion:|C TinyI|De ac mageN|tectio cura et|n cy|\n||||||||||\n||||||||||\n||||||||||\n||||||||||\n|at T ta d a Fo .c|TNR PR 9 fo usi re r a o|5% r i ng tra ll m/p|A ma th ine ex yt|URO ge e I d pe o|C cl ma on rim rch|De ac ass ge th en /v|tectio cura ifi Ne e ts, i|n cy cat t 2 1.2 w sio|\n\n\n-----\n\n# Review comment90 100 100 100\n\n8070 KD + PULIDOurs 9080 9080 9080\n\n60 70 70 70\n\n##### \u2022 Generating the garbage images matching mean & variance5040 605040 605040 605040\n\n3020100        - Initialize random vector X3020100 KD + PULIDOurs 3020100 BaselineODINLIDOurs 3020100 BaselineODINLIDOurs\n\nat TPR 95%\u2022TNR Find X which optimize the following objective (final layer attack):AUROC Detection accuracy at TPR 95%TNR AUROC Detection accuracy at TPR 95%TNR AUROC Detection accuracy at TPR 95%TNR AUROC Detection accuracy\n\n\n#### 2\n\n|70 \u2022 60 50 40 30|LID GeOurns e \u2022 In|rat itia|i liz|ng t e r|h an|80 e ga70 60 50 dom34 00|rb v|a ec|g to|e r|i X|m|a|ge KD|s + PU|80 ma70t 60 50 40 30|c|h|i|n|g|Col23|m|e|a B|n asel|ine|80 & va70r 60 50 40 30|ia|n|c|e|Col34|Col35|B|asel|ine|Col39|\n|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n\n\n(a) FGSM (b) BIM (c) Scenario 1 (d) Scenario 2\n\nFigure 10: (a)/(b) Distinguishing clean and adversarial samples using ResNet with 18 layers on\n\n##### \u2022ImageNet 2012 validation set. (c)/(d) Distinguishing clean and garbage samples using ResNet 18 Experimental results\n\nlayers trained on CIFAR-10 dataset.\u2022 Model: ResNet-34 trained on CIFAR-10 (Success rate: 89.00 %)\n\nClass 0  class 1.  class 2.  class 3.  class 4.  class 5.  class 6.  class 7.  class 8.  class 9.\n\nFigure 11: The generated garbage sample and its target class.\n\ndetecting adversarial samples generated by FGSM [10] and BIM [16]. Similar to Section 3.2, we\nextract the confidence scores from every end of residual block of ResNet. Figure 10(a) and 10(b)\nshow the performance of various detectors. One can note that the proposed Mahalanobis distancebased detector outperforms all tested methods including LID. These results imply that our method\ncan be working well for the large-scale datasets.\n\n\n###### E Adaptive attacks against Mahalanobis distance-based detector\n\nIn this section, we evaluate the robustness of our method by generating the garbage images which\nmay fool the Mahalanobis distance-based detector in a white-box setting, i.e., one can access to the\nparameters of the classifier and that of the Mahalanobis distance-based detector. Here, we remark\nthat accessing the parameters of the Mahalanobis distance-based detector, i.e., sample means and\ncovariance, is not mild assumption since the information about training data is required to compute\nthem. To attack our method, we generate a garbage images xg by minimizing the Mahalanobis\ndistance as follows:\n\narg min\n**xg** [(][f] [(][x][g][)][ \u2212] _[\u00b5][\ufffd][c][)][\u22a4]_ **[\u03a3][\ufffd]** _[\u2212][1][ (][f]_ [(][x][g][)][ \u2212] _[\u00b5][\ufffd][c][)][,]_\n\nwhere c is a target class. We test two different scenarios using ResNet with 34 layers trained on\nCIFAR-10 dataset. In the first scenario, we generate the garbage images only using a penultimate\nlayer of DNNs. In the second scenario, we attack every end of residual block of ResNet. Figure 11\nshows the generated samples by minimizing the Mahalanobis distance. Even though the generated\nsample looks like the random noise, it successfully fools the pre-trained classifier, i.e., it is classified\nas the target class. We measure the detection performance of the baseline [13], ODIN [21], LID\n\n[22] and the proposed Mahalanobis distance-based detector. As shown in Figure 10(c) and 10(d),\nour method can distinguish CIFAR-10 test and garbage images for both scenarios better than the\ntested methods. In particular, we remark that the input pre-processing is very useful in detecting\nsuch garbage samples. These results imply that our proposed method is robust to the attacks.\n\n###### F Hybrid inference of generative and discriminative classifiers\n\nIn this paper, we show that the generative classifier can be very useful in characterizing the abnormal\nsamples such as OOD and adversarial samples. Here, a caveat is that the generative classifier might\ndegrade the classification performance. In order to handle this issue, we introduce a hybrid inference\nof generative and discriminative classifiers. Given a generative classifier with GDA assumptions, the\nposterior distribution of generative classifier via Bayes rule is given as:\n\n_P (y = c) P (x|y = c)_ exp \ufffd\u00b5[\u22a4]c **[\u03a3][\u2212][1][x][ \u2212]** [1]2 _[\u00b5]c[\u22a4][\u03a3][\u2212][1][\u00b5][c]_ [+ log][ \u03b2][c]\ufffd\n_P (y = c_ **x) =**\n_|_ \ufffdc[\u2032][ P][ (][y][ =][ c][\u2032][)][ P][ (][x][|][y][ =][ c][\u2032][) =] \ufffdc[\u2032][ exp] \ufffd\u00b5[\u22a4]c[\u2032] **[\u03a3][\u2212][1][x][ \u2212]** [1]2 _[\u00b5]c[\u22a4][\u2032]_ **[\u03a3][\u2212][1][\u00b5][c][\u2032][ + log][ \u03b2][c][\u2032]** [\ufffd] _[.]_\n\n\n(b) BIM (c) Scenario 1\n\nFigure 10: (a)/(b) Distinguishing clean and adversarial samples using ResNet with 18 layers on\n\n\n-----\n\nTo match this with a standard softmax classifier\u2019s weights, the parameters of the generative classifier\nhave to satisfy the following conditions:\n\n_\u00b5c = \u03a3wc, log \u03b2c \u2212_ 0.5\u00b5[\u22a4]c [\u03a3][\u2212][1][\u00b5][c] [=][ b][c][,]\n\nwhere wc and bc are weights and bias for a class c, respectively. Using the empirical covariance\n\u03a3\ufffd as shown in (1), one can induce the parameters of another generative classifier which has same\ndecision boundary with the softmax classifier as follows:\n\n_\u00b5\u02dcc =_ \u03a3[\ufffd]wc, _\u03b2[\u02dc]c =_ \ufffd exp(0.5\u02dc\u00b5[\u22a4]c [\u03a3][\ufffd] _[\u2212][1][\u00b5][\u02dc][c]_ _[\u2212]_ _[b][c][)]_ _._\n\n_c[\u2032][ exp(0][.][5\u02dc][\u00b5]c[\u22a4][\u2032][ \ufffd][\u03a3][\u2212][1][\u00b5][\u02dc][c][\u2032][ \u2212]_ _[b][c][\u2032]_ [)]\n\nHere, we normalize the _\u03b2[\u02dc]c to satisfy_ [\ufffd]c _[\u03b2][\u02dc][c][ = 1][. Then, using this generative classifier, we define new]_\n\nhybrid posterior distribution which combines the softmax- and sample-based generative classifiers:\n\n_Ph(y|x)_\n\n\ufffd \ufffd \ufffd \ufffd \ufffd\ufffd\n= exp _\u03bb_ _\u00b5\ufffd[\u22a4]c_ **[\u03a3][\ufffd]** _[\u2212][1][x][ \u2212]_ [0][.][5][\u00b5][\ufffd]c[\u22a4][\u03a3][\ufffd] _[\u2212][1][\u00b5][\ufffd][c]_ [+ log][ \ufffd][\u03b2][c] + (1 \u2212 _\u03bb)_ _\u00b5\u02dc[\u22a4]c_ **[\u03a3][\ufffd]** _[\u2212][1][x][ \u2212]_ [0][.][5][\u00b5][\u02dc]c[\u22a4][\u03a3][\ufffd] _[\u2212][1][\u00b5][\u02dc][c]_ [+ log \u02dc][\u03b2][c] _,_\n\n\ufffd \ufffd \ufffd \ufffd \ufffd\ufffd\n\ufffdc[\u2032][ exp] _\u03bb_ _\u00b5\ufffd[\u22a4]c[\u2032][ \ufffd][\u03a3][\u2212][1][x][ \u2212]_ [0][.][5][\u00b5][\ufffd][\u22a4]c[\u2032][ \ufffd][\u03a3][\u2212][1][\u00b5][\ufffd][c][\u2032][ + log][ \ufffd][\u03b2][c][\u2032] + (1 \u2212 _\u03bb)_ _\u00b5\u02dc[\u22a4]c[\u2032][ \ufffd][\u03a3][\u2212][1][x][ \u2212]_ [0][.][5][\u00b5][\u02dc][\u22a4]c[\u2032][ \ufffd][\u03a3][\u2212][1][\u00b5][\u02dc][c][\u2032][ + log \u02dc][\u03b2][c][\u2032]\n\nwhere \u03bb [0, 1] is a hyper-parameter. This hybrid model can be interpreted as ensemble of softmax\n_\u2208_\nand generative classifiers, and one can expect that it can improve the classification performance.\nTable 8 compares the classification accuracy of softmax, generative and hybrid classifiers. One can\nnote that the hybrid model improves the classification accuracy, where we determine the optimal\ntuning parameter between the two objectives using the validation set. We also remark that such\nhybrid model can be useful in detecting the abnormal samples, where we pursue these tasks in the\nfuture.\n\nModel Dataset Softmax Generative Hybrid\n\nCIFAR-10 95.16 94.76 95.00\nDenseNet CIFAR-100 77.64 74.01 77.71\nSVHN 96.42 96.32 96.34\n\nCIFAR-10 93.61 94.13 94.11\nResNet CIFAR-100 78.08 77.86 77.96\nSVHN 96.62 96.58 96.59\n\nTable 8: Classification test set accuracy (%) of DenseNet and ResNet on CIFAR-10, CIFAR-100\nand SVHN datasets.\n\n\n-----\n\n",
    "query": "I am interested in finding articles about identify out of distribution samples in neural networks training",
    "references": [
      {
        "arxiv_id": "1606.06565",
        "title": "Concrete problems in ai safety",
        "relevance_score": 4,
        "relevance_score_explanation": "This paper discusses concrete problems in AI safety, which is tangentially related to the topic of identifying out-of-distribution samples in neural networks.  The connection lies in the need for robust and reliable AI systems, where the ability to detect unexpected inputs is crucial for safety."
      },
      {
        "arxiv_id": "1703.00410",
        "title": "Detecting adversarial samples from artifacts",
        "relevance_score": 5,
        "relevance_score_explanation": "This paper directly addresses the detection of adversarial samples, a closely related problem to identifying out-of-distribution samples.  Both deal with identifying inputs that deviate from the training distribution."
      },
      {
        "arxiv_id": "1707.08819",
        "title": "A downsampled variant of imagenet as an alternative to the cifar datasets",
        "relevance_score": 1,
        "relevance_score_explanation": "This paper introduces a downsampled variant of ImageNet, which is a dataset used in the main paper for experiments.  It is not directly about OOD detection but provides data used in the research."
      },
      {
        "arxiv_id": "1711.00117",
        "title": "Countering adversarial images using input transformations",
        "relevance_score": 2,
        "relevance_score_explanation": "This paper discusses countering adversarial images, which is related to the broader theme of improving robustness in neural networks.  While not directly about OOD detection, it contributes to the overall context."
      },
      {
        "arxiv_id": "1607.02533",
        "title": "Adversarial examples in the physical world",
        "relevance_score": 4,
        "relevance_score_explanation": "This paper focuses on adversarial examples in the physical world, a sub-topic highly relevant to identifying out-of-distribution samples.  The methods and challenges discussed are directly applicable."
      },
      {
        "arxiv_id": "1506.03365",
        "title": "Lsun: Construction of a large-scale image dataset using deep learning with humans in the loop",
        "relevance_score": 1,
        "relevance_score_explanation": "This paper describes the LSUN dataset, which is used in the main paper for experiments.  It is not directly about OOD detection but provides data used in the research."
      }
    ]
  }
]